var tipuesearch = {"pages":[{"title":"About This Website","text":"Welcome to Stats Works! This website is dedicated to statistical approaches to various problems. Statistics and the analysis of data are becoming more and more relevant in the world today. With the introduction of machine learning techniques, statistics and computer science have become essential to the ability of business and governments' success. Unleashing the potential of information is more crucial than ever, and is having a remarkable impact on the world. This website is dedicated to personal projects surrounding both statistics and machine learning and shows how we can leverage the wealth of data in the world today to make actionable insights to further improve the world we live in. Parts of this website are also dedicated to explaining some basic statistical concepts to those who may have no background in statistics, or have a background in STEM but need a refresher on these topics. The author, Sean Ammirati, is a Data Scientist with a deep love and passion for statistics, programming and machine learning. The intention of creating this website is to demonstrate practical implementations of theoretical statistics as well as demystify some of the more complex topics in the dicipline. Sean has a Master's degree in Statistics from Hunter College.","tags":"About","url":"pages/about/","loc":"pages/about/"},{"title":"Constrained Least Squares","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Consider the following: We wish to constrain the parameters of a linear model to have certain properties, for example, that the last coefficient is equal to 1, or that the sum of the coefficients are equal to one. How can we estimate the Least Squares Estimates using these constraints? Thus is constrained least squares, and this article will explore the theoretical basis for choosing a selection of coefficients that will minimize the least squares given some linear constraints on the coefficients. Constrained Least Squares -- Coefficient Calculation and Simulation We want to maximize the likelihood equation of β. We know that Y in this context is normally distributed with mean Xβ and variance σ&#94;2&#94;. This means that the distribution of yi given X is as follows: $$f_{Y}\\left( \\mathbf{y}_{i} \\middle| X \\right) = {(2\\pi\\sigma&#94;{2})}&#94;{- 1/2}e&#94;{\\frac{\\mathbf{- (y}_{\\mathbf{i}}\\mathbf{-}\\mathbf{x}_{\\mathbf{i}}\\mathbf{\\beta)}}{2\\mathbf{\\sigma}&#94;{\\mathbf{2}}}&#94;{\\mathbf{2}}}$$ So the likelihood of β is therefore: $$L\\left( \\beta,\\sigma&#94;{2} \\middle| y,X \\right) = \\left( 2\\pi\\sigma&#94;{2} \\right)&#94;{- \\frac{N}{2}}e&#94;{- \\frac{\\sum_{\\mathbf{i}}&#94;{\\mathbf{N}}{\\mathbf{(y}_{\\mathbf{i}}\\mathbf{-}\\mathbf{x}_{\\mathbf{i}}\\mathbf{\\beta)}}}{2\\mathbf{\\sigma}&#94;{\\mathbf{2}}}&#94;{\\mathbf{2}}}$$ Taking the natural logarithm gives us the log likelihood: $$l\\left( \\beta,\\sigma&#94;{2} \\middle| y,X \\right) = - \\frac{1}{2\\sigma&#94;{2}}\\sum_{\\mathbf{i}}&#94;{\\mathbf{N}}{{\\mathbf{(y}_{\\mathbf{i}}\\mathbf{-}\\mathbf{x}_{\\mathbf{i}}\\mathbf{\\beta)}}&#94;{\\mathbf{2}}\\mathbf{-}\\frac{N}{2}\\text{ln}\\left( \\sigma&#94;{2} \\right)\\mathbf{+ C}}\\mathbf{=} - \\frac{1}{2\\sigma&#94;{2}}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right) - \\frac{N}{2}\\text{ln}\\left( \\sigma&#94;{2} \\right)\\mathbf{+ C}$$ Here, I have truncated the result to only those involving β and $\\sigma&#94;{2}$, as we are only interested in maximizing with respect to β . Note that I have transitioned $\\sigma&#94;{2}$ to a constant, as we are assuming the errors are iid with constant variance $\\sigma&#94;{2}$. Here, we obtain the same result as minimizing the least squares estimator, so the MLE and the least squares estimators are the same. If we were unconstrained, we would simply take the partial derivative here with respect to β to estimate β using maximum likelihood. Since $\\sigma&#94;{2}$ is unconstrained, we can find the maximum likelihood estimator directly and use this to maximize with respect to β. To do this, we differentiate the above equation with respect to σ. Doing so yields the normal estimate for $\\sigma&#94;{2}$: $${\\widehat{\\sigma}}&#94;{2} = - \\frac{1}{N}\\sum_{\\mathbf{i}}&#94;{\\mathbf{N}}{\\mathbf{(y}_{\\mathbf{i}}\\mathbf{-}\\mathbf{x}_{\\mathbf{i}}\\mathbf{\\beta}&#94;{\\mathbf{c}}\\mathbf{)}}&#94;{\\mathbf{2}}\\mathbf{=}\\frac{\\mathbf{1}}{\\mathbf{N}}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)$$ Where $\\mathbf{\\beta}&#94;{\\mathbf{c}}$ is our new constrained estimates. Plugging this back into the log likelihood equation yields: $$l\\left( \\mathbf{\\beta}&#94;{\\mathbf{c}} \\middle| \\mathbf{y},X \\right) = - \\frac{1}{- \\frac{2}{N}\\left( y - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( y - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right) - \\frac{N}{2}\\text{ln}\\left( \\frac{1}{N}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right) \\right)\\mathbf{+ C}$$$$l\\left( \\beta \\middle| y,X \\right) = - \\frac{N}{2} - \\frac{N}{2}\\text{ln}\\left( \\frac{1}{N}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right) \\right)\\mathbf{+ C}$$ However, we want to maximize the above equation with the constraint that: M β = d, where d is a known vector and M is an r x p matrix of rank r \\< p. This is an equality constraint. We can use the Lagrange multipliers to solve this maximization problem with such a constraint. We can see that, since the natural logarithm is a monotonically increasing function, and the division within the above logarithm is a constant, and that all other terms do not involve B, maximizing the above equation with respect to$\\ \\mathbf{\\beta}&#94;{\\mathbf{c}}$ is equivalent to minimizing: $$f = \\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right)&#94;{'}\\left( \\mathbf{y} - X\\mathbf{\\beta}&#94;{\\mathbf{c}} \\right) - \\mathbf{\\lambda}&#94;{\\mathbf{'}}\\left( M\\mathbf{\\beta}&#94;{\\mathbf{c}}\\ –\\ d \\right)$$ Where $\\mathbf{\\lambda}$ is the Lagrange multiplier (and so f is the Lagrange function). The Lagrange multiplier is especially useful in this case, as we are trying to minimize the least square error with some constraint on the parameters. Multiplying the error by the transpose gives: $$\\mathbf{f =}\\mathbf{y}&#94;{\\mathbf{'}}\\mathbf{y -}\\mathbf{y}&#94;{\\mathbf{'}}X\\mathbf{\\beta}&#94;{\\mathbf{c}}\\mathbf{-}{\\mathbf{\\beta}&#94;{\\mathbf{c}}}&#94;{\\mathbf{'}}X&#94;{'}\\mathbf{y} + {\\mathbf{\\beta}&#94;{\\mathbf{c}}}&#94;{\\mathbf{'}}X&#94;{'}X\\mathbf{\\beta}&#94;{\\mathbf{c}}\\mathbf{-}\\mathbf{\\lambda}&#94;{\\mathbf{'}}\\left( M\\mathbf{\\beta}&#94;{\\mathbf{c}}\\ –\\ d \\right) = \\mathbf{=}\\mathbf{y}&#94;{\\mathbf{'}}\\mathbf{y -}\\mathbf{2}{\\mathbf{\\beta}&#94;{\\mathbf{c}}}&#94;{\\mathbf{'}}X&#94;{'}\\mathbf{y} + {\\mathbf{\\beta}&#94;{\\mathbf{c}}}&#94;{\\mathbf{'}}X&#94;{'}X\\mathbf{\\beta}&#94;{\\mathbf{c}}\\mathbf{-}\\mathbf{\\lambda}&#94;{\\mathbf{'}}\\left( M\\mathbf{\\beta}&#94;{\\mathbf{c}}\\ –\\ d \\right)$$ Now we take derivatives with respect to $\\mathbf{\\beta}&#94;{\\mathbf{c}}$ and $\\mathbf{\\lambda}$ to obtain $$\\frac{\\text{δf}}{\\text{δB}}\\mathbf{=} - 2X&#94;{'}\\mathbf{y}\\mathbf{+}2X&#94;{'}X\\mathbf{\\beta}&#94;{\\mathbf{c}}\\mathbf{-}M&#94;{'}\\mathbf{\\lambda}$$$$\\frac{\\text{δf}}{\\text{δλ}}\\mathbf{=}M\\mathbf{\\beta}&#94;{\\mathbf{c}}\\ –\\ d$$ We can now set both of these equal to zero and solve this system of equations to find the appropriate MLE estimate of $\\mathbf{\\beta}&#94;{\\mathbf{c}}$ . However, there is a few simplifying steps which can make the result more useable. The first is to get the expression in terms of the original least squares estimator. If we multiply the first equation above by M(${X&#94;{'}X)}&#94;{- 1}$, we obtain: $$- \\ 2M({X&#94;{'}X)}&#94;{- 1}X&#94;{'}\\mathbf{y}\\mathbf{+}\\ 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{-}\\ M({X&#94;{'}X)}&#94;{- 1}M&#94;{'}\\mathbf{\\lambda} = 0$$ The first term on the right is the familiar $\\mathbf{\\beta}$ from unconstrained OLS (I will denote this $\\mathbf{\\beta}&#94;{\\mathbf{u}}$). Substituting, we get $$- \\ 2M\\mathbf{\\beta}&#94;{\\mathbf{u}}\\mathbf{+}\\ 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{-}\\ M({X&#94;{'}X)}&#94;{- 1}M&#94;{'}\\mathbf{\\lambda} = 0$$$$- \\ 2M\\mathbf{\\beta}&#94;{\\mathbf{u}}\\mathbf{+}\\ 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{-}\\ M({X&#94;{'}X)}&#94;{- 1}M&#94;{'}\\mathbf{\\lambda} = 0$$$$M({X&#94;{'}X)}&#94;{- 1}M&#94;{'}\\mathbf{\\lambda} = \\ 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}} - \\ 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}$$ Solving for lambda: $$\\mathbf{\\lambda} = {(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\left\\lbrack 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}} - \\ 2M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}} \\right\\rbrack\\mathbf{= 2}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack}$$ Plugging this back into the original equation and solving for ${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}$ , $$0\\mathbf{=} - 2X&#94;{'}\\mathbf{y}\\mathbf{+}2X&#94;{'}X{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{-}M&#94;{'}\\mathbf{\\lambda}$$$$0\\mathbf{=} - 2X&#94;{'}\\mathbf{y}\\mathbf{+}2X&#94;{'}X{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{-}{2(M}&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack)}$$$$X&#94;{'}X{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}X&#94;{'}\\mathbf{y}\\mathbf{+}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack}$$$${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{= (}{{X&#94;{'}X)}&#94;{- 1}X}&#94;{'}\\mathbf{y}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack}$$$${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}\\mathbf{\\beta}&#94;{\\mathbf{u}}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack}$$ This is the desired result, the maximum likelihood estimator given the constraint M$\\mathbf{\\beta =}d$. Now, we return to the first part of the problem. $$\\beta_{p} = 0$$ Is equivalent to the following constraint. α $\\mathbf{'\\beta = 0}$ where α is a vector of zeros in all but the last row, which is a 1. So, $\\mathbf{\\alpha} = \\left( 0,\\ 0,\\ 0,\\ 0,\\ldots\\ 1 \\right)&#94;{'}$ Plugging it into the derived result, we get: $${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}\\mathbf{\\alpha}&#94;{'}{(\\mathbf{\\alpha}&#94;{'}({X&#94;{'}X)}&#94;{- 1}\\mathbf{\\alpha})}&#94;{- 1}\\lbrack - \\ \\mathbf{\\alpha}\\mathbf{'}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack}$$$${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}\\mathbf{\\alpha}&#94;{'}{(\\mathbf{\\alpha}&#94;{'}({X&#94;{'}X)}&#94;{- 1}\\mathbf{\\alpha})}&#94;{- 1}\\lbrack - \\ {{\\widehat{\\beta}}&#94;{u}}_{p}\\mathbf{\\rbrack}$$ Since $\\mathbf{\\alpha}&#94;{\\mathbf{- 1}}\\mathbf{= \\alpha}$ in this case, we know that $\\mathbf{\\alpha}&#94;{'}{(\\mathbf{\\alpha}&#94;{'}({X&#94;{'}X)}&#94;{- 1}\\mathbf{\\alpha})}&#94;{- 1} = \\mathbf{\\alpha}&#94;{'}\\left( \\mathbf{\\alpha}&#94;{'}\\left( X&#94;{'}X \\right)\\mathbf{\\alpha} \\right) = {X&#94;{'}X}_{p,p}$ which is a scalar that is the bottom right element of the X'X matrix. So we can simplify this to: $${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}{X&#94;{'}X}_{p,p}\\lbrack - \\ {{\\widehat{\\beta}}&#94;{u}}_{p}\\mathbf{\\rbrack}$$ Since ${X&#94;{'}X}_{p,p}\\lbrack 1 - \\ {\\beta&#94;{u}}_{p}\\mathbf{\\rbrack}$ is a constant: $${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{-}{X&#94;{'}X}_{p,p}(\\left\\lbrack \\ {\\beta&#94;{u}}_{p} \\right\\rbrack\\mathbf{)}{{(X}&#94;{'}X)}&#94;{- 1}$$ So, if we compute the unconstrained ${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}$ and ${{(X}&#94;{'}X)}&#94;{- 1}$, we can solve directly for the constrained $\\mathbf{\\text{β.}}$ Now, for the second part of part a), this is equivalent to M being a vector of 1s, lets call it ϕ. Then ϕ = (1,1,1,1,...,1)' and d = 1. Plugging it into the derived result, we get: $${\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}\\mathbf{=}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}\\phi&#94;{'}{(\\phi&#94;{'}({X&#94;{'}X)}&#94;{- 1}\\phi)}&#94;{- 1}\\lbrack 1 - \\text{ϕ}\\mathbf{'}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\mathbf{\\rbrack}$$ The residual sum of squares is defined as: $RSS = \\ {(\\mathbf{y -}\\widehat{\\mathbf{y}})}&#94;{'}(\\mathbf{y -}\\widehat{\\mathbf{y}})$ In this case, $\\widehat{\\mathbf{y}} = X{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{c}}$ = X ( $\\mathbf{\\beta}&#94;{\\mathbf{u}}\\mathbf{+}{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}$])$\\mathbf{=}\\mathbf{\\ }X\\mathbf{\\beta}&#94;{\\mathbf{u}}\\mathbf{+}\\text{X}{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\rbrack$ So it follows that $\\left( \\mathbf{y -}\\widehat{\\mathbf{y}_{\\mathbf{c}}} \\right) = \\mathbf{y} - \\ X\\mathbf{\\beta}&#94;{\\mathbf{u}}\\mathbf{+}\\text{X}{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\rbrack$= $$\\ \\mathbf{\\varepsilon +}\\text{X}{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\rbrack$$ where $\\mathbf{\\varepsilon}$ is the error in the unconstrained case. So RSSc -- RSS =$\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\rbrack'{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\rbrack)$ Each of the errors are normally distributed with mean 0 and variance sigma squared. This implies that: $(\\mathbf{y} - \\check{\\mathbf{y}})\\ \\mathbf{I}\\frac{1}{\\sigma}\\sim\\text{MVN}(0,I)$, iid. $\\ $ Where the estimator is the estimator from the restrained equation. We can write the sum of squares of the above as: $$\\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right)&#94;{'}(\\mathbf{I}\\frac{1}{\\sigma&#94;{2}})\\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right) = \\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right)&#94;{'}(\\mathbf{I}\\frac{1}{\\sigma&#94;{2}})\\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right) + \\ \\left( \\check{\\mathbf{y}}\\mathbf{-}\\widehat{\\mathbf{y}} \\right)&#94;{\\mathbf{'}}\\left( \\mathbf{I}\\frac{\\mathbf{1}}{\\mathbf{\\sigma}&#94;{\\mathbf{2}}} \\right)\\left( \\check{\\mathbf{y}}\\mathbf{-}\\widehat{\\mathbf{y}} \\right)\\mathbf{+ 2(}\\check{\\mathbf{y}}\\mathbf{-}\\widehat{\\mathbf{y}}\\mathbf{)'}\\left( \\mathbf{I}\\frac{\\mathbf{1}}{\\mathbf{\\sigma}&#94;{\\mathbf{2}}} \\right)\\mathbf{(y -}\\check{\\mathbf{y}}\\mathbf{)}$$ Where$\\ {\\check{y}}_{i}\\ $is the estimator of the unconstrained model. To show this, we remove the identical identity matrices and see that: $$\\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right)&#94;{'}\\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right) = \\left( \\mathbf{y} - \\check{\\mathbf{y}} + \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right)&#94;{'}\\left( \\mathbf{y} - \\check{\\mathbf{y}} + \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right) =$$$$\\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right)&#94;{'}\\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right) + \\ \\left( \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right)&#94;{'}\\left( \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right) + 2(\\mathbf{y} - \\check{\\mathbf{y}})'\\left( \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right)$$ Now, $$\\left( \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right) = \\left( \\mathbf{y} - \\widehat{\\mathbf{y}} - \\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right) \\right) = \\left( \\ \\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right) - \\mathbf{\\varepsilon} \\right)$$ which we know from the above is $(X{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\lbrack d - \\text{M}{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}}\\rbrack$)' Rewriting, we have: $$\\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right)'\\left( \\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right) - \\mathbf{\\varepsilon} \\right) = \\mathbf{\\varepsilon}'(X{{(X}&#94;{'}X)}&#94;{- 1}M&#94;{'}{(M({X&#94;{'}X)}&#94;{- 1}M&#94;{'})}&#94;{- 1}\\left\\lbrack d - \\ M{\\widehat{\\mathbf{\\beta}}}&#94;{\\mathbf{u}} \\right\\rbrack)$$ Using the fact that $\\mathbf{\\varepsilon'X = 0}$ , we can remove this to obtain. $${\\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right)&#94;{'}\\left( \\mathbf{y} - \\widehat{\\mathbf{y}} \\right) = \\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right)}&#94;{'}\\left( \\mathbf{y} - \\check{\\mathbf{y}} \\right) + \\ \\left( \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right)&#94;{'}\\left( \\check{\\mathbf{y}} - \\widehat{\\mathbf{y}} \\right)$$ Thus the original standardized normal variable can be represented as a sum of Q1, and Q2 where: Q1 = $\\left( \\mathbf{y -}\\check{\\mathbf{y}} \\right)&#94;{\\mathbf{'}}\\left( \\mathbf{y -}\\check{\\mathbf{y}} \\right)$ Q2 = $\\left( \\check{\\mathbf{y}}\\mathbf{-}\\widehat{\\mathbf{y}} \\right)&#94;{\\mathbf{'}}\\left( \\check{\\mathbf{y}}\\mathbf{-}\\widehat{\\mathbf{y}} \\right) $ Q1 is the sum of squared errors for the unconstrained model, and therefore has rank $n - p$. Q2 has rank p -- r , as it is the differences between the two estimators. Thus rank(Q1) + rank (Q2) = n-r, which is the rank of the errors of the constrained model, since r\\<p. Thus by Cochran's Theorum, the two are independently distributed. I have also produced simulations to prove that this is the case. I create three normal random variables, two of which are related to the others linearly and randomly. I compute the beta unconstrained, and then use this to compute the beta constrained. I then produce the errors for the constrained beta, and check the correlations in 100 samples of 100 each. The mean correlation is very close to zero, which is the expected result. This is included below. In [2]: const <- vector () unconst <- vector () correl <- vector () for ( j in 1 : 100 ) { for ( i in 1 : 100 ) { y <- rnorm ( 100 ) x1 <- y + rnorm ( 100 , 0 , .2 ) x2 <- rnorm ( 100 , 0 , .01 ) - .3 * y Xmat <- matrix ( c ( rep ( 1 , length ( x1 )), x1 , x2 ), ncol = 3 ) data2 <- data.frame ( y , x1 , x2 ) mod.sim.1 <- lm ( y ~ x1 + x2 , data = data2 ) constraint <- matrix ( 1 , nrow = nrow ( data2 ), ncol = 1 ) d = 1 M = matrix ( rep ( 1 , 3 ), ncol = 1 ) mod.sim.1 BetaUnconstr <- summary ( mod.sim.1 ) $ coef[ , 1 ] b <- d - t ( M ) %*% BetaUnconstr a <- t ( Xmat ) %*% Xmat c <- solve ( t ( M ) %*% solve ( a ) %*% M ) const[i] <- b * c * b unconst[i] <- sum ( resid ( mod.sim.1 ) &#94;2 ) } correl[j] <- cor ( const , unconst ) } correl mean ( correl ) -0.0531688267764585 -0.114464495425658 0.030905848126332 -0.0804090923830123 -0.0282214216966975 0.194785864859665 0.0830930039710045 0.0724914248601695 0.0829089181916613 0.0288906516772889 0.0279474715925631 -0.0533135707611509 0.0658332419742044 -0.0799946756911054 -0.0941441499229167 -0.024909668515204 0.0714084573952652 -0.0455394491591305 0.166193108785476 -0.077429232110221 -0.128495293842719 -0.0786313087721033 -0.135204615732129 0.00402444738581924 -0.210414921426846 -0.0466002337555276 -0.0744914482523485 0.0253724403628865 -0.144593000144071 -0.0558067022331745 0.0941802108323231 -0.0326002696533416 0.1191407256456 0.0742989188901125 0.0498008210293263 0.02980912239177 -0.132207185159464 -0.154762140608869 -0.0311445812733598 0.0213674326991292 -0.0563900846752629 0.113499475702925 -0.125719333220632 0.0434611514397736 0.202868180728299 -0.113919008868015 -0.0382369212754716 0.0491389841646633 -0.0198221517858243 0.0175352131496739 0.0264657952051942 0.119278436715872 -0.218521793800235 0.0159366944834975 0.194276086012615 -0.121180977909389 -0.165054100432551 -0.0651733446635078 -0.07680468077657 -0.0503302517530004 0.00823376132659068 0.00388666785680694 -0.00915532185917745 -0.0930607404292774 -0.171362738860478 -0.0310668331585724 -0.0210004347148357 0.0549900820264029 -0.0468877624516252 0.0868626310356565 0.0532565684252016 -0.168838788927617 0.0339257077316963 0.0762184886512164 -0.0890754231460831 -0.0647727147695691 -0.0889513202649563 0.000667073625725037 0.0509714346818621 -0.0940193584932185 -0.0839669876254321 0.106982624440368 0.145030507757848 -0.0757386310783636 0.161739345883223 0.214585243128979 -0.0764856927072532 0.0477290142665558 0.0126102486334496 -0.0741476392314046 -0.0725679361079652 -0.0807334358109478 0.0186774645788979 0.0234449247050084 0.0176989561150896 0.0516204767156866 0.120367846574953 0.0233333600272549 -0.00113490805336294 0.118557812809982 -0.00814363230874542 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Linear Models","url":"category/linear-models/constrained-least-squares.html","loc":"category/linear-models/constrained-least-squares.html"},{"title":"Hidden Markov Models","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } In my previous project, I developed the reasoning behind Hidden Markov Models (HMM) and developed a way of determining the most likely sequence of states that resulted in an observed sequence of emissions using the Viterbi algorithm. This project will explore extensions to the Hidden Markov Model, such as the Forwards-Backwards algorithm and the Baum-Welch algorithm. Consider a discrete time, discrete state-space Hidden Markov chain with: $\\pi_{t}$ : the state at time t (unknown in the HMM) of n possible states $\\pi_{t} = 1,2,\\ldots,n$ $x_{\\text{t}}$: the emission at time t of m possible emissions, $x_{\\text{t}} = 1,2,\\ldots,m$ P(0) : initial probabilities of being in the states. P : a nxn transition matrix of transitions between states, giving P($\\pi_{t} = i\\left| \\pi_{t - 1} = j \\right)$ for the ith row and jth column. E : a nxm matrix containing P($x_{\\text{t}} = j\\ \\left| \\ \\pi_{t} = i \\right)$ in the ith row, jth column, the emission probabilities. Note that the row sums must sum to 1. Given a set of observed emissions, $x_{1,\\ldots,\\ T}$, the Viterbi algorithm gives us the most likely sequence of states, $\\pi_{1,\\ldots,\\ T}$ that resulted in the observed emissions, given P and E. Although this decoding algorithm is very useful, there may be other aspects of the HMM we are interested in. One such problem is, given a set of observed emissions $x_{1,\\ldots,\\ T}$, what is the probability of the observed emissions? This problem can be solved using the law of total probability, i.e.: $$P\\left( x_{1},\\ \\ldots,x_{T} \\right) = \\ \\sum_{\\mathbf{\\pi}}&#94;{}{P(x_{1},\\ \\ldots,x_{T}}\\left| \\ \\mathbf{\\pi} \\right)P(\\mathbf{\\pi})\\ $$ where $\\mathbf{\\pi}$ refers to any vector of state sequences. This can be computationally intensive -- for many steps, this will involve summing over an exponentially large number of possible state sequences. Thus, an algorithmic approach will be useful to make this result practical to obtain for large T. This is a similar problem to the Viterbi algorithm, but not exactly the same. This can be solved using the forward algorithm , as described below. Note that we can also write the above as: $$P\\left( x_{1},\\ \\ldots,x_{T} \\right) = \\ \\sum_{\\mathbf{\\pi}}&#94;{}{P(x_{1},\\ \\ldots,x_{T}},\\mathbf{\\pi})\\ $$ Let's call $\\alpha_{t}(\\pi_{t})$ = $P\\left( x_{1},\\ \\ldots,x_{t},\\ \\pi_{t} \\right) = \\ \\sum_{\\pi_{t - 1}}&#94;{}{P(x_{1},\\ \\ldots,x_{T},\\ \\pi_{t},\\pi_{t - 1})}$ It follows that our desired probability of the sequence is equal to the sum over all states of the above quantity. $$\\alpha_{t}(\\pi_{t}) = \\ \\sum_{\\mathbf{\\pi}_{t - 1}}&#94;{}{P(x_{t}|x_{1},\\ \\ldots,x_{t - 1},\\ \\pi_{t},\\ \\pi_{t - 1})P(\\pi_{t}|x_{1},\\ \\ldots,x_{t - 1},\\ \\pi_{t - 1}})P(x_{1},\\ \\ldots,x_{t - 1},\\ \\pi_{t - 1})$$ But $x_{t}$ is conditionally independent of everything but $\\pi_{t},\\ $and $\\pi_{t}$conditionally independent on everything but $\\pi_{t - 1}$. So we can write this simply as: $$\\alpha_{t}(\\pi_{t}) = \\ P(x_{t}|\\pi_{t})\\sum_{\\mathbf{\\pi}_{t - 1}}&#94;{}{P(\\pi_{t}|\\pi_{t - 1}})P(x_{1},\\ \\ldots,x_{t - 1},\\ \\pi_{t - 1})$$$$= \\ P(x_{t}|\\pi_{t})\\sum_{\\mathbf{\\pi}_{t - 1}}&#94;{}{P(\\pi_{t}|\\pi_{t - 1}})\\alpha_{t - 1}(\\pi_{t - 1})$$ It follows, then, that we can compute each $\\alpha_{t}$ recursively. This will eliminate the need to look at the probability of all states. This has a computation time of $O(\\text{nm}&#94;{2})$ which is far faster than doing it for each possible sequence, which is$\\ O(\\text{nm}&#94;{n})$. After computing this for each possible state at time T, we sum the probabilities to get the probability of the observed sequence. Note that $\\alpha_{1}\\left( \\pi_{1} \\right) = P(x_{1}|\\pi_{1})\\sum_{x_{0}}&#94;{}{P(\\pi_{1}|\\pi_{0}})P(\\pi_{0}) = \\ \\ P(x_{1}|\\pi_{1})P(\\pi_{1})$, where $P\\left( \\pi_{1} \\right)$ is to be considered the initial probabilities of entering the chain, predefined by the problem. Consider the following example of a fair and biased coin, where: Initial probabilities are equal, .5 for fair and .5 for biased $$\\mathbf{P = \\ }\\begin{matrix} .9 & .1 \\\\ .05 & .95 \\\\ \\end{matrix}$$$$\\mathbf{E = \\ }\\begin{matrix} .5 & .5 \\\\ .25 & .75 \\\\ \\end{matrix}$$ We observe the sequence HTHHTTHH and want to determine the probability of this sequence occurring given our HMM. First, $$\\alpha_{1}\\left( \\pi_{1} = F \\right) = \\ P\\left( x_{1} \\middle| \\pi_{1} = F \\right)P\\left( \\pi_{1} = F \\right) = \\left( 0.5 \\right)\\left( 0.5 \\right) = \\ .25$$$$\\alpha_{1}\\left( \\pi_{1} = B \\right) = P\\left( x_{1} \\middle| \\pi_{1} = B \\right)P\\left( \\pi_{1} = B \\right) = \\left( 0.25 \\right)\\left( 0.5 \\right) = \\ .135$$ So it follows that the probability of a head being observed, alone, is the sum of these partial probabilities, or .385. To determine the probability of the full sequence, we continue this recursively, considering the results of the function at the last time step. We can also simplify this using matrix multiplication. If we consider $\\mathbf{\\alpha}_{\\mathbf{t}}$ as a nx1 vector pertaining to each of the n states, we can calculate the following: $${\\mathbf{\\alpha}_{\\mathbf{t}}\\mathbf{= \\ E}}_{\\mathbf{.,j}} x \\mathbf{P'\\alpha}_{\\mathbf{t - 1}}$$ Where j refers to a row vector of the jth column pertaining to the observed value at time t . This can help to simplify the calculations. Here, x refers to component-wise multiplication. I have included a user-defined function to determine this probability recursively for the problem at hand: In [6]: forwardalgor <- function ( obs , trans , emissions , init ){ alphas <- list ( 1 , init * emissions[ , obs[1]] ) for ( i in 2 : ( length ( obs ) + 1 )){ alphasum <- as.numeric ( trans %*% alphas[[i]] ) alphas[[i + 1 ]] <- emissions[ , obs[i -1 ]] * alphasum } print ( \"Sequences:\" ) print ( alphas ) print ( \"Final Probability\" ) print ( sum ( alphas[ [length ( obs ) +1 ]] )) return ( sum ( alphas[ [length ( obs ) +1 ]] )) } forwardalgor ( c ( 1 , 2 , 1 , 1 , 2 , 2 , 1 , 1 ), rbind ( c ( .9 , .1 ), c ( .95 , .05 )), rbind ( c ( .5 , .5 ), c ( .25 , .75 )), c ( .5 , .5 )) [1] \"Sequences:\" [[1]] [1] 1 [[2]] [1] 0.250 0.125 [[3]] [1] 0.1187500 0.0609375 [[4]] [1] 0.05648438 0.08689453 [[5]] [1] 0.02976270 0.01450122 [[6]] [1] 0.014118274 0.007249905 [[7]] [1] 0.006715719 0.010331142 [[8]] [1] 0.003538630 0.005172367 [[9]] [1] 0.0018510021 0.0009050793 [[10]] [1] 0.0008782049 0.0004509265 [1] \"Final Probability\" [1] 0.002756081 0.00275608136978746 This gives us our result -- there is about a .2% chance of this observation being output by this particular HMM. This can be useful for numerous applications: consider if one was testing against n possible HMMs. We could then find which HMM is the more likely fit by considering $\\text{argmax}_{i}(P\\left( \\text{HMM}_{i} \\middle| x_{1},\\ \\ldots,x_{T} \\right))$. Bayes' Rule tells us that: $$P\\left( \\text{HMM}_{i} \\middle| x_{1},\\ \\ldots,x_{T} \\right) \\propto \\ P\\left( x_{1},\\ \\ldots,x_{T} \\middle| \\text{HMM}_{i} \\right)P(\\text{HMM}_{i})$$ If we consider our n models as equally likely, we can then determine which model is most probable given the observations simply by considering the likelihood in the fashion calculated above. That is, $\\operatorname{}\\left( P\\left( \\text{HMM}_{i} \\middle| x_{1},\\ \\ldots,x_{T} \\right) \\right) = \\text{argmax}_{i}(\\ P\\left( x_{1},\\ \\ldots,x_{T} \\middle| \\text{HMM}_{i} \\right))$. This relatively simple result and simple algorithm gives us a method of comparing and optimizing our fit. Also, since the probabilities here can become quite small, the fact that a logarithmic function is monotonically increasing means we can also compare the logarithms, in order to avoid machine zeros. The closely related, but not exactly equivalent, Forwards-Backwards algorithm attempts to find probability of a particular state of a particular time point given all of the observations, i.e. : $$P({\\pi_{k}|x}_{1},\\ \\ldots,x_{T})$$$$P\\left( {\\pi_{k}|x}_{1},\\ \\ldots,x_{k,\\ }x_{k + 1},\\ldots,x_{T} \\right) = \\ \\frac{P\\left( x_{k + 1},\\ldots,x_{T}|{\\pi_{k},x}_{1},\\ \\ldots,x_{k} \\right)P\\left( {\\pi_{k}|x}_{1},\\ \\ldots,x_{k} \\right)}{P\\left( x_{k + 1},\\ldots,x_{T} \\right)}$$ $$\\propto P\\left( x_{k + 1},\\ldots,x_{T}|\\pi_{k} \\right)P\\left( {\\pi_{k}|x}_{1},\\ \\ldots,x_{k} \\right)$$ This is due to the fact that $x_{k + 1},\\ldots,x_{T}$ is conditionally independent of $x_{1},\\ \\ldots,x_{k}$ given $\\pi_{k}$ and that $P\\left( x_{k + 1},\\ldots,x_{T} \\right)$ is a multiplicative constant which does not change with a selection of $\\pi_{k}$. This means we can normalize this probability at each point to ensure that $\\sum_{}&#94;{}{P\\left( {\\pi_{k}|x}_{1},\\ \\ldots,x_{k,\\ }x_{k + 1},\\ldots,x_{T} \\right) = 1}$. Notice that $P\\left( {\\pi_{k}|x}_{1},\\ \\ldots,x_{k} \\right)\\ \\propto \\ P\\left( x_{1},\\ \\ldots,x_{k},\\ \\pi_{k} \\right) = \\ \\alpha_{k}\\mathbf{(}\\pi_{k})$ as described earlier. Notice that $P\\left( x_{k + 1},\\ldots,x_{T}|\\pi_{k} \\right)$ is a similar proposition, but backwards. That is, we can call $$b_{k}(\\pi_{k})$$ $$= \\sum_{\\pi_{k + 1}}&#94;{}{P\\left( \\pi_{k + 1},x_{k + 1},\\ldots,x_{T}|\\pi_{k} \\right)}$$ $$= \\sum_{\\pi_{k + 1}}&#94;{}{P\\left( x_{k + 2},\\ldots,x_{T}|{x_{k + 1},\\pi}_{k + 1},\\pi_{k} \\right)P(x_{k + 1}|\\pi_{k + 1},\\pi_{k})P(\\pi_{k + 1}|\\pi_{k})}$$ $$= \\sum_{\\pi_{k + 1}}&#94;{}{P\\left( x_{k + 2},\\ldots,x_{T}|\\pi_{k + 1} \\right)P(x_{k + 1}|\\pi_{k + 1})P(\\pi_{k + 1}|\\pi_{k})}$$ This is obtained using the chain rule and the conditional independencies of the HMM. Notice now that $P\\left( x_{k + 2},\\ldots,x_{T}|\\pi_{k + 1} \\right) = \\ b_{k + 1}\\left( \\pi_{k + 1} \\right)$ and we can now see the recursive nature of this function. That is, $$b_{k}\\left( \\pi_{k} \\right) = \\ \\sum_{\\pi_{k + 1}}&#94;{}{b_{k + 1}\\left( \\pi_{k + 1} \\right)P(x_{k + 1}|\\pi_{k + 1})P(\\pi_{k + 1}|\\pi_{k})}$$ We take $b_{T}\\left( \\pi_{T} \\right) = 1$ for all states, as this can be considered the exit probability. Intuitively, this means that we are considering, for some intermediate time step, the probabilities of getting there from zero and the probabilities of \"back tracking\" from T. This gives us the total probability of an intermediate state based on our observations. The implementation is as follows: Compute the forward probabilities (by the previously stated algorithm) until time step k. For each step, normalize the results so that the probabilities sum to 1. Then, compute the backward probabilities from T to k. Normalize these at each step as well. Then, multiply the two results and normalize to get the probabilities of being in each state after k time steps. To calculate this, we may use the following formula: $${\\mathbf{b}_{\\mathbf{t}}\\mathbf{= \\ P(E}}_{\\mathbf{.,j}} x \\mathbf{b}_{\\mathbf{t + 1}}\\mathbf{)}$$ Notice that this is similar to the formula from before for the forwards portion, but the multiplications are \"flipped.\" Thus we can implement the Forward-Backwards algorithm as follows: In [7]: bkforwardalgor <- function ( obs , k , trans , emissions , init ) { alphas <- list ( 1 , init * emissions[ , obs[1]] / sum ( init * emissions[ , obs[1]] )) betas <- list ( rep ( 1 , nrow ( trans ))) for ( i in 3 : ( k + 1 )) { alphasum <- as.numeric ( t ( trans ) %*% alphas[[i - 1 ]] ) alphas[[i]] <- emissions[ , obs[i - 1 ]] * alphasum alphas[[i]] <- alphas[[i]] / sum ( alphas[[i]] ) } for ( i in 2 : ( length ( obs ) - k + 1 )) { betasum <- emissions[ , obs [length ( obs ) - i + 2 ]] * betas[[i - 1 ]] betas[[i]] <- as.numeric ( trans %*% betasum ) betas[[i]] <- betas[[i]] / sum ( betas[[i]] ) } pointalph <- alphas[ [ ( k + 1 ) ]] pointbet <- betas[ [ ( length ( obs ) - k + 1 ) ]] return ( list ( forward = alphas , backward = betas , probstates = pointalph * pointbet / sum ( pointalph * pointbet ))) } bkforwardalgor ( c ( 1 , 2 , 1 , 1 , 2 , 2 , 1 , 1 ), 3 , rbind ( c ( 0.9 , 0.1 ), c ( 0.95 , 0.05 )), rbind ( c ( 0.5 , 0.5 ), c ( 0.25 , 0.75 )), c ( 0.5 , 0.5 )) $forward 1 0.666666666666667 0.333333333333333 0.88 0.12 0.950682056663169 0.0493179433368311 $backward 1 1 0.493506493506494 0.506493506493506 0.493683851143735 0.506316148856265 0.50646857940524 0.49353142059476 0.505577910274165 0.494422089725835 0.493357500634704 0.506642499365296 $probstates 0.949421205954081 0.0505787940459189 So, at the third time step, we are close to 95% certain that we were in the first state (Heads), given all of the observations. This all leads us to the Baum-Welch algorithm, which is a way of estimating parameters of a HMM given a sequence of emissions. Let $\\gamma_{i}\\left( t \\right) = P\\left( \\pi_{t} \\middle| \\theta,x_{1},\\ \\ldots,x_{T} \\right)$ where $\\theta$ is the parameters of the distribution (the transition matrix, the emission matrix and the initial probabilities.) Note that we have already calculated this in the previous exercise using the forwards backwards algorithm. Further, let $$\\xi_{i,j}\\left( t \\right) = \\ P\\left( \\pi_{t}\\ ,\\pi_{t + 1}\\ \\middle| \\theta,x_{1},\\ \\ldots,x_{T} \\right) = \\frac{\\alpha_{t}\\left( \\pi_{t} = i \\right)\\mathbf{P}_{\\text{ij}}b_{t + 1}\\left( \\pi_{t + 1} = j \\right)\\mathbf{E}_{{j,x}_{t + 1}}}{\\sum_{}&#94;{}{\\alpha_{t}\\left( \\pi_{t} = i \\right)\\mathbf{P}_{\\text{ij}}b_{t + 1}\\left( \\pi_{t + 1} = j \\right)\\mathbf{E}_{{j,x}_{t + 1}}}}$$ This represents the probability of entering state i from the left, going from state i to j, exiting state j from the right, and emitting the emission at the t+1 time step from state j. All of this culminates in the joint probability of two consecutive states. Then, using an initial set of parameters we can calculate these values and update our parameters to find a local maxima. Our updates are as follows: Initial probabilities = $\\gamma_{i}\\left( 1 \\right)$. This is the expected frequency spent in state i at time 1. The new transition matrix, P' , will have entries: $$\\mathbf{P'}_{\\text{ij}} = \\frac{\\sum_{t = 1}&#94;{T - 1}{\\ \\xi_{i,j}\\left( t \\right)}\\ }{\\sum_{t = 1}&#94;{T - 1}{\\gamma_{i}\\left( t \\right)}}$$ This is the expected number of transitions from state i to j compared to the expected total number of transitions away from state i (including itself). The new emission matrix, E' , will have entries: $\\mathbf{E'}_{\\text{ij}} = \\frac{\\sum_{t = 1}&#94;{T}1_{x_{t} = j}\\gamma_{i}\\left( t \\right)}{\\sum_{t = 1}&#94;{T}{\\gamma_{i}\\left( t \\right)}}$ Where $1_{x_{t} = j}$ is an indicator function which is 1 if the emission was the jth emission and zero otherwise. This calculates the average amount of time an emission j was emitted in state i divided by the average amount of time it was in state i in general. We then iterate this process until we are within a threshold to determine the optimal parameters for the model given only an observed sequence. While I have not implemented this algorithm directly here, I have used the HMM package in R to determine this. Here is the output: In [8]: library ( HMM ) chk <- initHMM ( States = c ( \"F\" , \"B\" ), Symbols = c ( \"H\" , \"T\" ), startProbs = c ( .5 , .5 ), transProbs = rbind ( c ( .9 , .1 ), c ( .95 , .05 )), emissionProbs = rbind ( c ( .5 , .5 ), c ( .25 , .75 ))) baumWelch ( chk , c ( \"H\" , \"T\" , \"H\" , \"H\" , \"T\" , \"T\" , \"H\" , \"H\" )) $hmm $States 'F' 'B' $Symbols 'H' 'T' $startProbs F 0.5 B 0.5 $transProbs F B F 0.8356626 1.643374e-01 B 1.0000000 4.663436e-19 $emissionProbs H T F 0.530374 4.696260e-01 B 1.000000 8.442496e-29 $difference 0.508902752112227 0.240556572158092 0.175367150726267 0.125799629747644 0.0789866075573572 0.0430462501906644 0.0220242002384686 0.0120457248068965 0.00797054223724487 0.00648938284089056 0.00596923716449372 0.00573434947770014 0.00556884788402301 0.00541435766962771 0.00525534145586094 0.0050878669619669 0.00491154731418667 0.0047272548854208 0.00453636210810545 0.00434044024235019 0.00414111692008325 0.0039399973466488 0.00373861517021827 0.00353839967199841 0.00334065357605126 0.00314653876626508 0.00295706838232949 0.00277310422503745 0.00259535857201991 0.00242439957307494 0.00226065943795158 0.00210444467891964 0.00195594773481778 0.00181525938160172 0.00168238142175776 0.00155723923619973 0.00143969387155143 0.0013295534195225 0.00122658352013238 0.00113051688536663 0.00104106179381376 0.000957909549977724 0.000880740935187623 0.000809231701136347 0.000743057173680575 0.00068189604460203 0.000625433433944128 0.000573363306621804 0.000525390324947385 0.00048123121464055 0.000440615716505618 0.000403287189561262 0.000369002924884535 0.0003375342226381 0.000308666278318049 0.00028219791808662 0.000257941217349493 0.000235721031633014 0.000215374464079931 0.000196750289868947 0.000179708354205615 0.000164118957457245 0.000149862238244094 0.000136827563139715 0.000124912929580535 0.000114024387063381 0.000104075480274582 9.49867167999181e-05 8.66850610378905e-05 7.91034553396986e-05 7.21803686502851e-05 6.58593726685694e-05 6.00887450076778e-05 5.48210986672737e-05 5.00130368923791e-05 4.56248323759889e-05 4.16201296418831e-05 3.79656693828655e-05 3.46310335586279e-05 3.1588409960111e-05 2.88123750393403e-05 2.62796938294031e-05 2.39691357210852e-05 2.18613050690297e-05 1.99384854986017e-05 1.81844969456332e-05 1.65845644250734e-05 1.51251977163732e-05 1.37940810142869e-05 1.25799718653171e-05 1.14726085741031e-05 1.04626254579159e-05 9.54147526764379e-06 8.70135822614897e-06 7.93515712464892e-06 7.23637797002243e-06 6.59909573466095e-06 6.0179047717908e-06 5.48787350674592e-06 5.00450304905593e-06 Here, we see that the algorithm suggests changing the transition probabilities to almost never transition when in the Biased state, and to transition more frequently when in the fair state. It also suggests that the emission probabilities be heads nearly in all cases when it is biased. This is troublesome, since we knew (by our definition) that the emissions would be fair for the fair coin and biased otherwise. Still, this generalizes the problem and allows us to attempt to fit optimal HMMs to a given set of emissions. Using the Viterbi algorithm is known as \"decoding\" -- we are attempting to determine the most likely state sequence given a sequence of observed emissions. Determining the most likely state at a time step is known as \"filtering\" (when the step is the final step, T) or \"smoothing\" (for some intermediate step, k ). This is what the forward-backward algorithm was used for. Attempting to determine the best fitting parameters is known as \"training\". This is the motivation of the Baum-Welch algorithm. Together, these three algorithms provide the basis for many applications of the HMM model. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Markov Chains","url":"category/markov-chains/hidden-markov-models.html","loc":"category/markov-chains/hidden-markov-models.html"},{"title":"HMMs: Viterbi Algorithm","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } This investigates HMMs (Hidden Markov Models) with two possible states and six possible emissions using the viterbi algorithm. Given a Markov process with two states (state 1 and state 2) and an arbitrary number of possible observed emissions , with transition probabilities and emission probabilities given for each state, we can find the most likely sequence of states given some observed emissions. That is the goal of this exercise. This takes less time to run than considering all possible sequences of states -- we only need to consider the state probabilities forwards, rejecting paths that are unlikely at each point. The example which the following function defaults to is the case of a fair and loaded die, each with some probability of values 1-6. The roller does not show you what die he is using, but we know that he will generally switch between the two die with some transition probs. The goal is then to find the most likely sequence of fair and loaded die given the observed sequence of emissions (for example 1,2,2,1,3). In [1]: source ( './HMM_functions.R' ) observed <- c ( 6 , 5 , 1 , 1 , 6 , 6 , 4 , 5 , 3 , 1 , 3 , 2 , 6 , 5 , 1 , 2 , 4 , 5 , 3 , 6 , 6 , 6 , 4 , 6 , 3 , 1 , 6 , 3 , 6 , 6 , 6 , 3 , 1 , 6 , 2 , 3 , 2 , 6 , 4 , 5 , 5 , 2 , 3 , 6 , 2 , 6 , 6 , 6 , 6 , 6 , 6 , 2 , 5 , 1 , 5 , 1 , 6 , 3 , 1 ) results <- viterbialgorithm ( observed ) resultswords <- c ( \"Fair\" , \"Loaded\" ) [results $ path] resultswords 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Loaded' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' 'Fair' So this tells us that given the observed die rolls, the most likely sequence of states is as shown above. This did not have to be done manually -- we can use the HMM package to do this. It will serve as a check. In [4]: require ( HMM ) mod <- initHMM ( c ( \"Fair\" , \"Loaded\" ), c ( 1 , 2 , 3 , 4 , 5 , 6 ), startProbs = c ( .5 , .5 ), transProbs = rbind ( c ( .95 , .05 ), c ( .1 , .90 )), emissionProbs = rbind ( c ( rep ( 1 / 6 , 6 )), c ( rep ( 1 / 10 , 5 ), 1 / 2 ))) viterbi ( mod , observed ) == resultswords ## :) TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE In [ ]: if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Markov Chains","url":"category/markov-chains/hmms-viterbi-algorithm.html","loc":"category/markov-chains/hmms-viterbi-algorithm.html"},{"title":"Hotelling's T-Test Example","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Here's an example of the Hotelling's MV T-test with responses and hypothesized means. In [ ]: source ( './hotellings_functions.R' ) response_data <- matrix ( c ( 51 , 27 , 37 , 42 , 27 , 43 , 41 , 38 , 36 , 26 , 29 , 36 , 20 , 22 , 36 , 18 , 32 , 22 , 21 , 23 , 31 , 20 , 50 , 26 , 41 , 32 , 33 , 43 , 36 , 31 , 27 , 31 , 25 , 35 , 17 , 37 , 34 , 14 , 35 , 25 , 20 , 25 , 32 , 26 , 42 , 27 , 30 , 27 , 29 , 40 , 38 , 16 , 28 , 36 , 25 ), ncol = 5 ) hypothesized_mean <- c ( 30 , 25 , 40 , 25 , 30 ) response_data prob_null ( response_data , hypothesized_mean ) find_discriminant ( response_data , hypothesized_mean ) From this, because the p value is less than .05, we reject the hypothesis that this data comes from a normally distributed population with mean vector 30, 25, 40, 25, 30. The discriminant indicates that the third variable contributes most to the difference between the hypothesized and sample mean. In [ ]: require ( MASS ) ex <- mvrnorm ( 11 , mu = hypothesized_mean , Sigma = cov ( response_data )) prob_null ( ex , hypothesized_mean ) find_discriminant ( ex , hypothesized_mean ) Now we see that a multivariate normal distribution sampled with mean equal to the hypothesized mean and Sigma equal to the covariance of the observed data provides unsignificant results -- as expected. Now, let's see the t-test for the equality of means, assuming an equal covariance matrix and sample sizes. In [ ]: differences <- response_data - ex prob_null ( differences , rep ( 0 , 5 )) find_discriminant ( differences , rep ( 0 , 5 )) We see the expected result: that the two samples produce significant results -- meaning that there is evidence to reject the null hypothesis that they come from a distribution with the same mean vector. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Multivariate Analysis","url":"category/multivariate-analysis/hotellings-t-test-example.html","loc":"category/multivariate-analysis/hotellings-t-test-example.html"},{"title":"To T-Test or Not to T-Test","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } In [1]: test_equality_means <- function ( norm_vec1 , norm_vec2 ){ sx <- var ( norm_vec1 ) sy <- var ( norm_vec2 ) xbar <- mean ( norm_vec1 ) ybar <- mean ( norm_vec2 ) n = length ( norm_vec1 ) m = length ( norm_vec2 ) tstat <- ( xbar - ybar ) / ( sqrt (( 1 / n + 1 / m ) * (( n - 1 ) * sx + ( m - 1 ) * sy ) / ( n + m - 2 ))) p_tstat <- pt ( tstat , n + m - 2 ) return ( list ( tstat = tstat , prob = p_tstat )) } simulatepostprob <- function ( vec , prior_params = c ( n = 0 , S = 0 , k = -1 , B = 0 )){ nnew = prior_params[ 'n' ] Snew = prior_params[ 'S' ] knew = prior_params[ 'k' ] Bnew = prior_params[ 'B' ] lst <- list () for ( i in 1 : length ( vec )) { obs <- vec[i] ninit = nnew Binit = Bnew Sinit = Snew kinit = knew knew = kinit + 1 nnew = ninit + 1 Bnew <- ( ninit * Binit + obs ) / nnew Snew <- Sinit + ninit * Binit&#94;2 + obs&#94;2 - nnew * Bnew&#94;2 if ( knew == 0 ) { sampchi <- 0 sigma <- 0 } else { ## We randomly sample a value for sigma|x first sampchi <- sum ( rnorm ( knew , 0 , 1 ) &#94;2 ) sigma <- sqrt ( Snew / sampchi ) } ## Using sigma, we sample for mu|x, sigma. mu <- rnorm ( 1 , obs + Bnew , sigma / sqrt ( nnew )) lst[[i]] <- mu } return ( unlist ( lst )) } rpost <- function ( n , vec , prior_params = c ( n = 0 , S = 0 , k = -1 , B = 0 )){ replicate ( n , expr = simulatepostprob ( vec ) [length ( vec ) ] ) } Standard T-Test Consider the t-test of equality of means. Using the standard procedure for a t-test: In [2]: vec1 <- c ( 120 , 107 , 110 , 116 , 114 , 111 , 113 , 117 , 114 , 112 ) vec2 <- c ( 110 , 111 , 107 , 108 , 110 , 105 , 107 , 106 , 111 , 111 ) t_test_res = test_equality_means ( vec1 , vec2 ) t_test_res $tstat 3.48432421316996 $prob 0.998676366290831 We can see that the t-test gives us a significant result -- the two means would have a difference smaller than the observed difference with probability r t_test_res$prob . We then would reject the null hypothesis with 95% confidence (or even 99% confidence.) Bayesian Approach Now let's try to solve this problem with our Bayesian hats! Assuming that we have a prior distribution of $\\mu$ and $\\sigma&#94;2$ such that $x \\mid \\mu, \\sigma&#94;2 \\sim N(\\mu, \\sigma&#94;2)$ , we want the posterior $f(\\mu \\mid x_1, x_2, ..., x_n, \\sigma&#94;2)$ . Assuming a prior of $\\mu \\mid \\sigma&#94;2 \\sim N(\\beta, \\frac{\\sigma}{\\sqrt{n}})$ and $\\frac{S}{\\sigma&#94;2} \\sim \\chi&#94;2(k)$, we start with prior parameters $\\beta_0, n, S_0, k$ and update for each value of x. In [3]: simulatepostprob ( vec = vec1 ) - simulatepostprob ( vec = vec2 ) 20 -0.503416712324565 1.45988251782074 17.6073011837844 7.22926620488519 9.24411515038176 8.35747543643981 15.4506594648444 8.61721035342939 6.22213384120991 By iterating for each observation, we arrive at a posterior distribution for $\\mu \\mid \\sigma&#94;2$ and $\\frac{S}{\\sigma&#94;2}$. We then sample randomly from these theoretical distributions to sample from the posterior distributions. If we replicate this many times, we will be able to estimate the differences between the posterior distributions of the two vectors. Using uninformative prior gives similar results to frequentist t-test method In [4]: sum ( rpost ( 1000 , vec1 ) > rpost ( 1000 , vec2 )) / 1000 0.999 We can then use our prior information about the sample to produce a mixed, updated result. For instance, with prior parameters: In [5]: prior_params = c ( n = 10 , S = 2 , k = 9 , B = 30 ) We can see our posterior: In [6]: sum ( rpost ( 1000 , vec1 , prior_params ) > rpost ( 1000 , vec2 , prior_params )) / 1000 0.999 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Bayesian Analysis","url":"category/bayesian-analysis/t test or not t test.html","loc":"category/bayesian-analysis/t test or not t test.html"},{"title":"Bayesian Analysis: Poisson Discrete","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } In [4]: ## Poisson Discrete Updater ## Basic Bayesian analysis on discrete random variables. ## Given our data follows a Poisson distribution, finds the probability of various ## lambdas given an observed value using discrete probabilities for discrete lambda values. ## In this case I have generalized this to where lambda_new = lambda * t where t is the number of days. ## Consider that the number of events, k, in t days follows a Poisson distribution with lambda = t*l. ## For example, consider that the number of accidents in t days is distributed Poisson(t*l) ## Given prior beliefs about various l values (can be seen as the daily rate), we find the posterior distribution ## of these lambdas given new information. # Variables: ## pos_lambda (vector): a vector of hypothesized lambdas to check in posterior distribution. ## prior_probs (vector): a vector of prior probabilities for the hypothesized lambdas ## X (dataframe): a dataframe of new observed values, where the first column is the total number of events and t is the ## total number of days. For instance k=4, t=2 means there were two accidents per day, or 4 accidents in two days. k is the first column and t ## the second. ManualPoisson <- function ( k , t , l ){ # Same as dpois(x=k,lambda = l*t), or explictly return ((( t * l ) &#94; k ) * exp ( - t * l ) / factorial ( k )) } PosteriorFinder <- function ( k , t , plam , pp ){ # Finds the posterior and multiplicative constant for given probabilities and values. const <- sum ( mapply ( function ( l , p ) ManualPoisson ( k , t , l ) * p , plam , pp )) post <- mapply ( function ( l , p ) ManualPoisson ( k , t , l ) * p / const , plam , pp ) return ( list ( const = const , post = post )) } find_posterior <- function ( pos_lambda , prior_probs , X ){ ## sanity checks if ( sum ( pos_lambda > 0 ) != length ( pos_lambda )) { stop ( \"Lambdas must all be greater than zero.\" ) } if ( sum ( prior_probs ) != 1 ) { stop ( 'Priors must sum to 1, as they are probabilities.' ) } if ( ncol ( X ) != 2 ) { stop ( \"X can only have two columns (number of incidents and time)\" ) } if ( length ( pos_lambda ) != length ( prior_probs )) { stop ( \"The lambda vector and probability vector must be the same length.\" ) } ## Initialize probabilities as prior probabilities. probs <- prior_probs # Updates the posteriors for each observed value for ( i in nrow ( X )) { k <- X [ i , 1 ] t <- X [ i , 2 ] probs <- PosteriorFinder ( k , t , pos_lambda , probs ) $ post } posterior = probs return ( posterior ) } Example : Allergic Reactions Example: Consider that we believe that people in most counties will have a severe allergic reaction around 1.5 times per day. We have an expert who has just moved to XYZ county who thinks that this is not the case in the county. He wants to test this hypothesis on stretches of the last two weeks, where he believes we have seen a lower number of alergic reactions. (There was 12 incidents in the first 6 days, and zero in the last seven) Suppose that we know (by some empirical estimation) that counties in the US approximately have probabilities .1,.2,.3,.2,.15,.05 of their rates being .5,1,1.5,2,2.5,4 respectively. We believe that the distribution of the number of severe alergic reactions follows a Poisson distribution with rate lambda. That is, the rate is constant in a given county, and each event occurs independently of one another (i.e., one person having an alergic reaction does not effect the probability of another having one). Given these assumptions, we want to check the probability of the rates given our new data. In [5]: poslam_example <- c ( . 5 , 1 , 1.5 , 2 , 2.5 , 4 ) probs_example <- c ( . 1 , . 2 , . 3 , . 2 , . 15 , . 05 ) X_example <- data . frame ( k = c ( 12 , 6 ), t = c ( 0 , 7 )) find_posterior ( poslam_example , probs_example , X_example ) 0.14075345211024 0.544049403057648 0.280702619102117 0.031750965697214 0.00274313760334297 4.22429437384091e-07 What is the conclusion? The expert seems to be on to something -- there appears to be more evidence at the current time that lambda is actually 1 rather than 1.5. More trials would find tune this result further. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Bayesian Analysis","url":"category/bayesian-analysis/Poisson Discrete.html","loc":"category/bayesian-analysis/Poisson Discrete.html"},{"title":"Bayesian Analysis: Binomial Discrete","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } A Simple Illustration of Bayesian Probability with a Binomial Distribution Suppose we have a discrete set of possible probabilities $q$ of an event E with some prior beliefs about which probability is the true probability of the event E. That is, we have a probability mass function that takes discrete values within $q$ and maps them to a discrete probability space, where $$ P(p=w) = 0, \\forall{w \\notin q} $$$$ \\sum_{w}{P(p=w)} = 1, w \\in q $$ We then observe some independent events and wish to update our prior beliefs accordingly. We observe $k$ occurences over $n$ trials, and wish to update our probabilities accordingly. From Bayes' Rule, we know that $$ P(p=w | k, n) = \\frac{P(k, n | p=w)P(p=w)}{P(k, n)} $$ We can now use this information to calculate our posterior of $p$ by using the fact that independent events occuring with some probability $p$ follow a Bernoulli distribution, and so the total number of events follow a binomial distribution. Using this for $P(X|p=w)$, we can now solve for our posterior for each defined value of p. This is implemented below: Code to Find Posterior Distribution Given Binomial Prior In [1]: ## Finds posterior distribution of observed values assuming that k follows a binomial distribution. p is discrete in this case. numerator <- function ( k , n , posprobs , probsofprobs ){ ## finds the numerator -- ie P(k|p)P(p) ## k (integer) : the total number of observed successes. ## n (integer) : the total number of observed trials. ## posprobs (vector): possible p values associated with the random variable k. ## probsofprobs (vector): this is our prior, mapping a probability to each possible probability function ( p ){ ## For a particular p, this will find the posterior probability of p given observed values. This is a function generator -- given ## values of k and n, we can then find the probability of any particular p. x <- posprobs[p] px <- probsofprobs[p] res <- ( x&#94;k ) * (( 1 - x ) &#94; ( n - k )) * px return ( res ) } } denominator <- function ( k , n , posprobs , probsofprobs ){ ## Finds the denominator, the multiplicative constant. Same for all values of p. P(k) sum ( sapply ( X = 1 : length ( posprobs ), FUN = numerator ( k , n , posprobs , probsofprobs ))) } probabilityfinder <- function ( k , n , p , posprobs , probsofprobs ){ ## Finds the posterior probability of a particular p value. numerator ( k , n , posprobs , probsofprobs )( p ) / denominator ( k , n , posprobs , probsofprobs ) } posterior <- function ( k , n , posprobs , probsofprobs ){ ## Finds the posterior probability mass function of the p values. sapply ( X = 1 : length ( posprobs ), FUN = function ( p ) probabilityfinder ( k , n , p , posprobs , probsofprobs )) } log_transf_numerator <- function ( k , n ){ ## finds the numerator -- ie P(k|p)P(p), using log transform to avoid machine zeros ## k (integer) : the total number of observed successes. ## n (integer) : the total number of observed trials. ## posprobs (vector): possible p values associated with the random variable k. ## probsofprobs (vector): this is our prior, mapping a probability to each possible probability function ( p ){ ## For a particular p, this will find the posterior probability of p given observed values. This is a function generator -- given ## values of k and n, we can then find the probability of any particular p. x <- posprobs[p] px <- probsofprobs[p] mx <- max ( sapply ( posprobs , function ( pr ) k * log ( pr ) + ( n - k ) * log ( 1 - pr ))) res <- exp ( k * log ( x ) + ( n - k ) * log ( 1 - x ) - mx ) * probsofprobs[p] return ( res ) } } log_transf_denominator <- function ( k , n ){ ## Finds the denominator, the multiplicative constant, using log transform for machine zeros. Same for all values of p. P(k) sum ( sapply ( X = 1 : length ( posprobs ), FUN = log_transf_numerator ( k , n ))) } log_transf_probabilitydist <- function ( k , n , p ){ ## Finds the posterior probability of a particular p value using log transform. log_transf_numerator ( k , n )( p ) / log_transf_denominator ( k , n ) } log_transf_posterior <- function ( k , n ){ ## Finds the posterior probability mass function of the p values using log transform sapply ( X = 1 : length ( posprobs ), FUN = function ( x ) log_transf_probabilitydist ( k , n , x )) } Example: Thunderstorms Consider if we observed 11 positive events in 27 days -- as an example, the number of thunderstorms in a month. We want to estimate the probability of a thunderstorm given the new information. Assuming weather each day is independent (which is a simplifying assumption), we can assume that the number of thunderstorms in $n$ days can be modeled by a binomial distribution. If we believe prior to this that the distribution looks as it does below (with the highest belief in 35 and 45%), we can now find the posterior of the probabilities after observing the 11 thunderstorms as follows: In [2]: posprobs <- c ( .05 , .15 , .25 , .35 , .45 , .55 , .65 , .75 , .85 , .95 ) probsofprobs <- c ( .07 , .13 , .26 , .26 , .13 , .07 , .02 , .02 , .02 , .02 ) pos <- posterior ( 11 , 27 , posprobs , probsofprobs ) round ( pos , 3 ) 0 0.002 0.128 0.524 0.287 0.057 0.002 0 0 0 So we now believe with 0.524 probability that the actual p value is .35. This means the data supports the assumption of .35 chance of thunderstorms a day, given our prior beliefs and the independence of events. Behaviors for different $n$ and $k$ Now, let us investigate the behaviors for various sample sizes, $n$, and number of observed thunderstorms $k$. In [3]: n <- c ( 10 , 50 , 100 , 150 , 200 , 300 , 500 ) k <- lapply ( n , function ( n ) seq ( n / 10 , n , n / 10 )) col_names = as.character ( 1 : 10 / 10 ) row_names = paste ( 'P(p=' , posprobs , ')' ) list_names = paste ( 'n=' , n ) iter_j = 1 : 10 ; names ( iter_j ) = col_names iter_i = 1 : 7 ; names ( iter_i ) = list_names dimthreedfs = lapply ( iter_i , function ( i ) data.frame ( sapply ( iter_j , function ( j ) posterior ( k[[i]][j] , n[i] , posprobs , probsofprobs )))) In [4]: dimthreedfs = lapply ( dimthreedfs , function ( y ) round ( y , 3 )) In [5]: dimthreedfs $`n= 10` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.160 0.030 0.004 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.328 0.209 0.096 0.035 0.010 0.002 0.000 0.000 0.000 0.000 0.354 0.427 0.371 0.255 0.141 0.062 0.020 0.004 0.000 0.000 0.137 0.266 0.373 0.415 0.372 0.263 0.136 0.043 0.006 0.000 0.020 0.058 0.123 0.208 0.283 0.304 0.239 0.116 0.026 0.003 0.002 0.009 0.030 0.075 0.152 0.245 0.287 0.208 0.070 0.010 0.000 0.000 0.002 0.009 0.029 0.070 0.124 0.137 0.070 0.015 0.000 0.000 0.000 0.002 0.011 0.043 0.123 0.219 0.182 0.064 0.000 0.000 0.000 0.000 0.002 0.012 0.064 0.215 0.338 0.225 0.000 0.000 0.000 0.000 0.000 0.000 0.005 0.058 0.306 0.683 $`n= 50` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.232 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.703 0.292 0.009 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.065 0.646 0.471 0.054 0.001 0.000 0.000 0.000 0.000 0.000 0.001 0.061 0.489 0.613 0.135 0.005 0.000 0.000 0.000 0.000 0.000 0.000 0.031 0.311 0.555 0.160 0.006 0.000 0.000 0.000 0.000 0.000 0.000 0.023 0.299 0.640 0.179 0.003 0.000 0.000 0.000 0.000 0.000 0.000 0.010 0.180 0.408 0.047 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.016 0.392 0.499 0.028 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.015 0.451 0.602 0.004 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.370 0.996 $`n= 100` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.168 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0 0.828 0.288 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0 0.004 0.706 0.479 0.005 0.000 0.000 0.000 0.000 0.000 0 0.000 0.006 0.517 0.655 0.019 0.000 0.000 0.000 0.000 0 0.000 0.000 0.004 0.337 0.637 0.026 0.000 0.000 0.000 0 0.000 0.000 0.000 0.003 0.343 0.762 0.028 0.000 0.000 0 0.000 0.000 0.000 0.000 0.001 0.211 0.505 0.005 0.000 0 0.000 0.000 0.000 0.000 0.000 0.002 0.467 0.548 0.002 0 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.447 0.725 0 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.273 1 $`n= 150` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.111 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0 0.889 0.269 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0 0.000 0.730 0.471 0.000 0.000 0.000 0.000 0.000 0.000 0 0.000 0.001 0.529 0.656 0.002 0.000 0.000 0.000 0.000 0 0.000 0.000 0.001 0.343 0.648 0.004 0.000 0.000 0.000 0 0.000 0.000 0.000 0.000 0.349 0.782 0.004 0.000 0.000 0 0.000 0.000 0.000 0.000 0.000 0.214 0.527 0.000 0.000 0 0.000 0.000 0.000 0.000 0.000 0.000 0.469 0.575 0.000 0 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.424 0.812 0 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.188 1 $`n= 200` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.071 0.00 0.000 0.000 0.00 0.000 0.000 0.0 0.000 0 0.929 0.25 0.000 0.000 0.00 0.000 0.000 0.0 0.000 0 0.000 0.75 0.461 0.000 0.00 0.000 0.000 0.0 0.000 0 0.000 0.00 0.538 0.653 0.00 0.000 0.000 0.0 0.000 0 0.000 0.00 0.000 0.346 0.65 0.000 0.000 0.0 0.000 0 0.000 0.00 0.000 0.000 0.35 0.787 0.000 0.0 0.000 0 0.000 0.00 0.000 0.000 0.00 0.212 0.538 0.0 0.000 0 0.000 0.00 0.000 0.000 0.00 0.000 0.461 0.6 0.000 0 0.000 0.00 0.000 0.000 0.00 0.000 0.000 0.4 0.876 0 0.000 0.00 0.000 0.000 0.00 0.000 0.000 0.0 0.124 1 $`n= 300` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.028 0.000 0.000 0.000 0.00 0.000 0.000 0.000 0.000 0 0.972 0.214 0.000 0.000 0.00 0.000 0.000 0.000 0.000 0 0.000 0.786 0.442 0.000 0.00 0.000 0.000 0.000 0.000 0 0.000 0.000 0.558 0.647 0.00 0.000 0.000 0.000 0.000 0 0.000 0.000 0.000 0.353 0.65 0.000 0.000 0.000 0.000 0 0.000 0.000 0.000 0.000 0.35 0.793 0.000 0.000 0.000 0 0.000 0.000 0.000 0.000 0.00 0.207 0.558 0.000 0.000 0 0.000 0.000 0.000 0.000 0.00 0.000 0.442 0.648 0.000 0 0.000 0.000 0.000 0.000 0.00 0.000 0.000 0.352 0.949 0 0.000 0.000 0.000 0.000 0.00 0.000 0.000 0.000 0.051 1 $`n= 500` X0.1 X0.2 X0.3 X0.4 X0.5 X0.6 X0.7 X0.8 X0.9 X1 0.004 0.000 0.000 0.000 0.00 0.000 0.000 0.000 0.000 0 0.996 0.153 0.000 0.000 0.00 0.000 0.000 0.000 0.000 0 0.000 0.847 0.405 0.000 0.00 0.000 0.000 0.000 0.000 0 0.000 0.000 0.595 0.633 0.00 0.000 0.000 0.000 0.000 0 0.000 0.000 0.000 0.367 0.65 0.000 0.000 0.000 0.000 0 0.000 0.000 0.000 0.000 0.35 0.802 0.000 0.000 0.000 0 0.000 0.000 0.000 0.000 0.00 0.198 0.595 0.000 0.000 0 0.000 0.000 0.000 0.000 0.00 0.000 0.405 0.734 0.000 0 0.000 0.000 0.000 0.000 0.00 0.000 0.000 0.266 0.992 0 0.000 0.000 0.000 0.000 0.00 0.000 0.000 0.000 0.008 1 In [6]: library ( ggplot2 ) library ( reshape2 ) create_gg_heatmap <- function ( df ){ mat = as.matrix ( df ) melted = melt ( mat ) plt = ggplot ( data = melted , aes ( x = Var1 , y = Var2 , fill = value )) + geom_tile () + scale_fill_gradientn ( limits = c ( 0 , 1 ), colors = c ( \"navyblue\" , \"darkmagenta\" , \"darkorange1\" )) return ( plt ) } In [7]: sapply ( dimthreedfs , create_gg_heatmap , simplify = FALSE , USE.NAMES = FALSE ) $`n= 10` $`n= 50` $`n= 100` $`n= 150` $`n= 200` $`n= 300` $`n= 500` Each list represents $n$ for $n \\in \\{10, 50, 100, 150, 200, 300, 500\\}$, and each column represents possible $k$ values from $\\frac{n}{10}$ to $n$. The heatmaps shows us that the probabilities become more polarized as $n$ increases, which is what we would expect. We see that with small $n$ the colors are fuzzy, reflecting our uncertainty concerning our estimate. We see what is expected with Bayesian probabilities: as $n$ increases, our confidence in our posterior probability becomes stronger. This is reflected in the fact that we get values that are nearly 1 for the observations which have p = k/n and 0 otherwise. This shows that as we get more observations, the data will overwhelm the prior. For small values of $n$, we see the opposite: it is highly skewed by our prior, so that we are not so confident that $p$ = $\\frac{k}{n}$ if $p$ was not deemed probable prior. Machine Zeros problem: In [8]: posterior ( 1000 , 2000 , posprobs , probsofprobs ) NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN Notice that we have many machine zeros for large n. This interferes with our calculations, and gives us NaNs for the calculations. The following uses a log transformation to avoid machine zeros: In [9]: posterior ( 1000 , 2000 , posprobs , probsofprobs ) log_transf_posterior ( 1000 , 2000 ) NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 0 5.59622100226468e-289 3.46746548211335e-121 3.31238703307168e-37 0.650000000000052 0.349999999999948 2.54799002543976e-38 2.66728114008719e-122 8.60957077271489e-290 0 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Bayesian Analysis","url":"category/bayesian-analysis/Binomial Discrete.html","loc":"category/bayesian-analysis/Binomial Discrete.html"},{"title":"Approaches to Contingency Tables","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Chi-Squared Test Here we will be investigating a few ways of dealing with contingency tables. The first two are standard procedures in frequentist statistics, the chi-squared test and the Fischer's Exact test. Consider a contingency table that looks like this: In [4]: row_names = c ( 'Has traveled outside US' , 'Has not traveled outside US' ) column_names = c ( 'Non-Artist' , 'Artist' ) cont_table <- matrix ( c ( 5 , 15 , 30 , 20 ), nrow = 2 , dimnames = list ( row_names , column_names )) cont_table Non-Artist Artist Has traveled outside US 5 30 Has not traveled outside US 15 20 Consider if we ask the question -- are artists and non-artists equally likely to travel outside of the US...? The first approach we can take is the chi-squared test, which is an asymptotically accurate. If each was equally likely to travel, we would expect a cont_table like this : In [7]: cont_table_exp <- matrix ( c ( 10 , 10 , 25 , 25 ), nrow = 2 , dimnames = list ( row_names , column_names )) cont_table_exp Non-Artist Artist Has traveled outside US 10 25 Has not traveled outside US 10 25 If we assume that artistry and travel likelihood are independent, our sum of the differences from this expectation divided by the square root of the expectation should be roughly normally distributed and so the squared differences will be approximately $\\chi &#94;{2}\\left ( 1 \\right )$. Here, we assume that the observed counts are Poisson distributed, so that their expectation and variance are defined by $E_{i}$ and $\\frac{1}{\\sqrt{E_{i}}}$. As $n \\to \\infty$, this is asymptotically normal GIVEN the hypothesis of independence. Because we know the row and column totals, in this case we have a degree of freedom of 1 -- when one value is known on this contingency table, given the row and column totals we can deduce the others. In order to calculate an (approximate) probability of this example given independence (the null hypothesis), we perform the following calculation. In [8]: zsq <- sum (( cont_table - cont_table_exp ) &#94;2 / cont_table_exp ) 1 - pchisq ( zsq , 1 ) 0.00815097159350264 So we would reject the notion of independence based on these observations. More generally: In [15]: chi_squared_test <- function ( cont_table , cont_table_exp = NULL ){ if ( cont_table_exp == NULL ) { cont_table_exp = t ( as.matrix ( rep ( apply ( cont_table , 2 , mean )))) } cont_table_exp df <- ( nrow ( cont_table ) - 1 ) * ( ncol ( cont_table ) - 1 ) zsq <- sum (( cont_table - cont_table_exp ) &#94;2 / cont_table_exp ) probability <- 1 - pchisq ( zsq , df ) return ( probability ) } Fischer Exact Test However, the chi-squared test is only asympotically accurate. If we consider the counts to be distributed as a hyper-geometric distribution, we can use Fisher's Exact Test to calculate the probability of independence. Given some values in the contingency table, the probability of any distribution of values given independence is as follows: In [16]: probfun <- function ( i , j , n , m ){ # i: particular coordinate (for instance, non-artist, has not traveled) # j: the column total for the particular coordinate (for instance, non-artists) # n: the row total for particular coordinate (for instance, people who have traveled) # m: the row total for the other coordinate (for instance, people who have not traveled) choose ( m , i ) * choose ( n ,( j - i )) / choose ( m + n , j ) } This will give us the exact probability of each coordinate. If we wanted to find the probability that non-artist, people who traveled is less than or equal to five, we would do the following in this case: In [17]: sum ( sapply ( 0 : 5 , function ( x ) probfun ( x , 20 , 35 , 35 ))) 0.008027370811152 This shows that the probability of what we have observed is quite small if the columns and rows are independent. We again reject independence with 1% significance. The results of this test and the chisquared test are also quite close, which is as expected. As n goes to infinity, the chisquared test converges to the Fischer's Exact test. This is the hyper geometric distribution, which is included in R. The results are the same: In [18]: phyper ( 5 , 35 , 35 , 20 ) ##same result 0.00802737081115199 These are well known tests we can make. However, we can add some bayesian analysis to the mix here! Bayesian Approach -- using Beta distributions Let us assume that the probability of having traveled for artists and non-artists can be modeled using a Beta distribution. That is [P(travel \\mid nonartist) = p \\sim \\ {Beta}(\\alpha {1}, \\beta {1})] and [P(travel \\mid artist) = q \\sim \\ {Beta}(\\alpha {2}, \\beta {2})] We can now make an approximation to determine the probability that $p < q$. That is, we want the posterior distribution of $p$ and $q$ given our contingency table. Because our likelihood is multinomial, we know that the posterior distribution is also Beta distributed. After doing some manipulations, we can write the posterior distribution of $p$ and $q$. If we assume uninformative priors, we set $\\alpha = \\beta = 1$ to get the following: In [50]: posteriorb <- function ( p , q , cont_table , num = FALSE ){ if ( num == TRUE ) { if ( p >= q ) { return ( 0 ) } } obs_row_totals = apply ( cont_table , 1 , sum ) obs_coordinates = c ( cont_table ) obs_rows_w_prior = cont_table - 1 constant <- ( prod ( gamma ( obs_row_totals )) / ( prod ( gamma ( obs_coordinates )))) p_mat <- matrix ( c ( p , q , 1 - p , 1 - q ), nrow = 2 ) ret <- constant * ( prod ( p_mat &#94; obs_rows_w_prior )) return ( ret ) } Note that this will only work for 2x2 contingency tables and assuming an (invalid) prior of $\\alpha = \\beta = 1$ for each prior. If we wanted to include prior information, we could change these for each prior, which would result in a different number being added/subtracted above. This joint distribution is somewhat difficult to determine analytically. There are alternative here to estimate this probability (gtools, MCMCpack, etc), but I have included a numerical approximation. In [53]: approx <- function ( f , num = FALSE , ... ) { sum ( sapply ( seq ( 0.01 , 0.99 , 0.01 ), function ( p ) sapply ( seq ( 0.01 , 0.99 , 0.01 ), function ( q ) f ( p , q , num , ... )))) } estim <- approx ( posteriorb , TRUE , cont_table = cont_table ) / approx ( posteriorb , cont_table = cont_table ) estim 0.996557074981106 We estimate ${P}(p< q) = .9966$. Here, we individual values of p,q and compare their pdf evaluations at each point. Bayesian Approach -- Assuming Dependence Structure Let's use another formulation that allows $p$ and $q$ to depend on one another. That is, it is unlikely that $p$ and $q$ are distributed independently -- there is an underlying 'willing to travel' factor that is prevalent in both groups. We saw this when we considered the earlier tests. If we assume then that $\\ln \\frac{p}{1-p} - \\ln \\frac{q}{1-q}$, the difference in their log odds ratios is normally distributed with mean 0 and some arbitrary variance, we are allowing for some dependencies based on the value of sigma squared that we select. Selecting a small value of sigmasquared introduces a higher dependency structure. We can then test, for a certain level of expected variance in their difference, whether they are independent or not. In [42]: posteriorc <- function ( p , q , cont_table , num = FALSE , sigmasq = 1 ){ if ( num == TRUE ) { if ( p >= q ) { return ( 0 ) } } obs_rows_w_prior = cont_table - 1 logit1 <- log (( p / ( 1 - p ))) logit2 <- log (( q / ( 1 - q ))) expo <- exp (( - ( logit1 - logit2 ) &#94;2 ) / ( 2 * sigmasq )) p_mat <- matrix ( c ( p , q , 1 - p , 1 - q ), nrow = 2 ) ret <- expo * prod (( p_mat &#94; obs_rows_w_prior )) return ( ret ) } We then approximate ${P}(p< q)$ given various assumed sigmas in the prior. In [52]: estimb1 <- approx ( posteriorc , num = TRUE , cont_table = cont_table , sigmasq = 1 ) / approx ( posteriorc , num = FALSE , cont_table = cont_table , sigmasq = 1 ) estimb2 <- approx ( posteriorc , num = TRUE , cont_table = cont_table , sigmasq = 0.25 ) / approx ( posteriorc , num = FALSE , cont_table = cont_table , sigmasq = 0.25 ) estimb3 <- approx ( posteriorc , num = TRUE , cont_table = cont_table , sigmasq = 4 ) / approx ( posteriorc , num = FALSE , cont_table = cont_table , sigmasq = 4 ) # sigmasq = 1 estimb1 # sigmasq = .25 estimb2 # sigma sq = 4 estimb3 # sigma sq = 400000 (close to complete independence) approx ( posteriorc , num = TRUE , cont_table = cont_table , sigmasq = 4e+05 ) / approx ( posteriorc , num = FALSE , cont_table = cont_table , sigmasq = 4e+05 ) 0.990231766938391 0.961061419233541 0.995239851507228 0.996557062782334 We see that the larger the variance, the higher ${P}(p< q)$ is. When we condsidered them to be independent, we got an estimate of .9965571. It makes sense, then, that as we increase the variance, and therefore the two become closer to being what we would consider as independent from one another, it approaches the value when they are assumed to be independent explicitly. Considering them to have a small variance (.25) will lead to the probability p < q to be smaller than any other method, including the chisquare and Fischer Exact test. When we have a high variance (even at sigma sq = 4), we obtain a higher probability that the two probabilities are different. The conclusion then is that the two groups are different from one another. When the variance is small, we are less confident that the two groups are different from one another, both in prior and posterior distribution. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Bayesian Analysis","url":"category/bayesian-analysis/Approaches to Contingency Tables.html","loc":"category/bayesian-analysis/Approaches to Contingency Tables.html"},{"title":"Factor Analysis","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Introduction Note: All of the code associated with this project can be found on my GitHub repository located here . What are the core factors of human personality? It's a hard question to answer! Data doesn't give us a direct answer to this question -- we may, using some sort of model , be able to determine how individuals are clustered into groups based on their responses to surveys. This is an example of unsupervised learning . We can use this information to cluser similar people together, and infer that they have similar personalities based on this. However, what we really want to know when we answer this question may be things that data cannot tell us. For example, what kinds of questions pertain to aggression? Introversion? Reliability? We can determine clusters of similar behaviors -- for instance, the answer to the questions \"Do you enjoy parties?\" and \"Do you have a large social network?\" will likely be correlated , so we may believe that these are influenced by some factor called extroversion. Most of the time, however, we do not model these explicitly -- we only wish to cluster individuals together, to make predictions of some measure (say, a happiness score), or make inferences about the questions themselves. For instance, people who answered question A and B in a certain way are likely to be similar to others in their responses to questions. This distinction is important -- we can speculate that there is some unknown factor involved, but it is not necessarily the case. In clustering algorithms like K-Means, SVD, LDA and Gaussian Mixture Models, we do not concern ourselves with what the actual underlying factors actually are -- we only use them as a way to categorize the data in order to make inferences or to predict another variable of interest. We can see that these approaches are data-driven . We assume that the data contains relevant information by which we can group people together. But does this truly answer the question we wish to solve? In most cases, the answer is no, at least not explicitly. Factor Analysis attempts to model these underlying constructs explicitly. In this way, it is hypothesis driven , i.e., we model for the hypothesis we wish to verify or reject. Hypothesis testing is a common exercise in Statistics, but in this case our hypothesis is quite specific -- we hyptohesize that there are some unknown, unseen, unobservable factors underlying the patterns we see. It is for this reason that is particularly controversial -- who is to say that such factors even exist, and if they do, how can we categorize them in abstract terms? This is an open ended question -- but factor analysis can begin to give us a sense of how these factors may interact. Here's the objective : from our concrete features, we wish to derive information about unknown, and generally unknowable, latent variables. Let's dive in! Overview Factor analysis is similar to principal components analysis in that we are working only with a single group of variables (in this case, the response) and we wish to in some way reduce the number of variables in order to simplify our data. This gives us a sense of what the underlying nature of the data is, and how it is organized. In factor analysis, we wish to reduce the redundancy of the variables by limiting them to a smaller number of factors which can adequately explain the variation in the full set of variables. Factor analysis is considered somewhat controversial by statisticians and is not encouraged by all schools of thought. This is because factor analysis is often difficult to validate in practice, as the number of factors or the interpretations are not always clear from the analysis itself. Although at first glance factor analysis and principal component analysis may seem very similar, there are key differences which separate the two methods. In principal component analysis we aim to maximize the total variance of the variables in question, but in factor analysis we wish to account for the covariance between the variables. While principal components analysis uses linear combinations of the variables themselves, in factor analysis we create a linear combination of factors , which are unobserved, supposed latent variables. The factors that we are looking at are often some underlying attributes of the variables that we believe to be \"seperate\" in some way. For instance, let's say there we have students' test scores for different classes: physics, chemistry, statistics, English, history, etc. We may expect that there would be some underlying factors that would affect an individual's ability to perform well in these classes. Perhaps this would be something like quantitative reasoning skills, critical thinking ability, or reading level and skill. We wish to reduce the variables to a smaller subset that can use these factors (which are not observed but can be derived from the data using factor analysis) to simplify our dataset. We would then use factor analysis to determine both the \"correct\" number of factors and the effects these factors have on each of the variables. It is quite easy to see how in practice this could be quite difficult to implement. This contributes to the skepticism of some statisticians to its use in the first place. Often times, the data doesn't easily lend itself to such a simplistic interpretation, and it is unclear what these factors can be and how they should be interpreted. The Model Our model is constructed as follows: For each observation vector of $p$ variables, we have $$ y_1 - \\mu_1 = \\lambda_{1 1}f_1 + \\lambda_{1 2}f_2 + ... + \\lambda_{1 m}f_m + \\epsilon_1 \\\\ y_2 - \\mu_2 = \\lambda_{2 1}f_1 + \\lambda_{2 2}f_2 + ... + \\lambda_{2 m}f_m + \\epsilon_2 \\\\ ... \\\\ y_p - \\mu_p = \\lambda_{p 1}f_1 + \\lambda_{p 2}f_2 + ... + \\lambda_{p m}f_m + \\epsilon_p $$ On the left side of the equations, $y_1, ..., y_p$ are the variables in the dataset, and $\\mu_1, ..., \\mu_p$ are the corresponding means of these variables. We do this in order to center the variables. On the right side of the equations, $\\lambda_{i j}$ are the loadings for the $ith$ variable and $jth$ factor, $f_1, f_2, ..., f_m$ are the $m$ factors, and $\\epsilon_1, \\epsilon_2, ..., \\epsilon_p$ are the $p$ error terms associated with each variable. Our goal in doing factor analysis is to find some $m << p$ such that the factors specified above are appropriate for the $p$ variables of interest. In doing this, we are defining the original $p$ variables into a linear combination of $m$ factors. The $f$s in the above model are the $m$ factors themselves, while the lambdas are the loadings, which serve as weights for each factor for each of the $p$ variables. While this may seem similar to a more typical multiple regression model , there are key differences. Perhaps the most important thing to note here is that the $fs$ are unobserved random variables, not fixed effects like in multiple regression. Factor analysis only represents one observation vector, while multiple regression represents all of the observations simultaneously -- in this way, factor analysis is looking more to individual variation as opposed to aggregate or population level aggregation. Our model can be written more simply in matrix notation as: $$ \\begin{equation} \\vec{y} - \\vec{\\mu} = \\Lambda\\vec{f} + \\vec{\\epsilon} \\end{equation} $$ where $$ \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_p \\end{bmatrix} \\\\ \\vec{\\mu} = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_p \\end{bmatrix} \\\\ \\vec{f} = \\begin{bmatrix} f_1 \\\\ f_2 \\\\ \\vdots \\\\ f_m \\end{bmatrix} \\\\ \\vec{\\epsilon} = \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_p \\end{bmatrix} \\\\ \\Lambda = \\begin{bmatrix} \\lambda_{1 1} ... \\lambda_{1 m} \\\\ \\vdots \\ddots\\vdots \\\\ \\lambda_{p 1} ... \\lambda_{p m} \\end{bmatrix} $$ Assumptions : In performing factor analysis, we assume that the following holds: $\\mathbb{E}[\\vec{f}] = \\vec{0}$ $\\Sigma_{\\vec{f}} = I_{mxm}$ $\\mathbb{E}[\\vec{\\epsilon}] = \\vec{0}$ $\\Sigma_{\\vec{\\epsilon}} = \\Phi_{mxm} \\text{, where } \\Phi{pxp} = \\begin{pmatrix} \\sigma&#94;2_{\\epsilon_1} & 0 & \\dots & 0 \\\\ 0 & \\sigma&#94;2_{\\epsilon_2} & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & \\sigma&#94;2_{\\epsilon_p} \\end{pmatrix}$ $\\Sigma_{\\vec{f}, \\vec{\\epsilon}} = 0_{mxm}$ Notationally, I mean $\\Sigma_{\\vec{X}}$ to be the square covariance matrix of a vector $\\vec{X}$ with itself, where the $i, j$th element is the covariance of the $i$th entry in $\\vec{X}$ with the $j$th entry. It is therefore a positive semi-definite symmetric matrix with variances in the diagonal. I mean $\\Sigma_{\\vec{X}, \\vec{Y}}$ to be the covariances of each element in $\\vec{X}$ with each element in $\\vec{Y}$. This is not a square matrix, but relates the covariance of the individual elements of the two vectors. These assumptions follow naturally from the model itself. For instance, as $\\mathbb{E}[\\vec{y} - \\vec{\\mu}] = \\vec{0}$, it follows that both episilon and the factors themselves must also have an expected value of zero. We assume that the factors are uncorrelated, as we wish to minimize the number of variables used (so, we wish to have no correlation between the factors themselves.) The $\\Phi$ matrix shows that there are no covariance between the errors, only a specific variance for each error term, meaning the factors account for the correlations amongst the $y$s. This is exactly the goal of factor analysis, so these assumptions are self-checking -- if in recreating the model it is not clear what the factors should be or what number of them there should be, it is saying that these assumptions have not been met. In achieving our goal in factor analysis of reducing the variables used, we wish to express the covariance of $\\vec{y}$ in terms of the loadings $\\Lambda$ and the variances of the errors, $Phi$ using some number of factors $m$ which is less than the original number of variables $p.$ We can show that the population covariance matrix $\\Sigma_{\\vec{y}-\\vec{\\mu}}$ can be written as follows: $$ \\Sigma_{\\vec{y}-\\vec{\\mu}} = \\Lambda \\Lambda{'} + \\Phi$$ This follows from assumption 2 and 5 above. We can see then that the variance in this case will be a combination of some signal -- or explained -- variance in the latent variable loadings, and some random or unexplained variance in the error terms. This seperates Factor analysis from Principle Component Analysis -- in PCA, we make no distinction between explained and unexplained variance except in terms of the number of components selected. Here, we make this distinction for a number of latent variables. It is also of note that we can rotate the loadings by an orthogonal matrix without effecting their ability to reproduce this population covariance matrix. As such the loadings are not unique. We will use these rotations when we perform our analysis. The rotations prove useful as the results given in the loadings may not make it clear which variables are effected by which factors. By rotating the coordinate axis, we can more easily interpret the results from the factor analysis. The variances of each of the individual $y$s can be written as follows: $$ Var[y_i] = h&#94;2_i + \\phi_i $$ where $h_i&#94;2 = \\lambda_{i 1}&#94;2 + \\lambda_{i 2}&#94;2 + ... + \\lambda_{i m}&#94;2$ and $\\phi_i$ is the specific variance for the ith error term, that is, the ith diagonal of $\\Phi$. Thus we can separate the variance of each of the $y$s into a communal and specific part, which is $h_i&#94;2$ and $\\phi_i$ respectively. As such, the diagonal elements can be easily estimated using the loadings and the specific variance, while the off diagonal elements depend on the selection of the loadings alone. Since factor analysis is largely dealing with the estimations of the loadings, it accounts for the covariations between the variables, rather than the total variance as in principal component analysis. There are four different methods to obtain the loadings $\\Lambda$ from a sample. These are the principal component method, the principal factor method, the iterated principal factor method, and the maximum likelihood method. These will be explored later in the coding. Another difficulty is determining the number of factors, $m$. There are four approaches: we can select the number of variables $m$ which accounts for a prespecified amount of variance of the variables, we can choose $m$ to be the number of eigenvalues of the correlation matrix $R$ which is greater than the average of the eigenvalues, we can use a scree plot to determine where there is a leveling of the eigenvalues of $R$, or we can test the hypothesis using a chi-squared distribution if the number of factors is the true number of factors. Again, this will be shown further in the coding. Data The dataset I will be using to illustrate the benefits and limitations of factor analysis is collected data from an online personality questionnaire. The link can be found here . In this study, 1,005 participants were prompted with 40 statements to rate on a scale of one to five. This scale is used frequently and is known as the likert scale. It ranges from 1 (strongly disagree) to 5 (strongly agree). The data was partitioned into four sections, with every ten statements designed to be related to some attributes of the population; in particular, it was looking for their assertiveness, social confidence, adventurousness, and dominance. The questions were designed to discover the prevalence of these attributes through the responses to the statements in the survey. This seems like an ideal dataset to use factor analysis on, because the goal of the dataset seems to be precisely what factor analysis is used for. That is, we have some variables (the questions) that have some underlying, unobservable factor (initially hypothesized to be assertiveness, social confidence, adventurousness and dominance) that ties them all together. We are not very interested in the individual answers to the questions themselves, but of the behavior of the underlying factors that exist which are unobservable. Some examples of questions are printed below: AS2 I try to lead others. SC4 I express myself easily. AD6 I dislike changes. DO8 I challenge others' points of view. By looking at the coding markers of each of the questions, we can get a sense of how this survey was distributed and why. If, after doing factor analysis, there are four factors (that is, $m = 4$) and these factors are inclusive of each of the ten questions, we can then say that the data reflects these attributes well. Therefore, the goal of this analysis is to see if the data supports the idea that these factors are well separated in the variables, and if not, is there a better set of factors that can describe the individual more effectively. After doing some research, it seems that many personality scales fail to truly describe individuals completely. A very popular scale, the Myers Briggs Type Indicator (MBTI), has been purported by many to effectively separate all personalities into one of sixteen types. However, when researchers used factor analysis on data testing for the four underling dimensions of the Myers Briggs tests, they found conflicting results. One of these analyses confirmed the four-dimensionality of the data, while the other suggested there to be six, rather than the four purported by the Myers Briggs test.The motivation for choosing this topic and subsequent dataset was to test these findings for myself. Although I was unable to find an adequate dataset with questions relating to the Myers Briggs tests, I used this dataset to see how well factor analysis can truly separate personality types from a series of related statements. Analysis In [ ]: require ( psych ) tmp <- tempfile () download.file ( \"http://personality-testing.info/_rawdata/AS+SC+AD+DO.zip\" , tmp ) data <- read.csv ( unz ( tmp , 'AS+SC+AD+DO/data.csv' )) unlink ( tmp ) data <- data[ , 1 : 40 ] head ( data ) R <- cor ( data ) In [107]: head ( R ) AS1 AS2 AS3 AS4 AS5 AS6 AS7 AS8 AS9 AS10 ... DO1 DO2 DO3 DO4 DO5 DO6 DO7 DO8 DO9 DO10 4 4 3 3 5 4 1 3 1 1 ... 1 1 3 1 3 2 5 4 2 1 4 3 4 4 3 2 3 3 4 3 ... 4 4 3 2 3 2 3 3 2 2 5 4 4 5 3 3 2 2 1 1 ... 4 3 3 3 3 4 4 5 2 3 4 3 3 2 3 3 4 3 4 1 ... 3 3 3 3 4 4 4 5 3 1 4 4 4 4 4 3 2 1 2 0 ... 4 4 4 3 4 3 5 5 4 4 3 4 4 3 3 3 3 2 3 3 ... 4 3 3 4 4 4 3 4 4 3 AS1 AS2 AS3 AS4 AS5 AS6 AS7 AS8 AS9 AS10 ... DO1 DO2 DO3 DO4 DO5 DO6 DO7 DO8 DO9 DO10 AS1 1.0000000 0.4137723 0.3682398 0.4448159 0.3221669 0.2931655 -0.3267101 -0.2608312 -0.1858184 -0.1295499 ... 0.1031671 0.09393072 0.05655698 0.1736394 0.1128714 0.2045945 0.2821300 0.1982907 0.1183617 0.1488767 AS2 0.4137723 1.0000000 0.6344424 0.4177133 0.4526988 0.4913432 -0.4684408 -0.2919509 -0.3102848 -0.1228974 ... 0.2551933 0.26932527 0.20737706 0.3264103 0.2162572 0.3004144 0.2971938 0.2598124 0.3015476 0.2841464 AS3 0.3682398 0.6344424 1.0000000 0.3838178 0.4944641 0.5456192 -0.4765066 -0.2718920 -0.2233892 -0.1374873 ... 0.2574269 0.27971084 0.24749086 0.3568029 0.2513066 0.3279393 0.2882716 0.2657068 0.2976032 0.3326947 AS4 0.4448159 0.4177133 0.3838178 1.0000000 0.3028295 0.3159420 -0.2751444 -0.2203457 -0.1744766 -0.2328334 ... 0.1601098 0.15038853 0.12135381 0.2166474 0.1918464 0.2673106 0.2415963 0.2472153 0.1542765 0.2298038 AS5 0.3221669 0.4526988 0.4944641 0.3028295 1.0000000 0.4661230 -0.3747829 -0.1977530 -0.2327827 -0.1506424 ... 0.2189824 0.22601369 0.15205653 0.2137453 0.1715335 0.1811936 0.2429682 0.2532139 0.2470171 0.2718944 AS6 0.2931655 0.4913432 0.5456192 0.3159420 0.4661230 1.0000000 -0.3557865 -0.2394912 -0.2095667 -0.1155672 ... 0.2377874 0.25424424 0.22620592 0.3082356 0.2454524 0.2617313 0.2924134 0.3185667 0.2968619 0.2707137 I begin by importing the dataset and only using the variables pertaining to the questions. The next step is to find the correlation matrix. This is the preferred matrix to work with, as it makes many of the computations easier to do (as compared with the covariance matrix itself). We can see immediately that this is a covariance matrix, as there are ones in the diagonal. However, it does not appear to have particularly strong or easily discernible groups of correlations between the variables, which implies that factor analysis may not perform as well as we had hoped. I did not produce the entire matrix, as it is a 40x40 matrix. Instead, I use the head function to display the first six rows of the matrix. There were forty questions on the questionaire, with every ten representing a \"factor\" of one's personality. We are using factor analysis to determine whether there is statistical evidence that these groupings represent latent 'factors'. Selecting $m$ As mentioned before, it often is not clear how many factors, $m$, we should use in the factor analysis. In this example, it would be preferable to use four, as that is how the data is designed. However, as we will see, four factors are not sufficient to separate the variables. In order to perform factor analysis, we must find the correlation matrix of the dataset. This makes many of the calculations quite simple. The next step will be determining how many factors we should use. In [108]: R <- cor ( data ) Once we have the correlation matrix, the eigenvalues will tell us the optimal number of ways to reduce the features. In [109]: eigen ( R ) $ values 9.21029045767209 4.24760230352397 2.71094042312592 2.12362289107785 1.58576259730588 1.40297421933113 1.25498754107964 1.0702244847308 0.980598047554073 0.932908788172687 0.875987401716021 0.810352421774326 0.794043533485721 0.770980301512266 0.730096544235721 0.680693097946611 0.665770057061438 0.636014100079021 0.589687061258025 0.563270135901251 0.550068374680893 0.521441549385526 0.5079724127076 0.49008858321543 0.471300978751053 0.455906836189933 0.435144284728272 0.412711543929556 0.391866415262251 0.375715323212406 0.359819660931453 0.349986696198294 0.339350022467012 0.315884675549187 0.295294865270752 0.255552072439942 0.235430143959798 0.225839012349674 0.203852564039258 0.169967576187254 There are numerous methods to select the number of eigenvectors/eigenvalues we want to include. Each eigenvalue represents the proportion of variance explained by that eigenvector (a linear combination of the variables). We want to select eigenvectors/values such that we can explain a good deal of the variance with a smaller number of linear combinations of the features. The first method involves choosing an arbitrary threshold. In this example, at 19 latent variables (that is, reducing the forty variables nearly in half) we have acheieved a threshold of variance explained greater than 60%. In [110]: sum ( eigen ( R ) $ values[1 : 19 ] ) / 40 ##choose 19 0.80183840681608 Another method is to select eigenvectors such that each corresponding eigenvalue is greater than one. This means that the eigenvector of variables contributes more to the variance of the features than any single feature alone. Using this method, we come up with 8 linear combinations. In [111]: sum ( eigen ( R ) $ values > 1 ) ##choose 8 8 The final methodology is using a scree plot and determining where the eigenvalues level off. This is at 9 linear combinations of the features. In [112]: scree ( R ) ##choose 9 fa.parallel ( data ) Parallel analysis suggests that the number of factors = 9 and the number of components = 7 Three different methods were explored to determine the amount of factors, $m$, to use. Unfortunately, it seems right from the beginning that four factors will not be enough to adequately describe the variables. The three methods provide very different numbers â€\" 19, 8 and 9. I will use 9, as it appears to be a middle ground between the two, and the scree plot does flatten out significantly. Also, we do not wish to use nearly half of the number of variables as factors! Even 9 factors is quite high. This is where factor analysis and principle component analysis begin to differ. In PCA, we simply use the eigenvectors of the correlation matrix as variables, or 'principle components'. This does not account for the noise in the principle components themselves -- it is not trying to find any signal here. Factor analysis considers that these components are representations of some latent variables, that which are the true 'signal' in the correlation matrix, while the remainder is noise. Factor analysis is controversial because it attempts to estimate this latency by approximating correlation matrices, as we saw above. Now that we have determined m, the number of factors, we will aim to create the loadings matrix to estimate the covariance matrix, as explained above. There are four methods by which we can estimate the loadings matrices. The loadings matrix in each case will be a $p x m$ matrix, and will use the eigenvalues of the correlation matrix. The first method we will use is the principal components method. Principal Components Method In [113]: eigenvectors <- eigen ( R ) $ vectors[ , 1 : 9 ] loadings <- eigenvectors %*% ( diag ( 1 , nrow = 9 ) * ( eigen ( R ) $ values[1 : 9 ] ) &#94;.5 ) loadings -0.6277856 0.119554084 0.33171585 -0.0517100760 0.19589620 -0.256426344 -0.0051466920 -0.1050080325 -0.217875830 -0.6628787 -0.132540591 0.11886326 0.2214725941 0.22140567 0.132387083 -0.2481776856 0.0048103856 0.073391368 -0.6390134 -0.197196788 0.05624741 0.2311725131 0.23664371 0.106747616 -0.3142731034 0.0725529294 -0.009258277 -0.6038332 -0.001172604 0.25194869 0.0287228625 0.19716616 -0.096650456 0.2237402385 0.3933113732 0.175740568 -0.5623461 -0.075542614 -0.04215597 0.0889017298 0.31622038 0.101831072 -0.3414194020 0.0325078492 0.085362217 -0.5588305 -0.202629294 -0.02405988 0.1321338363 0.30155513 0.073081367 -0.2777839481 -0.0712005483 0.093765748 0.5610817 -0.101431288 -0.01542818 -0.4286785091 -0.17991988 -0.065822588 0.1121413950 0.1320328403 0.243711028 0.4195786 -0.089834730 0.04744726 -0.4219788203 -0.09239017 0.008179850 -0.1017128152 0.1404356750 0.359181871 0.3666707 -0.121246001 0.12235117 -0.2673284202 -0.19228688 -0.331672078 -0.1723038527 0.3330872957 -0.293884580 0.2834756 -0.191213944 0.13406289 -0.2440643282 -0.18539624 -0.106304884 -0.4565341789 -0.0821946123 -0.171057932 -0.5196860 0.270565545 0.30577781 -0.3423029175 -0.11245766 -0.001271796 -0.1320537729 -0.2283180107 0.265527940 -0.6564641 0.068827634 0.31328652 -0.2478632919 -0.34403345 0.087823904 -0.1132566054 0.0377935294 -0.011283238 -0.5998907 0.074604175 0.26507843 -0.1892944458 -0.07212877 0.033343619 0.0308950899 0.1426224411 -0.200220801 -0.6074783 0.096622639 0.34093184 -0.1742184243 0.20372042 -0.252897043 0.0281370136 -0.0346131237 -0.254485357 -0.6248483 0.011604348 0.28844967 -0.1296150311 0.17592820 -0.039241251 0.1844820354 0.4216051360 0.098786819 0.5974964 -0.234896621 -0.29156288 0.0140733681 0.45380545 -0.094810107 0.0093078526 0.0096644094 0.016502011 0.5405337 -0.286677830 -0.22708170 -0.1085333297 -0.06070240 -0.083413069 -0.3147783298 -0.2285523728 -0.186028731 0.5065189 -0.420628297 -0.27874397 0.0715082012 0.18189460 0.002006571 0.0463524348 0.3018104199 -0.260546935 0.5780675 -0.232627930 -0.26378683 -0.0556981294 0.44299196 -0.109840640 0.0355312724 0.0666607568 0.098413082 0.5219373 -0.216594655 -0.13173681 -0.1032620489 -0.04359939 0.070382456 -0.2508050668 0.2867068313 0.083829363 -0.3992462 0.160965015 -0.36037555 -0.3690507373 0.03464572 -0.123678525 -0.1924745951 0.1507108412 -0.019742963 -0.3394289 0.150689800 -0.26903653 -0.5548752336 0.16905090 0.011646505 -0.0474249609 -0.1572321905 0.166900898 -0.3320934 -0.027645815 -0.28907100 -0.5582492767 0.25327472 -0.005346193 0.1102181121 -0.1334792270 -0.157127058 -0.3658667 0.108273914 -0.38501438 -0.4940891181 0.19559323 0.064851965 -0.0003570599 0.0709592952 -0.068600025 0.3796437 -0.447822215 0.39727206 -0.1408538430 0.10110562 0.076120098 0.0523492570 -0.1131530027 0.095050608 0.3772945 -0.495954442 0.47234291 -0.1033727528 0.11469191 0.018459564 0.1824386999 -0.1389626180 -0.114702885 0.3799486 -0.444134704 0.49194137 -0.1387764590 0.13915859 0.013283974 0.1229109140 -0.0973772037 -0.116962488 0.2576489 -0.483342987 0.37297134 -0.1416818547 0.21231287 0.117125266 0.1369392140 -0.1222056233 0.146276756 0.2062744 -0.354617033 0.26543767 -0.0007295079 0.06470126 0.099806178 -0.2945216155 0.1256130100 -0.077929380 0.3334748 -0.402402498 0.39061932 -0.1902953021 0.08669907 0.083796843 -0.1520357393 -0.0181765447 0.107031691 -0.4064146 -0.347591815 -0.19534506 -0.1439862302 -0.08445037 0.611418809 0.1300478000 -0.0035088423 -0.175680364 -0.4213233 -0.421047564 -0.21614195 -0.1475954934 -0.14140091 0.569277998 0.1274642030 0.0120766707 -0.147817867 -0.3177238 -0.558528507 -0.21188225 -0.0260375231 -0.11058613 -0.064299580 0.1599389824 0.0008566237 0.011078551 -0.4535206 -0.568930452 -0.13969631 0.0740933171 -0.20728453 -0.111993462 0.0128182266 0.0851071945 0.058119259 -0.3733466 -0.534136456 -0.20889608 0.0462874732 -0.18328216 -0.242376556 0.0930813931 -0.0879622294 0.120472821 -0.4519620 -0.486894058 0.02868335 -0.0237170894 -0.22067245 -0.121746325 0.0211133535 0.0949324784 -0.117122331 -0.4792771 -0.359058583 -0.17026707 0.0243226733 0.01058587 -0.329825553 0.0814961168 -0.2338333561 0.027777255 -0.4884591 -0.361002718 -0.23670362 -0.0576248626 0.04542125 -0.266631231 0.1774163361 -0.1496133363 -0.028050715 -0.3794872 -0.555721465 -0.09478251 0.1039076241 -0.19174868 -0.083409801 -0.1393220930 -0.0449142959 0.188743726 -0.4024135 -0.549377337 -0.11356106 0.1869168187 -0.12464387 -0.136300169 -0.0389545949 0.0957233294 0.133687572 We first determine the loadings by multiplying the first $m$ eigenvectors (in this case, 9) by the square roots of their corresponding eigenvalues. This produces the above matrix, a unsightly $40x9$ matrix. Each column corresponds to a different loading. To determine the communalities and specific variances of the variables, we can square the entries in each of the rows of the loadings matrix. This will give us the $h&#94;2_i$ vector, from which we can also determine the specific variances. In [114]: hisq <- apply ( apply ( loadings , 2 , function ( x ) x&#94;2 ), 1 , sum ) psi <- rep ( 1 , 40 ) - hisq hisq psi 0.683770176904431 0.653702160695683 0.675341735731149 0.712773153297998 0.566896037890536 0.558690262100049 0.635211516458175 0.532115981531147 0.609566835025406 0.484574181409319 0.706671375970135 0.735721820684866 0.539231950202743 0.69716387017627 0.744607322341919 0.712766093667313 0.634277201980493 0.710513684222417 0.684661714950165 0.506335359710202 0.528022968048179 0.60172739948512 0.625084947046191 0.590145642396035 0.562934286491778 0.701361913962161 0.660692998827501 0.573063322313833 0.361502179731792 0.511368640368655 0.773637765079673 0.805610905334176 0.500542243541453 0.620662490871121 0.593723463371302 0.529414785891513 0.559200271826264 0.556067291455054 0.573394271904066 0.574252742505073 0.316229823095569 0.346297839304317 0.324658264268851 0.287226846702002 0.433103962109464 0.441309737899951 0.364788483541825 0.467884018468853 0.390433164974594 0.515425818590681 0.293328624029865 0.264278179315134 0.460768049797257 0.30283612982373 0.255392677658081 0.287233906332687 0.365722798019507 0.289486315777583 0.315338285049835 0.493664640289798 0.471977031951821 0.39827260051488 0.374915052953809 0.409854357603965 0.437065713508222 0.298638086037839 0.339307001172499 0.426936677686167 0.638497820268208 0.488631359631345 0.226362234920327 0.194389094665824 0.499457756458547 0.379337509128879 0.406276536628698 0.470585214108487 0.440799728173736 0.443932708544946 0.426605728095934 0.425747257494927 The above are the communalities and the specific variances of each of the variables. To determine the amount of the total variance of which each loading contributes, we can divide the eigenvalues of $R$ by the number of variables, $p = 40$. Thus, all nine factors account for about 60% of the variance of the variables. This is not very good, especially considering there were supposed to be only four underlying factors! Rotating the Loadings Because we have $m = 9$, I will use the varimax rotations from the psych package to rotate the loadings we have above. This will make it easier to see which variables correspond to the factors. In [115]: ## varimax includes a print method which makes the loading distributions easier to see. loadingsrot <- print ( varimax ( loadings ) $ loadings , cutoff = .3 , sort = T ) Loadings: [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [1,] -0.681 [2,] -0.713 [3,] -0.681 [4,] -0.655 [5,] 0.506 0.486 [6,] -0.657 [7,] -0.742 [8,] -0.765 [9,] -0.616 [10,] -0.642 [11,] -0.623 [12,] -0.685 [13,] -0.698 [14,] 0.716 [15,] 0.784 [16,] 0.769 [17,] 0.731 [18,] 0.643 [19,] -0.397 -0.534 [20,] -0.718 [21,] -0.747 [22,] -0.688 [23,] -0.313 -0.728 [24,] -0.753 [25,] 0.759 [26,] 0.727 0.301 [27,] 0.722 [28,] 0.794 [29,] -0.349 0.786 [30,] 0.744 [31,] 0.745 [32,] 0.338 -0.618 [33,] 0.302 0.681 [34,] -0.408 -0.522 [35,] 0.578 [36,] -0.396 0.337 -0.501 [37,] -0.407 0.481 [38,] -0.478 0.355 [39,] 0.360 0.327 0.457 [40,] 0.391 0.326 [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] SS loadings 2.970 4.308 3.507 2.557 3.954 1.746 2.289 1.437 1.819 Proportion Var 0.074 0.108 0.088 0.064 0.099 0.044 0.057 0.036 0.045 Cumulative Var 0.074 0.182 0.270 0.334 0.432 0.476 0.533 0.569 0.615 We can see from the above that the factors do not separate so easily. The values of the loadings below .3 have been omitted to make it clearer what the underling relationships are. Although they do not separate cleanly into the four theorized factors, we can see that the first factor, for instance, largely is between the first and tenth variables (which was assertiveness), the second factor between the 30th and 40th variables (which was dominance). Similarly, the fifth factor is between the 20th and 30th variables (social confidence) and the third and factor is largely between the 30th and 40th variables (adventurousness). However, the split is not so simple as we assumed before the analysis, as the other factors show relationships between variables which are not in the same groups. The second function simply sorts the variables by factor, so we can get a better sense of how they separate. We can see that towards the top there are larger values for the loading matrix, which indicates a stronger association with the factor. We can also see that the 6th-9th factors also have some large values, which means that their correlations cannot be ignored. This suggests that the initial separation into only four factors may have been overly simplistic. Principle Factors Method In the previous method, we had ignored the structure of the specific variances. Now, using the principal factors method, we will take the $\\Phi$ matrix into account. We first make an initial estimate of the $h_i$s, and use this to account for the specific variances. Below I create a diagonal matrix which has the specific variances in each of the diagonal elements. We will then subtract this matrix from the covariance matrix, and use the new matrix to compute our loadings. In [116]: hinit <- 1 - 1 / diag ( solve ( R )) psiint <- 1 - hinit hinit AS1 0.703351716235528 AS2 0.547924923423483 AS3 0.55110592594616 AS4 0.505277553186238 AS5 0.390968237137091 AS6 0.417887373144211 AS7 0.479120494482409 AS8 0.327259567877729 AS9 0.267933784282943 AS10 0.219370957003131 SC1 0.578039342631155 SC2 0.655687388651141 SC3 0.456950572036036 SC4 0.695887704065272 SC5 0.572176977540937 SC6 0.639285723548227 SC7 0.486094063924925 SC8 0.57955658432216 SC9 0.572181489668999 SC10 0.377978608918933 AD1 0.362251502864202 AD2 0.382357316270689 AD3 0.402193273797794 AD4 0.412581346196776 AD5 0.428481448115908 AD6 0.610754177794417 AD7 0.579359418895454 AD8 0.392654029176029 AD9 0.230305720741996 AD10 0.360903362125066 DO1 0.618517766838695 DO2 0.657506921900043 DO3 0.424117606047785 DO4 0.538841247151321 DO5 0.438784438295507 DO6 0.41461456936309 DO7 0.442354015793423 DO8 0.462192532311484 DO9 0.45847071523956 DO10 0.484904277176995 In [117]: psiint AS1 0.296648283764472 AS2 0.452075076576517 AS3 0.44889407405384 AS4 0.494722446813762 AS5 0.609031762862909 AS6 0.582112626855789 AS7 0.520879505517591 AS8 0.672740432122271 AS9 0.732066215717057 AS10 0.780629042996869 SC1 0.421960657368845 SC2 0.344312611348859 SC3 0.543049427963964 SC4 0.304112295934728 SC5 0.427823022459063 SC6 0.360714276451773 SC7 0.513905936075075 SC8 0.42044341567784 SC9 0.427818510331001 SC10 0.622021391081067 AD1 0.637748497135798 AD2 0.617642683729311 AD3 0.597806726202206 AD4 0.587418653803224 AD5 0.571518551884092 AD6 0.389245822205583 AD7 0.420640581104546 AD8 0.607345970823971 AD9 0.769694279258004 AD10 0.639096637874934 DO1 0.381482233161305 DO2 0.342493078099957 DO3 0.575882393952215 DO4 0.461158752848679 DO5 0.561215561704493 DO6 0.58538543063691 DO7 0.557645984206577 DO8 0.537807467688516 DO9 0.54152928476044 DO10 0.515095722823005 In [118]: head ( diag ( psiint , nrow = 40 )) 0.2966483 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0.0000000 0.4520751 0.0000000 0.0000000 0.0000000 0.0000000 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0.0000000 0.0000000 0.4488941 0.0000000 0.0000000 0.0000000 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0.0000000 0.0000000 0.0000000 0.4947224 0.0000000 0.0000000 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0.0000000 0.0000000 0.0000000 0.0000000 0.6090318 0.0000000 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.5821126 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 In [119]: New <- R - diag ( psiint , nrow = 40 ) eigs <- eigen ( New ) eigs eigen() decomposition $values [1] 8.72480786 3.73122125 2.22214484 1.55959578 1.13192575 0.94924084 [7] 0.69195388 0.57596597 0.51777057 0.43404257 0.27746408 0.24907073 [13] 0.20382247 0.18319157 0.14466391 0.10130984 0.08749738 0.06797501 [19] 0.03771954 0.01208288 -0.01256549 -0.03911447 -0.04221706 -0.06783310 [25] -0.09186545 -0.09808676 -0.10163170 -0.11804259 -0.12715993 -0.13788099 [31] -0.15202202 -0.15751357 -0.17112680 -0.18008415 -0.18710930 -0.19541343 [37] -0.20017634 -0.21596482 -0.23296518 -0.24850889 $vectors [,1] [,2] [,3] [,4] [,5] [1,] -0.21191434 0.0638645803 0.216822536 -0.022468256 -0.25615848 [2,] -0.21927351 -0.0651230428 0.060958567 0.176672739 -0.13311399 [3,] -0.21134289 -0.0975909567 0.024092374 0.184194194 -0.14976161 [4,] -0.19896989 0.0003466393 0.146503753 0.036124043 -0.16574130 [5,] -0.18252625 -0.0364514037 -0.031953933 0.068121563 -0.18846025 [6,] -0.18190149 -0.0973139299 -0.019771354 0.098589581 -0.18447426 [7,] 0.18387677 -0.0482107759 0.007793947 -0.307751553 0.10121267 [8,] 0.13501250 -0.0404225650 0.039020411 -0.270733036 0.05035865 [9,] 0.11713155 -0.0533301025 0.077886468 -0.154472414 0.05325027 [10,] 0.08984830 -0.0840485083 0.080677025 -0.136809325 0.08195542 [11,] -0.17310669 0.1374663028 0.188035682 -0.242264396 0.07688027 [12,] -0.22051610 0.0377714836 0.197260508 -0.180360079 0.30285600 [13,] -0.19681859 0.0374233202 0.152409585 -0.121605209 0.05178017 [14,] -0.20495512 0.0521895454 0.225533522 -0.118908627 -0.26503696 [15,] -0.20756081 0.0070522330 0.175144989 -0.077991784 -0.15090784 [16,] 0.20030461 -0.1209811419 -0.174818628 0.002661036 -0.39996267 [17,] 0.17770036 -0.1395591708 -0.122119769 -0.085951004 0.01937474 [18,] 0.16857986 -0.2115737663 -0.162210441 0.043223444 -0.14326556 [19,] 0.19221725 -0.1173746987 -0.150999335 -0.048170270 -0.37524166 [20,] 0.16932886 -0.1022850999 -0.066391823 -0.073364420 0.04165247 [21,] -0.12898946 0.0734429712 -0.202814551 -0.244825607 -0.06795927 [22,] -0.10993024 0.0695263365 -0.147704369 -0.370765189 -0.12523340 [23,] -0.10769927 -0.0152920098 -0.156792280 -0.379661784 -0.18761962 [24,] -0.11878337 0.0488835014 -0.218973571 -0.342253282 -0.14086453 [25,] 0.12344763 -0.2112173729 0.245815037 -0.085344833 -0.03827756 [26,] 0.12525971 -0.2461001017 0.316800429 -0.065964297 -0.07122012 [27,] 0.12562028 -0.2179364719 0.324647616 -0.089517877 -0.09262179 [28,] 0.08339879 -0.2266499762 0.226451086 -0.083557483 -0.10456494 [29,] 0.06544192 -0.1581824758 0.146234944 0.008942834 -0.01682762 [30,] 0.10746484 -0.1855239018 0.233367104 -0.110238782 -0.02908694 [31,] -0.13547116 -0.1786365421 -0.126289225 -0.136896947 0.18515118 [32,] -0.14099901 -0.2177440388 -0.139574002 -0.142611136 0.22845087 [33,] -0.10330488 -0.2681499356 -0.116866275 -0.026874693 0.05623212 [34,] -0.14963116 -0.2806943436 -0.081503597 0.050448938 0.12386953 [35,] -0.12160025 -0.2569026085 -0.116685857 0.026558886 0.07581466 [36,] -0.14725857 -0.2314500666 0.020682137 -0.013222301 0.11979588 [37,] -0.15631314 -0.1727513006 -0.095991992 0.015281278 -0.07316327 [38,] -0.15951395 -0.1755079663 -0.136005589 -0.044236436 -0.08708976 [39,] -0.12405265 -0.2680220873 -0.053469497 0.070947368 0.11829684 [40,] -0.13191686 -0.2673459106 -0.066980180 0.130023170 0.06007734 [,6] [,7] [,8] [,9] [,10] [1,] -0.15827430 -0.024370544 0.4224781068 0.283846440 1.031011e-01 [2,] 0.16948247 0.256608475 -0.0821893620 -0.025852984 2.220461e-02 [3,] 0.15429878 0.315258322 -0.1168124788 0.053865031 -9.834273e-02 [4,] 0.00831336 -0.267711489 -0.3441884719 0.106418967 1.731900e-01 [5,] 0.13620105 0.290255310 -0.0718212342 0.021728576 6.960383e-03 [6,] 0.11876169 0.264451319 -0.0550391735 -0.111677533 -2.946530e-02 [7,] -0.11983914 -0.081808089 -0.0885797717 0.103757761 2.917757e-01 [8,] -0.03638548 0.106832218 -0.1216425503 0.081192391 2.767154e-01 [9,] -0.22758313 0.068913132 -0.1462576486 0.251324530 -1.503272e-01 [10,] -0.09836163 0.284579531 0.0295665354 0.096691319 -3.174537e-02 [11,] -0.04159560 0.199690466 0.0811955025 -0.248526910 3.737468e-01 [12,] -0.03143641 0.138431767 -0.1064316538 0.071034512 -1.555814e-01 [13,] 0.01845562 -0.036382777 -0.0557317087 0.143148630 -1.820674e-01 [14,] -0.15512880 -0.069879416 0.3514228501 0.344208761 3.102509e-02 [15,] 0.04932728 -0.252791620 -0.4134395758 0.136705403 1.063398e-01 [16,] 0.04852405 -0.009191454 0.0540441676 -0.009051929 2.187696e-01 [17,] -0.11391111 0.331796110 0.2845588774 0.116429272 -9.469127e-02 [18,] 0.04685364 -0.097220774 -0.1245846052 0.380314139 -3.207187e-01 [19,] 0.02598492 -0.030379206 -0.0187931360 0.036064034 2.647564e-01 [20,] 0.02356316 0.173181864 -0.2096544144 0.213152551 6.651396e-02 [21,] -0.08933338 0.132017255 -0.1016462713 0.106055687 -1.563673e-02 [22,] 0.01747455 0.092299153 -0.0589124181 -0.213043710 -1.151562e-02 [23,] 0.03002665 -0.039697120 -0.0007127983 -0.176397646 -2.957268e-01 [24,] 0.05825359 0.022250604 -0.0835513124 0.011648537 -1.694231e-01 [25,] 0.07225976 0.019548111 -0.0320634032 -0.158535811 8.227759e-05 [26,] 0.06007824 -0.130169484 0.0882919492 -0.179487793 -2.022112e-01 [27,] 0.06157881 -0.083945667 0.0822447224 -0.112769681 -1.448531e-01 [28,] 0.12506919 -0.036460762 -0.0398695032 -0.198717192 1.904711e-02 [29,] 0.05963406 0.195333527 -0.0375618776 0.127083107 1.367631e-02 [30,] 0.06016990 0.165641225 -0.0829931136 -0.020241198 3.118090e-04 [31,] 0.49629699 -0.139568268 0.2334919364 0.136470107 1.228746e-01 [32,] 0.45331974 -0.133403153 0.2036658111 0.142013496 1.058988e-01 [33,] -0.09906670 -0.123998263 -0.0123462892 -0.033555908 -3.513423e-02 [34,] -0.17200932 -0.018014320 -0.0525556731 0.076674017 7.605789e-02 [35,] -0.24447264 -0.073476737 0.0037701821 -0.119654641 5.546094e-02 [36,] -0.15091680 -0.032103762 -0.0375143314 0.091121696 -1.053736e-01 [37,] -0.25136231 -0.057850425 0.1352130623 -0.188409724 -1.135128e-02 [38,] -0.19474644 -0.153848312 0.0485388559 -0.217494610 -1.182452e-01 [39,] -0.13910063 0.137555935 -0.0240529211 -0.047495780 1.745509e-01 [40,] -0.14829209 0.011484563 -0.0505739246 0.069005274 2.200400e-01 [,11] [,12] [,13] [,14] [,15] [1,] -0.093106049 0.023953605 0.1117642781 -0.113668062 0.004013874 [2,] -0.091594959 0.116164513 0.1234670649 0.120932190 -0.058282880 [3,] -0.096311382 0.023670802 0.0301013676 0.171924685 0.174719738 [4,] 0.031169404 -0.041063817 0.1284634151 -0.056395911 0.084647510 [5,] 0.089108922 0.056604682 -0.1898358272 -0.141490134 0.187404140 [6,] -0.021100498 0.006001516 0.0726063633 0.014045167 0.331118635 [7,] -0.142377583 0.221895979 -0.0831367706 -0.058015962 0.250495434 [8,] 0.066598083 0.326645997 -0.1283547910 0.134837419 0.312362155 [9,] 0.138863707 -0.245192228 0.0005251174 0.222729453 0.061742042 [10,] 0.096860572 -0.239634419 0.4166085223 0.129274248 -0.109238876 [11,] 0.032137040 -0.072744124 -0.0210042302 0.195457424 -0.031786573 [12,] 0.113908667 0.160259725 0.1018486933 -0.090273594 0.110726129 [13,] 0.262175090 0.114901214 -0.3062113567 0.075555168 0.015794822 [14,] -0.095782673 0.050590974 0.0380508460 -0.104868927 -0.040408956 [15,] 0.127620058 -0.120741802 0.0185095025 0.089821657 -0.077724697 [16,] 0.097562858 -0.152357458 -0.1851300772 0.253259537 -0.112013067 [17,] 0.084887200 0.064189354 -0.1251991747 -0.002436892 0.146522710 [18,] -0.008751875 0.152683667 0.0731774456 -0.172994806 0.111272080 [19,] 0.040925231 0.035538330 0.1281941236 0.071947140 0.020408208 [20,] 0.151121452 -0.113893518 0.3176877023 -0.215341692 -0.036916168 [21,] 0.027220596 -0.279414760 -0.0433390425 0.107478575 0.035253394 [22,] -0.169510734 -0.159674756 0.1943993309 -0.211848067 0.002522462 [23,] -0.104679536 -0.042392807 -0.0338028763 -0.063781597 -0.159117917 [24,] -0.140280185 0.123130792 -0.2595967733 -0.081837727 -0.150508676 [25,] -0.035231678 0.030111977 0.0951462131 -0.269069359 -0.097736756 [26,] -0.078007435 -0.268096562 -0.0732707829 0.018338435 0.264014738 [27,] 0.005860812 -0.238214479 -0.1359315757 0.149958479 0.212755146 [28,] -0.002991652 0.258861576 0.0072169464 -0.119524778 -0.069977754 [29,] 0.089399076 0.168638263 -0.1681037648 0.222630026 -0.512673304 [30,] -0.037932190 0.125090822 0.0568209367 -0.143333016 -0.304207052 [31,] 0.137616759 -0.053774593 0.1118868527 0.091599985 -0.054671924 [32,] 0.064922713 -0.098253612 0.0245284558 -0.009400531 0.076538119 [33,] -0.270183667 0.267178022 0.1643686377 0.270876943 0.013175597 [34,] -0.401859145 -0.028585352 -0.0340428235 0.081695820 -0.003376735 [35,] -0.122327060 0.001947819 0.1762680714 0.094229249 0.013548891 [36,] -0.133373550 -0.070487115 -0.1131474580 0.212853198 -0.136479841 [37,] 0.425845448 0.178438174 0.2011172845 -0.069139919 0.015441866 [38,] 0.449148328 0.129750421 0.0331814001 0.102540454 0.022067505 [39,] 0.005658654 -0.179248687 -0.2686955684 -0.311721069 -0.059326690 [40,] 0.104881177 -0.221573698 -0.2569202640 -0.335994013 -0.050981529 [,16] [,17] [,18] [,19] [,20] [1,] 0.051720282 -0.020238235 -0.058414767 0.051386778 -0.07469648 [2,] 0.007900105 -0.060657392 -0.204351746 0.356363407 -0.36586927 [3,] -0.059353877 -0.041045516 -0.100604716 0.113254414 0.04586721 [4,] 0.163214149 0.022029493 -0.115407241 0.160971104 0.26392717 [5,] 0.026535895 -0.031813851 -0.003240182 -0.481812626 0.13138548 [6,] 0.023463697 -0.177477204 0.323295238 0.010728552 0.29721500 [7,] 0.095408883 -0.190247303 0.010081957 0.170243516 0.09287607 [8,] 0.118784719 -0.196428690 -0.224053731 -0.045563986 -0.12468882 [9,] -0.347625830 -0.265593306 0.089249789 -0.046668060 0.05152229 [10,] -0.121290117 -0.370258195 -0.035792352 -0.070014074 -0.16248416 [11,] -0.062675487 0.220098506 0.160339101 0.043641668 0.03028082 [12,] 0.050279390 0.169227620 0.036932560 0.151684871 -0.07978067 [13,] -0.384984033 0.294069805 0.166008709 0.099372197 0.02033137 [14,] -0.002739694 -0.087999264 0.078464334 -0.087310380 0.07619189 [15,] -0.018256737 0.004952343 0.101991017 -0.194234539 -0.12371531 [16,] -0.062219141 -0.006547805 0.033942989 0.126531607 0.08430365 [17,] -0.023548163 0.269649746 -0.029525599 0.046919843 0.15406323 [18,] -0.003740704 0.077740029 -0.088847153 0.053133996 -0.10928175 [19,] -0.205485270 0.258116841 0.098378726 0.128843426 -0.08405342 [20,] 0.260010856 0.254843891 0.331655352 0.081325147 0.03186721 [21,] 0.045060363 0.314590398 -0.385126163 -0.094414285 -0.08571515 [22,] -0.002137638 0.058724250 -0.080568516 0.011762663 -0.02423440 [23,] -0.011364031 -0.159136904 0.093150561 0.142806160 0.04425149 [24,] 0.143093618 -0.128972864 0.123444664 -0.019143156 -0.11418887 [25,] -0.205453327 -0.033657825 0.119336213 0.081793613 0.28913437 [26,] 0.097058514 0.133415650 -0.078565994 0.104596997 -0.09782283 [27,] 0.365188226 0.043768308 0.099117058 -0.151138200 -0.20757132 [28,] -0.384396969 -0.002547885 -0.159472994 0.010463457 -0.16205344 [29,] 0.340774417 -0.014595412 0.127879953 0.002344641 0.02043592 [30,] 0.028675413 0.114443712 -0.314578858 -0.295229956 0.17182108 [31,] -0.011902622 -0.022681539 -0.041731986 -0.117132033 0.03326848 [32,] -0.034003731 -0.064140786 -0.017126434 0.086641437 0.04895536 [33,] -0.037773697 0.062852864 0.290491093 -0.240911252 -0.12450871 [34,] -0.110736030 0.159814187 0.148828191 -0.091103479 -0.17246856 [35,] -0.010102437 0.116545622 -0.184509835 -0.191199381 0.25110941 [36,] 0.104349502 -0.015312409 -0.185172637 0.344170979 0.38552672 [37,] 0.153071645 0.085194208 0.051589122 0.079933406 -0.14949080 [38,] 0.060750415 -0.184128812 -0.106072097 -0.032739581 0.05910251 [39,] 0.039153548 -0.153044940 0.133559195 0.160187270 -0.18260341 [40,] -0.104029738 -0.077892510 -0.090346363 -0.059860307 -0.12365209 [,21] [,22] [,23] [,24] [,25] [1,] 0.0579591307 -0.039740203 -0.10091982 0.1942841006 0.017966313 [2,] -0.0638452228 0.070692539 0.09664590 0.0291234192 -0.237945831 [3,] 0.1526559936 0.235933268 -0.24627306 0.1702130370 0.192466940 [4,] -0.0641744493 -0.001977639 -0.14865577 0.2282540880 -0.129454561 [5,] 0.0123882163 0.045289069 0.12488489 -0.0217560204 0.159394251 [6,] 0.0080916563 -0.338532991 0.04980414 -0.1720542752 -0.210683128 [7,] 0.1495902663 0.022563021 0.11404634 0.0479750596 -0.205737785 [8,] -0.0612781453 -0.006327463 -0.07999877 0.0008769464 0.166442897 [9,] 0.1518713102 -0.040987409 -0.18438643 0.1862782857 -0.007132275 [10,] -0.1582276401 -0.031648033 0.09735055 -0.0766521956 -0.017719865 [11,] -0.1252435964 0.223314076 0.02084079 -0.1231135815 -0.033634954 [12,] -0.0913193836 0.104541665 -0.10844077 -0.3977057666 0.117024755 [13,] -0.0744130173 -0.187769187 0.15818975 0.1559301723 -0.105192037 [14,] -0.0471932126 0.020402393 0.12184407 -0.2430700333 -0.034092675 [15,] -0.1872153412 0.178775678 0.09625183 0.0906899853 0.045560988 [16,] -0.1351770406 0.165135611 0.15147667 -0.0224691708 -0.191520189 [17,] -0.2144382862 0.177457606 -0.07553808 0.2853070234 -0.098217811 [18,] -0.1520261334 0.121036994 0.23578525 -0.1815775576 -0.006242295 [19,] 0.0332746045 -0.166374126 -0.17678741 -0.2939967800 0.376315640 [20,] -0.0327359512 -0.062531184 -0.08401832 0.0557358929 -0.110850195 [21,] 0.3460286380 -0.043548404 0.14738032 -0.0996739946 -0.105962853 [22,] 0.0701799548 -0.159000336 0.31439556 0.1608637114 0.131615590 [23,] -0.1468553043 0.166848819 -0.27498667 0.0586445156 0.116787012 [24,] -0.0504228670 -0.050956329 -0.27627230 -0.0379906188 -0.144433418 [25,] 0.3623962226 0.295260837 0.07526132 -0.0513925862 0.043945684 [26,] -0.0156444481 0.204781606 -0.08037619 -0.1463832699 -0.216720488 [27,] -0.0065058861 -0.221096313 0.01618676 0.0867471177 0.203277324 [28,] -0.0819656322 -0.344715215 -0.03475543 0.0547417753 0.002297038 [29,] 0.1670186892 -0.090315359 -0.03359917 -0.0570117185 0.017178761 [30,] -0.0200453377 0.009832483 0.00737685 0.1035461618 -0.171514697 [31,] -0.0345718072 -0.077443600 -0.12451561 -0.0538730712 -0.073891870 [32,] 0.0847929955 0.048745471 0.06597151 0.1345667287 0.055963832 [33,] 0.0565325365 0.321406605 0.24899408 0.1211265296 0.124184236 [34,] 0.2464053688 -0.198852184 -0.16066676 -0.0363620636 -0.298624927 [35,] -0.4500559845 -0.087885134 -0.20970486 -0.0359137120 -0.032942481 [36,] 0.0005874973 -0.179565570 0.21562362 -0.0862699484 0.363402967 [37,] 0.2039633972 -0.044234455 -0.05975796 0.3037845599 0.099813485 [38,] 0.1312358804 0.053820235 0.09237845 -0.2532880646 -0.258180296 [39,] -0.2691440461 -0.034644630 0.26806242 0.1180734442 0.053118305 [40,] 0.1130941349 0.156533276 -0.25197774 -0.1806635672 0.104414035 [,26] [,27] [,28] [,29] [,30] [1,] 0.039467582 -0.2840391273 -0.20725439 0.396697101 0.1531317689 [2,] -0.164260013 -0.1757583326 0.01613049 -0.179027156 -0.1447680728 [3,] 0.088154522 0.3573144007 -0.14554754 0.156740995 0.0348901311 [4,] 0.257136663 -0.2418886890 0.16263086 -0.300708024 -0.0031598058 [5,] -0.268030695 -0.3908587166 0.06133227 -0.109763843 -0.0175360338 [6,] 0.154210185 0.1218706436 0.06392335 0.173228391 -0.0696772699 [7,] -0.049756894 -0.0928175534 0.01610963 0.180927225 -0.2311703627 [8,] -0.067008171 0.2449493781 -0.16530560 -0.139570319 0.0924849396 [9,] 0.171561158 -0.1706096878 0.06632165 0.029143109 -0.0406118330 [10,] -0.151751824 -0.0806612466 0.10251604 -0.066704537 -0.0936753047 [11,] 0.127085186 -0.0461831830 -0.10114725 0.061750919 -0.0656478754 [12,] 0.183492246 -0.1906804528 0.27356471 0.093910554 0.3154096903 [13,] -0.091485207 0.0828372705 -0.06444023 0.051063898 -0.2284318788 [14,] -0.080831262 0.3892270526 0.11937920 -0.320671538 -0.0372443758 [15,] -0.161500881 0.1329170244 -0.13223510 0.037488170 0.0691655905 [16,] 0.022149174 0.0005670124 0.27821076 0.093749595 0.3740361205 [17,] 0.094636341 -0.0600021737 0.02429151 -0.346922837 0.0788245119 [18,] 0.235973241 -0.0730378063 -0.17793189 0.089854503 -0.0617591477 [19,] 0.009347526 -0.1362944664 0.01096128 0.057720156 -0.2619759050 [20,] -0.271918209 0.1984913894 -0.08552990 0.030609516 0.1648268665 [21,] -0.071109758 -0.0147363652 -0.12442636 0.076172377 0.0285799179 [22,] 0.308506643 0.0800603849 0.04222100 -0.163563630 0.0004563894 [23,] 0.023351604 0.0758914792 -0.16851410 0.009459511 0.0186627422 [24,] -0.223907224 -0.1472371042 0.19168939 0.039139536 -0.0734021999 [25,] -0.190027999 -0.1764417426 -0.29011323 -0.171285663 0.0720009315 [26,] -0.142975531 0.0445287376 0.09381860 0.046245505 -0.2877081566 [27,] 0.097024422 -0.0756465548 -0.03746653 -0.057450427 0.1295984615 [28,] -0.023809170 0.0256009249 0.04767220 -0.053399281 0.3204161680 [29,] 0.191606867 -0.0860759422 -0.14228592 -0.048424723 -0.0777383369 [30,] 0.141634385 0.1870734867 0.24219103 0.333110008 -0.1477013237 [31,] 0.206258329 -0.0283817646 -0.16758729 -0.199333304 -0.2312462101 [32,] -0.182214064 -0.0003276381 0.17397209 0.212858478 0.2092743862 [33,] 0.126038496 -0.0350938799 0.20003242 0.039024884 -0.0558366229 [34,] -0.030164624 0.0213708929 -0.08269342 -0.183877174 0.2181854614 [35,] -0.168249868 -0.0934655884 -0.20540797 0.112733677 -0.0535145938 [36,] -0.224599291 0.0157637932 0.11664186 -0.041537521 -0.0033759093 [37,] -0.142615264 0.0704992312 0.22991204 -0.001423657 -0.1830070638 [38,] 0.096976806 0.0109747239 -0.23421904 0.008052716 0.1780495448 [39,] 0.126995085 -0.0206763301 -0.21606228 0.111897033 -0.0555356867 [40,] 0.145516718 0.1265183082 0.21774350 -0.050439024 -0.0890523114 [,31] [,32] [,33] [,34] [,35] [1,] -0.03929150 0.039036327 0.234407800 -0.195661904 -0.052521020 [2,] -0.11410580 0.267195808 -0.257214476 0.084579620 0.006368062 [3,] 0.30324362 -0.249997605 -0.011329700 0.048299141 -0.029114530 [4,] -0.02117228 -0.178660580 0.015950290 -0.006459983 0.166166465 [5,] -0.06221996 -0.049952025 0.123985606 0.033326042 0.296758825 [6,] -0.16322995 0.129372845 0.012958367 -0.090902394 -0.224304742 [7,] 0.13541207 0.050125630 -0.084493015 0.012540594 -0.064918089 [8,] -0.02413885 0.073915394 0.135172816 -0.081482425 0.159089202 [9,] -0.15934722 -0.027654017 -0.175117527 0.214110801 0.073510123 [10,] 0.16674656 -0.081900480 0.158700561 -0.194846626 -0.006962392 [11,] -0.29966159 -0.310919518 -0.123272047 0.073955519 -0.035311762 [12,] 0.24948402 0.151517812 0.070383035 0.107911339 0.014310545 [13,] 0.25068044 0.060387453 -0.018235376 -0.199337687 0.192125531 [14,] 0.02726727 -0.076621955 -0.241997116 0.194677831 0.093976893 [15,] -0.07277121 0.286385315 0.121980271 -0.075536247 -0.403937140 [16,] 0.32301848 -0.008218561 0.100811942 0.058990914 0.093713908 [17,] -0.14102919 0.193622173 0.046182068 -0.100545741 -0.322998914 [18,] -0.10973798 -0.208461930 -0.111034664 0.009747904 -0.037118914 [19,] -0.01586770 0.197562797 0.001992001 0.077403368 0.039732073 [20,] -0.12926193 -0.148019368 0.028648592 -0.018656041 0.141698662 [21,] -0.06016887 -0.129882691 -0.063795887 0.110965005 -0.098773847 [22,] 0.19986776 0.069895464 -0.025077302 -0.311423521 0.054581792 [23,] -0.23085512 0.230768851 0.054992877 0.077971457 0.313556372 [24,] 0.13299918 -0.271090970 -0.032899761 0.027187211 -0.338681646 [25,] 0.22191455 0.057180120 -0.088281763 0.068086131 -0.176956001 [26,] -0.05263206 -0.126225701 0.270004872 -0.210473938 0.174811705 [27,] 0.11276382 0.095453625 -0.302387164 0.161153966 -0.117786040 [28,] -0.20507650 -0.368068524 0.021768376 -0.045942986 -0.112949390 [29,] 0.02978577 -0.054301412 -0.113058660 -0.337538715 0.124733149 [30,] -0.06848216 0.246895579 0.050212859 0.265827875 0.049590355 [31,] 0.14714742 -0.057497700 0.300217752 0.216599437 -0.137425732 [32,] -0.16679376 0.076976793 -0.350715085 -0.139544967 0.151896964 [33,] -0.09636997 -0.109962092 0.049938161 -0.077857333 0.006201032 [34,] 0.03193342 0.169985320 0.189404721 0.085796054 0.161790917 [35,] 0.26575723 -0.024247239 -0.360733154 -0.111191978 0.033302669 [36,] -0.18351059 -0.033070204 0.240490321 0.042284383 -0.140254105 [37,] 0.07640285 -0.063540523 0.032207550 0.176138205 -0.046229884 [38,] -0.09016278 0.052711591 0.009825214 -0.044902345 0.046250358 [39,] 0.07322608 -0.088340720 0.102709992 0.326530028 0.089667710 [40,] -0.07695258 0.046396648 -0.120292879 -0.346951521 -0.123820962 [,36] [,37] [,38] [,39] [,40] [1,] 0.073202913 -1.077204e-01 0.0345802185 0.104614721 -0.076167249 [2,] 0.198232783 -1.040005e-01 -0.0192821416 0.089306752 -0.166691951 [3,] -0.041753424 2.922844e-01 -0.0391627344 0.011321615 -0.061030741 [4,] -0.236022109 -9.898293e-05 -0.0247717853 0.174975976 0.171245715 [5,] 0.154228208 1.732424e-01 0.0095106520 -0.103838575 -0.047414803 [6,] -0.030888773 -2.512679e-01 -0.0226852931 -0.059528257 0.182444231 [7,] 0.272912634 4.014193e-01 -0.2097037990 -0.090019612 0.101995852 [8,] -0.106243548 -4.020676e-01 0.1897921825 0.069072795 -0.021338197 [9,] 0.083475574 -1.653481e-01 0.0001245743 -0.182592710 -0.339590220 [10,] -0.164952791 1.813943e-01 0.0765198942 0.167280468 0.333154785 [11,] 0.070571458 1.127840e-01 0.3575193052 -0.005139065 0.042449463 [12,] 0.019442145 -3.542866e-02 -0.1302258754 -0.134030914 -0.009336972 [13,] 0.037861033 -2.590358e-02 0.0572470569 0.272662399 0.089389713 [14,] -0.051600053 1.955630e-02 -0.1280507899 -0.086309797 -0.044150474 [15,] -0.035926493 1.104654e-01 -0.0269238696 -0.284802531 -0.023849878 [16,] 0.204555192 -1.368484e-01 0.0733278916 -0.048265671 0.046456671 [17,] -0.159228113 1.487147e-01 -0.1197965511 -0.036850825 0.009388998 [18,] 0.080428443 1.173415e-02 0.3975204223 -0.120504237 0.155859971 [19,] -0.275776537 1.430277e-01 -0.0827326452 0.064815790 -0.097957552 [20,] 0.218625473 -1.149067e-02 -0.1009829827 0.210638253 -0.227552606 [21,] -0.066242087 -2.031058e-01 -0.3168660745 0.010797991 0.285122314 [22,] 0.068359850 3.288600e-02 0.1293247779 -0.141740559 -0.335193371 [23,] 0.192684257 3.243411e-02 -0.1169638845 0.009704912 0.346784585 [24,] -0.217948709 -5.095151e-02 0.1585513406 0.144993941 -0.195741663 [25,] -0.073696928 -2.514598e-01 0.0975879256 0.069962507 0.064542102 [26,] -0.109721694 -7.949213e-02 -0.0800515099 -0.223622600 -0.175548323 [27,] 0.124446753 1.114992e-01 0.0738133630 0.280378745 0.098140781 [28,] 0.111534411 8.447453e-02 -0.2510605616 -0.104287972 0.055827450 [29,] -0.071723658 -1.946262e-02 -0.1319386672 -0.306431211 0.053495476 [30,] -0.094872498 3.238229e-02 0.1370211150 0.158518104 -0.053164040 [31,] 0.269372698 -7.619546e-02 -0.0600342023 0.011702940 -0.071291291 [32,] -0.317314799 6.019473e-02 0.0780420915 -0.102948282 0.025152779 [33,] 0.005330222 -1.848071e-01 -0.2660664678 0.260488877 -0.027685999 [34,] -0.073545879 1.827986e-01 0.3098538087 -0.114334372 0.091532208 [35,] 0.079847028 -1.366967e-01 -0.0549126282 -0.132991312 -0.045998504 [36,] 0.141395354 5.203679e-02 0.1255613006 0.075523547 -0.103298166 [37,] 0.074960387 -8.705884e-02 0.1962094947 -0.310635257 0.190894168 [38,] -0.131712458 2.801683e-01 -0.0300976347 0.235480701 -0.288824106 [39,] -0.293872107 -6.678347e-02 -0.1953074869 -0.040274101 -0.048995780 [40,] 0.278086759 -4.131369e-02 0.0221214957 0.201924497 0.069240683 We will then use this new matrix to compute our eigenvalues and vectors, and subsequently create our new loadings matrix. In a similar way, we will determine the specific variances and communalities, and then rotate the loadings matrix. In [120]: eigenvectors2 <- eigen ( New ) $ vectors[ , 1 : 9 ] loadings2 <- eigenvectors2 %*% ( diag ( 1 , nrow = 9 ) * ( eigen ( New ) $ values[1 : 9 ] ) &#94;.5 ) hisq2 <- apply ( apply ( loadings2 , 2 , function ( x ) x&#94;2 ), 1 , sum ) psi <- rep ( 1 , 40 ) - hisq loadings2rot <- print ( varimax ( loadings2 ) $ loadings , cutoff = .35 ) Loadings: [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [1,] 0.713 [2,] -0.635 [3,] -0.662 [4,] -0.574 [5,] -0.549 [6,] -0.554 [7,] 0.500 [8,] [9,] 0.368 [10,] [11,] 0.636 [12,] 0.729 [13,] 0.460 [14,] 0.717 [15,] -0.620 [16,] -0.739 [17,] -0.360 0.505 [18,] -0.650 [19,] -0.688 [20,] 0.371 [21,] -0.466 [22,] -0.625 [23,] -0.627 [24,] -0.597 [25,] 0.649 [26,] 0.754 [27,] 0.732 [28,] 0.635 [29,] 0.362 [30,] 0.578 [31,] 0.727 [32,] -0.375 0.730 [33,] -0.609 [34,] -0.711 [35,] -0.686 [36,] -0.588 [37,] -0.582 [38,] -0.581 [39,] -0.631 [40,] -0.651 [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] SS loadings 2.508 3.963 3.089 1.957 3.511 1.279 1.401 1.402 0.995 Proportion Var 0.063 0.099 0.077 0.049 0.088 0.032 0.035 0.035 0.025 Cumulative Var 0.063 0.162 0.239 0.288 0.376 0.408 0.443 0.478 0.503 We can see a similar pattern to that of the principal component method above. The variance is not as well explained using this method, but when we perform the next step (using iterations of the above method), it will become a better representation of the data. Again, we can see similar relationships between the first five factors and the variables, but it is not all encompassing. Principal Factors Method We will now use a similar method to above, but iterate it each time and update it with the new initial squared loadings. That is, when we calculate the new $h&#94;2_i$ values, we do the iterate until it converges. For completeness, I perform the process 100 times below. In [121]: hinit2 <- 1 - 1 / diag ( solve ( R )) for ( i in 1 : 100 ) { New2 <- R - diag (( 1 - hinit2 ), nrow = 40 ) eigenvectors3 <- eigen ( New2 ) $ vectors[ , 1 : 9 ] loadings3 <- eigenvectors3 %*% ( diag ( 1 , nrow = 9 ) * ( eigen ( New2 ) $ values[1 : 9 ] ) &#94;.5 ) hinit2 <- apply ( apply ( loadings3 , 2 , function ( x ) x&#94;2 ), 1 , sum ) } hisq3 = hinit2 loadings3 -0.6336865 0.129510159 0.342334002 -0.038023630 -0.298855098 -0.106461077 0.004012698 0.4158842813 -0.135351810 -0.6502007 -0.125780976 0.094612300 0.224797379 -0.119888358 0.183656923 -0.219213531 -0.0853302346 -0.005595223 -0.6291168 -0.190720725 0.040105304 0.241398639 -0.146635370 0.173629622 -0.280919773 -0.1084499357 -0.062148373 -0.5908644 0.002653042 0.226497992 0.040334761 -0.168819189 0.045883497 0.264423699 -0.2146298828 -0.139428187 -0.5403052 -0.069776558 -0.046541079 0.088730496 -0.184540364 0.153429789 -0.241690414 -0.0715201038 -0.043392862 -0.5383186 -0.187930368 -0.027921243 0.127559024 -0.182887463 0.135235784 -0.224915024 -0.0776985624 0.061374907 0.5427781 -0.094736535 0.006660377 -0.381431291 0.087614276 -0.135960537 0.081417002 -0.0316562359 -0.128293688 0.3964542 -0.078623909 0.051902429 -0.326084495 0.044529009 -0.049494223 -0.071142504 -0.0747379454 -0.122691640 0.3450905 -0.102407731 0.114416779 -0.188480115 0.024731098 -0.224110839 -0.036705193 -0.0697731205 -0.189402920 0.2642319 -0.161843476 0.115746565 -0.166040194 0.068724964 -0.112025835 -0.220779261 0.0120029682 -0.083149450 -0.5066480 0.260520630 0.262478846 -0.290267019 0.080632270 -0.054378180 -0.154096849 0.0042190639 0.110051557 -0.6545789 0.074217208 0.290576461 -0.232408027 0.333829685 -0.097500210 -0.134497695 -0.0869242753 -0.052456320 -0.5774633 0.071893130 0.217354904 -0.150535446 0.064325771 0.004985414 0.017801279 -0.0225716598 -0.066759174 -0.6108433 0.105405443 0.349790991 -0.163838651 -0.300910254 -0.103460721 0.045917678 0.3512154313 -0.173798335 -0.6225742 0.015818600 0.276931601 -0.112348412 -0.156714309 0.086461623 0.283676355 -0.3076787991 -0.195371434 0.5917724 -0.235014489 -0.255368899 0.006650969 -0.424432473 0.116896158 0.026640961 0.0407768581 -0.024693231 0.5279568 -0.274680621 -0.187219522 -0.101549741 -0.006358423 -0.131489718 -0.307936400 0.2109326646 -0.053543527 0.4940006 -0.403112322 -0.229288093 0.053826480 -0.149052853 0.058937557 0.079736682 -0.0232532548 -0.217180572 0.5679135 -0.227968636 -0.220179480 -0.057163025 -0.401467891 0.088122223 0.046636312 0.0008630064 -0.070659460 0.4988083 -0.198023532 -0.098685578 -0.087517556 0.037379190 0.007864417 -0.112906050 -0.1261029356 -0.214195713 -0.3811688 0.142742173 -0.307097139 -0.296217542 -0.089586852 -0.090118823 -0.097821370 -0.0685454038 -0.104261189 -0.3269154 0.136263759 -0.233410980 -0.474756404 -0.138868985 0.016461123 -0.091602431 -0.0939518707 0.145870493 -0.3203851 -0.030166568 -0.245768083 -0.487202590 -0.205275498 0.037694710 0.008704829 -0.0416043160 0.183271179 -0.3520775 0.095211884 -0.336299557 -0.428447845 -0.149642422 0.056262149 -0.029658115 -0.0706184986 0.004097048 0.3651857 -0.412331552 0.368944213 -0.117631028 -0.026511108 0.073337166 -0.028056229 -0.0530975791 0.108645037 0.3703239 -0.479742202 0.476104604 -0.096721625 -0.057825485 0.071261480 0.081462466 0.0360994696 0.185563020 0.3699674 -0.421161776 0.480916968 -0.124121065 -0.078094691 0.074598867 0.047942227 0.0369657600 0.117259474 0.2463836 -0.441672543 0.339399682 -0.114323666 -0.089602239 0.133700006 0.015520059 -0.0628408544 0.141265238 0.1920995 -0.302887469 0.214310995 0.008630304 -0.010576560 0.051437400 -0.149282018 -0.0246684699 -0.103773907 0.3177906 -0.361924210 0.349591276 -0.146596477 -0.020838225 0.053217935 -0.144213470 -0.0810473995 -0.010744364 -0.4021482 -0.351959582 -0.201011400 -0.176729613 0.263077182 0.444156811 0.088841988 0.1869857115 -0.057679182 -0.4265001 -0.447290807 -0.237762488 -0.201792383 0.345792026 0.460313960 0.104878412 0.2129963667 -0.087767881 -0.3041925 -0.513476732 -0.171039751 -0.023635033 0.034697829 -0.114633165 0.097987560 -0.0090573562 0.030682748 -0.4423233 -0.542324765 -0.120056095 0.074356156 0.095296276 -0.199403042 0.027929674 -0.0202432667 -0.069660173 -0.3607007 -0.500592080 -0.174513283 0.046947376 0.037358826 -0.267136034 0.074407466 -0.0093759739 0.080036468 -0.4350645 -0.446475795 0.030254396 -0.010627044 0.101759433 -0.174325196 0.029505768 -0.0120425589 -0.050011012 -0.4599254 -0.329350786 -0.137864380 0.028873337 -0.110769493 -0.226812362 0.044696510 0.0707773605 0.146141059 -0.4702438 -0.336331662 -0.199380424 -0.044648421 -0.119115633 -0.177227803 0.122626669 0.0060156884 0.175156554 -0.3655473 -0.514596691 -0.078419787 0.097432633 0.093421477 -0.160987378 -0.093535945 -0.0298388671 -0.005968257 -0.3888139 -0.512946164 -0.095166329 0.169291414 0.033699196 -0.152326147 0.016936469 -0.0188479397 -0.086933077 In [122]: print ( hisq3 ) [1] 0.8289141 0.6015374 0.6382330 0.5680873 0.4298459 0.4542829 0.4993689 [8] 0.3025154 0.2711171 0.2100527 0.5230468 0.7217756 0.4179823 0.7903544 [15] 0.7225057 0.6674738 0.5590656 0.5417629 0.6023525 0.3814098 0.3890036 [22] 0.4633676 0.4802789 0.4611304 0.4748262 0.6541179 0.5900188 0.4340915 [29] 0.2110671 0.4064326 0.6699060 0.8747538 0.4109744 0.5645937 0.4981439 [36] 0.4339110 0.4319218 0.4673458 0.4583968 0.4845446 In [123]: loadings3rot <- print ( varimax ( loadings3 ) $ loadings , cutoff = .3 ) Loadings: [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [1,] 0.328 0.771 [2,] -0.639 [3,] -0.688 -0.300 [4,] 0.593 [5,] -0.551 [6,] -0.555 [7,] 0.487 -0.362 [8,] -0.357 [9,] -0.376 [10,] -0.326 [11,] 0.605 [12,] 0.755 [13,] 0.463 [14,] 0.324 0.749 [15,] 0.300 0.703 [16,] -0.757 [17,] -0.361 -0.509 -0.340 [18,] -0.624 [19,] -0.706 [20,] -0.327 -0.398 [21,] -0.350 -0.455 [22,] -0.647 [23,] -0.662 [24,] -0.606 [25,] 0.653 [26,] 0.771 [27,] 0.734 [28,] 0.641 [29,] 0.347 [30,] 0.573 [31,] 0.730 [32,] -0.367 0.834 [33,] -0.606 [34,] -0.717 [35,] -0.698 [36,] -0.592 [37,] -0.575 [38,] -0.578 [39,] -0.628 [40,] -0.649 [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] SS loadings 2.456 3.967 3.049 1.971 3.529 1.417 1.485 1.511 1.206 Proportion Var 0.061 0.099 0.076 0.049 0.088 0.035 0.037 0.038 0.030 Cumulative Var 0.061 0.161 0.237 0.286 0.374 0.410 0.447 0.485 0.515 Again, we can see a similar pattern to the two above methods. The iterated method also created loadings which are closer to the principal component method. There are a few differences; for instance, in the iterated method we see that the third variable is part of both the 1st and 2nd factor, which wasnâ€™t present in the principal component method nor the principal factor method. Still, the analysis from before holds: much of the expected separation is contained in the factors (or some combination of them), but there are other correlations which those four factors cannot account for. I will use the rotated matrix above to make some considerations about the level of effectiveness of the analysis. We know that the main goal of factor analysis is to acquire factors for which each variable can be loaded into only one factor. If we can do this, we have essentially reached our goal â€\" we have separated the variables completely into a smaller number of factors which accounts for the covariates between them. However, in practice, this is very difficult to achieve. In the loading matrix above, there are many instance where the variables correlate strongly with more than one factor at once -- that is there is no clear distinction between what these questions relate to in terms of our factors. This indicates that factor analysis is not doing a very good job at separating the factors with the number of factors we have used. Some Considerations In an ideal situation, we would use a very small value of $m$ relative to the amount of variables $p$. Although $m = 9$ performed decently well, it is quite a large number of factors. Even with nine factors, we see that the factor analysis was only able to account for around 60% of the covariation of the original variables. A fundamental issue with factor analysis is that the correlation matrix $R$ contains both structure and error, and factor analysis is not able to separate the two. Thus, the original assumptions of no relationships between the errors and the factors are too optimistic, as this rarely happens in practice. As a result, the loadings above are quite difficult to interpret. It is difficult to say what the exact factors are in plain English. Here, we can see some of the difficulty in working with factor analysis in practice â€\" it is often questioned if these factors truly exist. Conclusions and Relation to Psychological Tests In [124]: loadings -0.6277856 0.119554084 0.33171585 -0.0517100760 0.19589620 -0.256426344 -0.0051466920 -0.1050080325 -0.217875830 -0.6628787 -0.132540591 0.11886326 0.2214725941 0.22140567 0.132387083 -0.2481776856 0.0048103856 0.073391368 -0.6390134 -0.197196788 0.05624741 0.2311725131 0.23664371 0.106747616 -0.3142731034 0.0725529294 -0.009258277 -0.6038332 -0.001172604 0.25194869 0.0287228625 0.19716616 -0.096650456 0.2237402385 0.3933113732 0.175740568 -0.5623461 -0.075542614 -0.04215597 0.0889017298 0.31622038 0.101831072 -0.3414194020 0.0325078492 0.085362217 -0.5588305 -0.202629294 -0.02405988 0.1321338363 0.30155513 0.073081367 -0.2777839481 -0.0712005483 0.093765748 0.5610817 -0.101431288 -0.01542818 -0.4286785091 -0.17991988 -0.065822588 0.1121413950 0.1320328403 0.243711028 0.4195786 -0.089834730 0.04744726 -0.4219788203 -0.09239017 0.008179850 -0.1017128152 0.1404356750 0.359181871 0.3666707 -0.121246001 0.12235117 -0.2673284202 -0.19228688 -0.331672078 -0.1723038527 0.3330872957 -0.293884580 0.2834756 -0.191213944 0.13406289 -0.2440643282 -0.18539624 -0.106304884 -0.4565341789 -0.0821946123 -0.171057932 -0.5196860 0.270565545 0.30577781 -0.3423029175 -0.11245766 -0.001271796 -0.1320537729 -0.2283180107 0.265527940 -0.6564641 0.068827634 0.31328652 -0.2478632919 -0.34403345 0.087823904 -0.1132566054 0.0377935294 -0.011283238 -0.5998907 0.074604175 0.26507843 -0.1892944458 -0.07212877 0.033343619 0.0308950899 0.1426224411 -0.200220801 -0.6074783 0.096622639 0.34093184 -0.1742184243 0.20372042 -0.252897043 0.0281370136 -0.0346131237 -0.254485357 -0.6248483 0.011604348 0.28844967 -0.1296150311 0.17592820 -0.039241251 0.1844820354 0.4216051360 0.098786819 0.5974964 -0.234896621 -0.29156288 0.0140733681 0.45380545 -0.094810107 0.0093078526 0.0096644094 0.016502011 0.5405337 -0.286677830 -0.22708170 -0.1085333297 -0.06070240 -0.083413069 -0.3147783298 -0.2285523728 -0.186028731 0.5065189 -0.420628297 -0.27874397 0.0715082012 0.18189460 0.002006571 0.0463524348 0.3018104199 -0.260546935 0.5780675 -0.232627930 -0.26378683 -0.0556981294 0.44299196 -0.109840640 0.0355312724 0.0666607568 0.098413082 0.5219373 -0.216594655 -0.13173681 -0.1032620489 -0.04359939 0.070382456 -0.2508050668 0.2867068313 0.083829363 -0.3992462 0.160965015 -0.36037555 -0.3690507373 0.03464572 -0.123678525 -0.1924745951 0.1507108412 -0.019742963 -0.3394289 0.150689800 -0.26903653 -0.5548752336 0.16905090 0.011646505 -0.0474249609 -0.1572321905 0.166900898 -0.3320934 -0.027645815 -0.28907100 -0.5582492767 0.25327472 -0.005346193 0.1102181121 -0.1334792270 -0.157127058 -0.3658667 0.108273914 -0.38501438 -0.4940891181 0.19559323 0.064851965 -0.0003570599 0.0709592952 -0.068600025 0.3796437 -0.447822215 0.39727206 -0.1408538430 0.10110562 0.076120098 0.0523492570 -0.1131530027 0.095050608 0.3772945 -0.495954442 0.47234291 -0.1033727528 0.11469191 0.018459564 0.1824386999 -0.1389626180 -0.114702885 0.3799486 -0.444134704 0.49194137 -0.1387764590 0.13915859 0.013283974 0.1229109140 -0.0973772037 -0.116962488 0.2576489 -0.483342987 0.37297134 -0.1416818547 0.21231287 0.117125266 0.1369392140 -0.1222056233 0.146276756 0.2062744 -0.354617033 0.26543767 -0.0007295079 0.06470126 0.099806178 -0.2945216155 0.1256130100 -0.077929380 0.3334748 -0.402402498 0.39061932 -0.1902953021 0.08669907 0.083796843 -0.1520357393 -0.0181765447 0.107031691 -0.4064146 -0.347591815 -0.19534506 -0.1439862302 -0.08445037 0.611418809 0.1300478000 -0.0035088423 -0.175680364 -0.4213233 -0.421047564 -0.21614195 -0.1475954934 -0.14140091 0.569277998 0.1274642030 0.0120766707 -0.147817867 -0.3177238 -0.558528507 -0.21188225 -0.0260375231 -0.11058613 -0.064299580 0.1599389824 0.0008566237 0.011078551 -0.4535206 -0.568930452 -0.13969631 0.0740933171 -0.20728453 -0.111993462 0.0128182266 0.0851071945 0.058119259 -0.3733466 -0.534136456 -0.20889608 0.0462874732 -0.18328216 -0.242376556 0.0930813931 -0.0879622294 0.120472821 -0.4519620 -0.486894058 0.02868335 -0.0237170894 -0.22067245 -0.121746325 0.0211133535 0.0949324784 -0.117122331 -0.4792771 -0.359058583 -0.17026707 0.0243226733 0.01058587 -0.329825553 0.0814961168 -0.2338333561 0.027777255 -0.4884591 -0.361002718 -0.23670362 -0.0576248626 0.04542125 -0.266631231 0.1774163361 -0.1496133363 -0.028050715 -0.3794872 -0.555721465 -0.09478251 0.1039076241 -0.19174868 -0.083409801 -0.1393220930 -0.0449142959 0.188743726 -0.4024135 -0.549377337 -0.11356106 0.1869168187 -0.12464387 -0.136300169 -0.0389545949 0.0957233294 0.133687572 We know that the original variables were constructed considering four groups (assertiveness, social confidence, adventurousness, and dominance). These were the intended characteristics that the statements were testing for. Above, we can see how factors 1-5 capture a lot of the variables in each set. So, we could say that factor 1 represents assertiveness, factor 2 represents dominance, factor 3 and 4 represent adventurousness, and factor 5 represents social confidence. However, this would not be so accurate, as there are other factors to consider as well. We can see that factors 6-9 have members from all the different groups. This suggests that the relationship between the variables was not so simple as we once thought. Additionally, variable 10 failed to have a loading greater than .3 into any of the factors, which suggests that even 9 factors are inadequate to capture the variation in the data. In this example, which seemed relatively straightforward, we see that problems emerged quite quickly. What, for instance, is factor six? And why are factors 3 and 4 separated? It is not so clear that our prior ideas about the factors are accurate. One thing is clear, though. The four factors used to create the questionnaire are insufficient to truly describe the structure of the data. To say that these statements measure these factors would be jumping to conclusions too quickly. Doing so is, in a way, oversimplifying the data. In conclusion, we have learned that this dataset cannot be so simply separated into the four purported factors. In fact, even separating the variables into 9 factors can only account for 60% of the variation of the variables. We can see that while factor analysis is a powerful technique, it is very dependent on the dataset which it is performed on. The self-checking property of the assumptions of factor analysis ensures that only models which fit the assumptions will produce results which separate the variables adequately to the different factors. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Projects","url":"category/projects/Factor Analysis.html","loc":"category/projects/Factor Analysis.html"},{"title":"Summary Statistics Part 2: Measures of Spread","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Measures of Spread In the last post on central tendency , we discussed the basics of what a statistic and a population is as well as the common measures of central tendency, the mean , median and mode . In this post, we will dive deeper into how to describe sample and population data using Measures of Spread. When we talked about central tendency, we discussed the idea behind the \"average\" observation in a pool of data. When it comes to describing a dataset, the central tendency is a great place to start -- it gives us a sense of the location of our data. For instance, if we had the weight of a variety of individuals, we can get a sense of what a \"typical\" weight might be using measures of central tendency. Alien Brains Imagine you are an observer who knows nothing about a particular subject. Let's say this subject is the number of neurons in a sample of aliens' brains. Or, you know, something. Based on this information alone, an ordinary, human observer would have absolutely no sense of where to begin. That is, we have absolutely no prior information about aliens' brains. Let's say the sample of neurons in 100 aliens found in the first UFO crashing ever known to man look something like this: In [1]: import numpy as np import pandas as pd import scipy.stats import plotly.offline as plt import plotly.graph_objs as go plt . init_notebook_mode ( connected = True ) window.PlotlyConfig = {MathJaxConfig: 'local'}; if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});} if (typeof require !== 'undefined') { require.undef(\"plotly\"); requirejs.config({ paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min'] } }); require(['plotly'], function(Plotly) { window._Plotly = Plotly; }); } In [47]: alien_neurons = pd . Series ( np . random . negative_binomial ( 424242 , . 0042 , 100 )) In [48]: data = [ go . Histogram ( x = alien_neurons . tolist ())] layout = go . Layout ( title = 'Alien Brains' , xaxis = dict ( title = 'Number of Neurons' ), yaxis = dict ( title = 'Number of Aliens' ), bargap = 0.2 , bargroupgap = 0.1 ) fig = go . Figure ( data = data , layout = layout ) plt . iplot ( fig ) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"09ae3301-bd44-49a0-9519-dfd56c1467c5\")) { Plotly.newPlot( '09ae3301-bd44-49a0-9519-dfd56c1467c5', [{\"type\": \"histogram\", \"uid\": \"5e303c3d-e696-4e70-9952-95d4879c4f01\", \"x\": [100507682, 100601005, 100336496, 100623165, 100754041, 100856570, 100702398, 100729273, 100411299, 100556471, 100697638, 100540953, 100411717, 100478614, 100574488, 100499210, 100852747, 100651745, 100697942, 100484243, 100397057, 100552299, 100388278, 100785268, 100546213, 100522820, 100426863, 100282560, 100397992, 100590144, 100248387, 100545909, 100517592, 100687610, 100657954, 100568996, 100569742, 100442644, 100411784, 100579139, 100520273, 100738283, 100342396, 100445818, 100624941, 100764764, 100430309, 100737396, 100761735, 100353133, 100467783, 100533562, 100415755, 100564377, 100444869, 100578210, 100630623, 100761510, 100550665, 100546729, 100360033, 100672311, 100472937, 100750441, 100616384, 100577225, 100397447, 100554639, 100617736, 100420158, 100568391, 100779155, 100415724, 100318415, 100496400, 100483601, 100511965, 100398418, 100613111, 100467889, 100696693, 100689413, 100656193, 100412745, 100548172, 100419812, 100603947, 100631853, 100453490, 100657843, 100290953, 100387413, 100512580, 100223744, 100436972, 100392013, 100836090, 100636159, 100540619, 100668141]}], {\"bargap\": 0.2, \"bargroupgap\": 0.1, \"title\": {\"text\": \"Alien Brains\"}, \"xaxis\": {\"title\": {\"text\": \"Number of Neurons\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of Aliens\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('09ae3301-bd44-49a0-9519-dfd56c1467c5'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); Woah! These values are in the hundreds of millions! Well actually, the human brain has over 100,000,000,000 neurons! So, this alien is not the most sophisticated in terms of neurons. Is there a way to see this, the location, more quantitatively? Your answer should be ... yes! Using the techniques we learned last time, we can find the mean and median of this distribution. To spare the agony of performing this arithmetic on such huge numbers, we can use pandas to find these values. In [49]: alien_mean , alien_median = alien_neurons . aggregate ([ 'mean' , 'median' ]) print ( '''Mean of Alien Neurons: {} , Median of Alien Neurons: {} ''' . format ( alien_mean , alien_median )) Mean of Alien Neurons: 100544873.04, Median of Alien Neurons: 100546471.0 This means that the mean of this sample is 100,584,186.03 and the median is 100,592,749. These values are quite \"close\", which is expected because we see that the distribution is somewhat symmetric. But... wait a minute! How are we certain that these two values are \"close\"? We can look at our histogram to see if this assertion is correct. In [50]: alien_mean - alien_median Out[50]: -1597.9599999934435 In [51]: data = [ go . Histogram ( x = alien_neurons . tolist ())] shapes = [{ 'type' : 'line' , 'name' : 'Mean' , 'line' : { 'color' : 'red' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : alien_mean , 'y0' : 0 , 'x1' : alien_mean , 'y1' : 20 , }, { 'type' : 'line' , 'name' : 'Median' , 'line' : { 'color' : 'black' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : alien_median , 'y0' : 0 , 'x1' : alien_median , 'y1' : 20 , }] layout = go . Layout ( title = 'Alien Brains' , xaxis = dict ( title = 'Number of Neurons' ), yaxis = dict ( title = 'Number of Aliens' ), bargap = 0.2 , bargroupgap = 0.1 , shapes = shapes ) fig = go . Figure ( data = data , layout = layout ) plt . iplot ( fig ) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"3e5aed8e-0899-454d-b71a-f03f955e1bc1\")) { Plotly.newPlot( '3e5aed8e-0899-454d-b71a-f03f955e1bc1', [{\"type\": \"histogram\", \"uid\": \"0d4397e6-67cb-403d-8f39-c79630522a63\", \"x\": [100507682, 100601005, 100336496, 100623165, 100754041, 100856570, 100702398, 100729273, 100411299, 100556471, 100697638, 100540953, 100411717, 100478614, 100574488, 100499210, 100852747, 100651745, 100697942, 100484243, 100397057, 100552299, 100388278, 100785268, 100546213, 100522820, 100426863, 100282560, 100397992, 100590144, 100248387, 100545909, 100517592, 100687610, 100657954, 100568996, 100569742, 100442644, 100411784, 100579139, 100520273, 100738283, 100342396, 100445818, 100624941, 100764764, 100430309, 100737396, 100761735, 100353133, 100467783, 100533562, 100415755, 100564377, 100444869, 100578210, 100630623, 100761510, 100550665, 100546729, 100360033, 100672311, 100472937, 100750441, 100616384, 100577225, 100397447, 100554639, 100617736, 100420158, 100568391, 100779155, 100415724, 100318415, 100496400, 100483601, 100511965, 100398418, 100613111, 100467889, 100696693, 100689413, 100656193, 100412745, 100548172, 100419812, 100603947, 100631853, 100453490, 100657843, 100290953, 100387413, 100512580, 100223744, 100436972, 100392013, 100836090, 100636159, 100540619, 100668141]}], {\"bargap\": 0.2, \"bargroupgap\": 0.1, \"shapes\": [{\"line\": {\"color\": \"red\"}, \"name\": \"Mean\", \"type\": \"line\", \"x0\": 100544873.04, \"x1\": 100544873.04, \"xref\": \"x\", \"y0\": 0, \"y1\": 20, \"yref\": \"y\"}, {\"line\": {\"color\": \"black\"}, \"name\": \"Median\", \"type\": \"line\", \"x0\": 100546471.0, \"x1\": 100546471.0, \"xref\": \"x\", \"y0\": 0, \"y1\": 20, \"yref\": \"y\"}], \"title\": {\"text\": \"Alien Brains\"}, \"xaxis\": {\"title\": {\"text\": \"Number of Neurons\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of Aliens\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('3e5aed8e-0899-454d-b71a-f03f955e1bc1'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); Well, they look pretty close. However, this is far too hand-wavy of an answer. In determining the \"closeness\" of these two statistics, we would like to have an objective measure relative to scale. The actual difference is around {{alien_mean - alien_median}}! With just that information alone, we would likely not say that the two are \"close\". If the difference between what you got in a paycheck was \\$8,563 less than what you expected, you would definitely be upset! The more we think about it, relative differences like these are reliant of the <b> scale </b> of the numbers we're talking about. 8,000 stars may be astronomically small compared to the total number of stars, but \\$8,000 is significant to most people! However, because of the scale of this distribution, this is not a large difference relative to the differences in observations. Imagine we had a distribution that looked like this instead: In [52]: log_norm_sigma = 1.158 log_norm_mu = np . log (( alien_mean - alien_median ) / ( 1 - np . exp ( ( log_norm_sigma ** 2 ) / 2 ))) sim = pd . Series ( np . random . lognormal ( mean = log_norm_mu , sigma = log_norm_sigma , size = 100 )) In [53]: data = [ go . Histogram ( x = sim . tolist ())] shapes = [{ 'type' : 'line' , 'name' : 'Mean' , 'line' : { 'color' : 'red' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : sim . mean (), 'y0' : 0 , 'x1' : sim . mean (), 'y1' : 50 , }, { 'type' : 'line' , 'name' : 'Median' , 'line' : { 'color' : 'black' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : sim . median (), 'y0' : 0 , 'x1' : sim . median (), 'y1' : 50 , }] layout = go . Layout ( title = 'Not Alien Brains' , xaxis = dict ( title = 'Counts' ), yaxis = dict ( title = 'Volume' ), bargap = 0.2 , bargroupgap = 0.1 , shapes = shapes ) fig = go . Figure ( data = data , layout = layout ) plt . iplot ( fig ) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"4cd22171-3ebd-468e-8ae1-f7c03abd1a07\")) { Plotly.newPlot( '4cd22171-3ebd-468e-8ae1-f7c03abd1a07', [{\"type\": \"histogram\", \"uid\": \"6bf4918b-be79-4c0a-9ccb-068d3fd435da\", \"x\": [1815.2961130358603, 2320.218549594198, 1774.238950351985, 10129.329569604373, 1291.3107998367987, 223.3226019797967, 511.1190584745391, 2539.1462070254247, 1691.7984992130866, 3932.300750670352, 6793.957503120814, 1535.0287569346979, 2022.8973728018339, 1053.8154762349425, 973.5181073035899, 323.6513923572703, 9726.847031775475, 7135.352086198367, 3512.474945472328, 6227.505350176736, 13244.888216522466, 2867.9361099027983, 807.5146428567614, 2894.549648576427, 2244.178387714029, 3257.1038221480812, 1736.2230124900836, 924.3957750430835, 3939.8535567342283, 203.32884083827767, 14045.997332778845, 546.2147123850925, 417.5538715626165, 107.90409001348492, 1704.8438615097614, 113.8419174685519, 2439.006413127879, 1843.269218713016, 808.3472313135118, 866.3462227327186, 1505.053252145675, 1046.5330708322601, 2068.027719683339, 251.17616713782976, 141.12043094440338, 819.6818612377483, 2020.2503585291886, 417.7717118081688, 1978.642699972511, 4152.00901968332, 7141.121777756109, 294.25439730884705, 5055.263403490116, 2359.4096263832603, 737.0583169703585, 756.5588683955067, 1688.1995118447353, 1200.3525822057034, 5537.486837091894, 3052.5661838992432, 716.0370763823562, 9048.079440812544, 235.87876321395117, 779.4247291113422, 376.7574206190164, 1871.9125744152384, 1405.5064649823244, 1715.8137527463932, 8766.403226820257, 21225.42670423942, 4486.2549196354785, 416.20474169790657, 1517.5508166911504, 1267.3033729274018, 1133.9330477820738, 389.8746550213425, 67.45747393366179, 486.5432413205892, 7031.818751334337, 2086.3679690315575, 2097.541446182641, 2840.221558126296, 2919.222008028245, 5299.136151360571, 14501.064835070783, 1688.2746230691446, 3801.6947174533625, 1643.3099010076398, 204.99257950344463, 8409.984220817802, 1017.3364757112194, 1338.7638173892342, 404.5430086683285, 2607.930463755532, 171.50491673765143, 464.69817123005356, 2333.719993719836, 8551.131279451381, 8005.88791102838, 945.8413547396598]}], {\"bargap\": 0.2, \"bargroupgap\": 0.1, \"shapes\": [{\"line\": {\"color\": \"red\"}, \"name\": \"Mean\", \"type\": \"line\", \"x0\": 2970.40312379684, \"x1\": 2970.40312379684, \"xref\": \"x\", \"y0\": 0, \"y1\": 50, \"yref\": \"y\"}, {\"line\": {\"color\": \"black\"}, \"name\": \"Median\", \"type\": \"line\", \"x0\": 1710.3288071280772, \"x1\": 1710.3288071280772, \"xref\": \"x\", \"y0\": 0, \"y1\": 50, \"yref\": \"y\"}], \"title\": {\"text\": \"Not Alien Brains\"}, \"xaxis\": {\"title\": {\"text\": \"Counts\"}}, \"yaxis\": {\"title\": {\"text\": \"Volume\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('4cd22171-3ebd-468e-8ae1-f7c03abd1a07'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); As a sidenote, the way this distribution was simulated was using the fact that we want a relative difference in the mean and median in the population to be equal to 4,692, but on a completely different scale. This was using the lognormal distribution, which is a skewed distribution, so it works well for this purpose! In [54]: sim . mean () - sim . median () Out[54]: 1260.074316668763 We can now clearly see that the absolute differences in the mean and median (and in fact, any of the observations) is not sufficient to describe their \"closeness\" to one another. We have an idea of the location, but we need a sense of scale. Why does spread matter? We can already see why the measures of central tendency are insufficient to give us an idea of what a distribution looks like. To investigate further, suppose we know only that the mean of some observations is 100. What else can we say? Well, not much. Consider the two distributions below. Both populations have mean 100, and we sample 100 values from them. The resulting samples have means very close to one another (and to 100), but they are quite different from one another. In [55]: ex_1 = np . random . normal ( 100 , 2 , 1000 ) ex_2 = np . random . normal ( 100 , 10 , 1000 ) data = [ go . Histogram ( x = ex_1 . tolist (), name = 'Less Variant' ), go . Histogram ( x = ex_2 . tolist (), name = 'More Variant' ) ] layout = go . Layout ( title = 'Mean of 100' , xaxis = dict ( title = 'Value' ), yaxis = dict ( title = 'Volume' ), ) figure = go . Figure ( data = data , layout = layout ) plt . iplot ( figure ) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"a88eee82-3b22-4b01-91c5-078e071902a1\")) { Plotly.newPlot( 'a88eee82-3b22-4b01-91c5-078e071902a1', [{\"name\": \"Less Variant\", \"type\": \"histogram\", \"uid\": \"cd804516-5933-4b30-8d43-5368731efb3d\", \"x\": [99.38985063430285, 101.57786997499045, 97.72968143733631, 99.86580330462117, 100.60960920723952, 100.19453843583749, 96.14296686632719, 100.59489116884787, 100.79960125344947, 96.78428505718558, 100.88431320876047, 101.52795885924196, 105.11729638701253, 99.78278860078109, 101.94979113335262, 101.30040677656582, 100.7981603365975, 98.11092706313588, 103.81120439531075, 99.99592649465478, 99.54972840142521, 102.14961489695646, 97.84711040334989, 98.69080905636176, 100.9285751715484, 98.62453699252728, 103.01285415600354, 98.51624277879884, 103.72942185391707, 101.17529057976235, 95.98686715938096, 101.31601098895142, 102.49229107346395, 101.4496615249436, 98.80405885552159, 98.49051805196775, 99.1399871367666, 97.8015925835382, 100.84652325966319, 100.08310020142484, 98.4132768693645, 101.54316396735918, 97.30493791107776, 96.27348748649298, 100.13335813121893, 100.3285548025085, 98.84662985037437, 100.7272311527272, 98.47490870962213, 99.2967072141941, 102.73220474008569, 100.50081336942448, 99.77013647996544, 101.92007881250333, 101.22863755101332, 100.47705319838887, 101.70007801886027, 98.07547145042764, 99.40716146133559, 99.20009011505581, 101.72254567906432, 98.9121627309853, 97.06266852781866, 101.723942091344, 99.58394184180534, 99.3516411315752, 101.58884664569797, 105.56907438054824, 98.36756472424071, 98.18507409242244, 101.39468099483311, 100.89643536907528, 97.21583832914551, 99.4366972547168, 101.56147268571033, 100.99359050057646, 97.80383323203893, 100.46753304561882, 97.85746988561115, 98.93940422866456, 98.79150309498202, 103.72196238766342, 96.99136684807735, 101.05279092687236, 102.89765018866271, 99.26834347235435, 98.55094513307607, 104.52169863583735, 97.63532300996613, 99.75189898076216, 100.23984726502461, 98.84189611017986, 101.63368523942097, 96.85284210396466, 99.46999277861187, 98.12674874974371, 98.4091133525268, 101.62117678084844, 99.27677781645458, 99.93389848055523, 102.5062027779343, 96.55330998287909, 98.68351558318946, 104.1711586949174, 101.03496544300732, 101.62148895462812, 103.00024738394939, 99.55614965720176, 103.80997939430576, 100.87167421615271, 101.70229155966388, 99.91308548809646, 99.49549951820755, 102.79181315903448, 96.17116110917587, 97.79067974752527, 102.74617561525653, 96.66871571457919, 99.1607132887049, 101.83161724885281, 96.0129604044558, 97.51391480090884, 96.29772688396284, 98.43796151550445, 97.11723356238775, 96.15608356592425, 99.72072112381368, 100.96750319612829, 99.505567696941, 99.6656175745221, 99.7183349290162, 100.43341128038664, 103.40035099307175, 102.09688998317591, 101.32034204842762, 99.40172373750859, 98.39276036743551, 99.66487517521014, 101.59480697847606, 102.54589543087482, 101.93713263714861, 95.61246206553875, 100.69716286410907, 99.029911189909, 100.27780808146564, 94.173961800972, 100.99349036602196, 101.43583825200591, 100.94988246844945, 101.25404674309202, 101.1007803130729, 95.10587506534067, 100.85073978945994, 102.12400481116265, 102.60955713919762, 98.63148176716241, 99.22846570364533, 100.61379184814345, 99.70628421920621, 99.10080879523, 100.65035861733317, 98.86669309287747, 97.75766042088495, 102.11468618583919, 98.60685660364614, 99.64878848555192, 97.53216473840615, 98.25047360104763, 105.54288676491058, 103.06478809457082, 100.71820388038027, 101.3352752958592, 99.29257430914025, 100.94241524441804, 100.23680808021493, 96.90249696657793, 102.54083618174684, 98.2575379266819, 101.47707679903044, 98.7041491136464, 101.69008569282404, 101.27086844816654, 98.68325487430484, 101.78641689543791, 98.98825416098006, 100.68480852497868, 99.19211460990238, 100.64985453384712, 102.95819317571875, 104.71870102075711, 99.90446033369464, 99.40382857029161, 101.16048706698407, 103.58267934515808, 97.73543165193128, 103.77932755658756, 96.12319334624699, 101.75256301505203, 99.4433331869735, 99.51306927927915, 98.03976409346427, 102.17778311826139, 103.74564685462627, 100.88172143972355, 100.36263088554712, 97.58709007419745, 97.93215566853766, 101.11746627207349, 96.81493430582243, 96.93476084702779, 96.57692387504544, 102.29198305004198, 102.35121757128967, 99.5945522341328, 101.75077102491686, 100.8783991372796, 104.27648255371912, 103.3267478840224, 99.54426756994106, 97.68029934799867, 103.50830704716047, 99.88903754198299, 101.37723905897502, 99.55543683116076, 98.74017739979784, 103.48809657776664, 99.47290101615138, 101.78034177036876, 100.88917456891747, 97.69012039623199, 97.6344340810314, 103.27833978446438, 101.7158807674536, 100.92447460533202, 99.78490232596889, 102.83420392480559, 96.98579021427527, 100.60814903386371, 95.82667224781564, 99.01403610388188, 102.07455726724085, 97.34168517627394, 101.39903042091802, 99.69456459799996, 101.35609040451165, 101.43134801620165, 98.68912976735274, 95.21497197212017, 94.88363130156515, 96.39217313800576, 102.91228768856787, 96.57508716010578, 98.1949369042508, 101.04704445803841, 98.49112943560789, 97.6046381020529, 102.46079688884342, 99.73944643548506, 98.67100311455246, 99.8468777375295, 100.03333844424816, 101.63047325286024, 102.93234042331521, 100.5009207527822, 101.3431042122024, 100.62038551017115, 102.4085215760305, 102.1160868650908, 99.38171051077725, 102.08341059846808, 97.75684560166783, 99.35427795597039, 99.5452753032954, 95.77086439217383, 97.20703300825522, 98.7438172557698, 98.36634150431308, 102.38512962078077, 100.17412707667064, 98.48837546829563, 101.54963561627676, 97.76789756713804, 100.15355281899447, 100.36645694121574, 102.74409147206804, 100.6313196999039, 98.61278933824977, 97.38891258407467, 100.40734505473472, 99.80484281826254, 101.02517097096992, 102.35962003100316, 99.49032226929641, 98.06666684169309, 101.64087693367004, 98.62577514868852, 100.87658338132968, 99.30592439267039, 98.43856922341368, 103.4636633169931, 99.71181310716688, 100.81781835518514, 99.58770638841585, 100.80038570842196, 100.86762070290507, 103.28332743893915, 100.1607176177553, 100.31484534553036, 101.01432413293583, 99.8811180780776, 103.60818540966935, 102.10043223096135, 100.2779602631504, 100.35047003957315, 99.22115207477287, 100.08390595479887, 100.87122191893741, 99.16484591229346, 100.28285738924258, 102.00696455205868, 100.68511317487807, 97.38285515611902, 97.67305629443642, 101.61251112673274, 97.17573478863653, 99.47868644657257, 97.38589854017475, 102.73059516777913, 99.4593507146707, 104.47452751400799, 99.82033180952534, 102.3040890894644, 99.36933579076445, 99.08985027562214, 101.23989227292012, 106.24502704866094, 100.72527936594945, 100.13385293552886, 101.4959486237657, 102.11770573436651, 99.96010773701137, 101.77041621599915, 101.13548099329466, 98.92398503737643, 100.35911861106213, 101.69194268493204, 102.63158081233063, 99.09438796024295, 99.33111904717236, 101.41903699964948, 99.78998664885303, 102.35203933812204, 101.16490942359496, 100.49766257928351, 99.93923283419822, 96.90225921991666, 100.87582653862667, 100.88171775951172, 99.36192062599764, 100.74845986708647, 100.91889405546378, 99.03758521615718, 98.36789343326531, 98.66670201509233, 103.34758971151857, 106.55770337242518, 98.27284560806446, 99.347990419899, 99.78139630131685, 99.94254867780775, 101.62249855588288, 98.64949067173895, 98.08339234007401, 97.25167901011757, 94.5798212594745, 98.72240648471643, 100.0050822184239, 104.1812302669573, 99.6947434633773, 98.67857796184133, 97.95774204927216, 98.3541574715511, 99.33632515851536, 102.85274195603499, 97.21871324389701, 101.30894287913416, 100.81563311958479, 101.98549412865911, 97.97501909626597, 100.90917611867204, 99.00210493890044, 98.70774312106819, 99.19279908743121, 100.99045475577248, 102.04906538675885, 99.1763686465721, 100.86276524853365, 101.47716742648687, 98.28592773895535, 100.91217143933379, 98.14694801004852, 99.77624104409315, 97.893532825537, 97.43891975267452, 101.9263509033096, 99.35976290884923, 104.48173631370707, 101.91901117994045, 104.4595411234753, 100.98854270139636, 97.1746067199248, 99.78043447160283, 100.51523579242537, 101.2264566096604, 98.74928116606486, 101.52153831515398, 96.96280729869083, 98.22098196246709, 96.77498923687752, 98.83833585358136, 100.77561794988961, 104.13793997029916, 102.79542639776308, 98.98656584473403, 98.21796583800881, 100.91374125686251, 97.38070129406147, 97.48643945184662, 101.36607514545595, 99.15451271656823, 100.49957733276968, 100.66716314538684, 102.12273296373348, 99.37979737373347, 102.60361862611946, 99.17960170517313, 100.55573747272209, 100.8585646167549, 96.64495611092951, 99.32575321221765, 99.54544781340738, 98.83552147514112, 97.8970108117513, 101.64053366968191, 101.13937787010374, 100.11681555365764, 99.38937447237033, 101.28456566898025, 99.04539153726344, 101.83592968278927, 101.5313887994313, 98.9324490693168, 97.74944919059396, 97.78175555251148, 99.36822352977467, 100.33888405632806, 99.3738813071264, 100.86860219252678, 100.98937760019795, 99.26336324882813, 99.49533334999863, 98.61036351981988, 103.55722613021084, 100.4162739709045, 105.5069583997027, 98.93390669472325, 99.26254586811466, 100.31061347393239, 102.57257699178996, 99.26090046380818, 100.98871634710281, 100.81822650259971, 99.85194274457025, 103.60539019316558, 100.06484016983435, 99.28110510530183, 97.82837288045641, 103.37478276801026, 102.40013347268514, 100.11282381576821, 98.39614246571278, 102.67748606003913, 99.28146954847341, 101.49130339759203, 101.62596325250713, 100.81261657152808, 98.77990610617516, 96.30138212833116, 104.0112237453227, 99.88265112546786, 97.62169612833395, 100.9213783339792, 101.90307860628455, 99.9182077851164, 101.55917717627453, 101.03462186416988, 101.71351001362152, 103.08309855421226, 102.26418046478173, 102.29516309990201, 98.89865320344028, 98.93088840748827, 100.97689264562227, 100.67826491130853, 99.13413358080992, 99.75091536439571, 101.65043065983896, 100.87718247265718, 101.27492961000188, 98.27675812834838, 99.38738396323687, 99.77387739865502, 99.0903465384263, 100.28494909613575, 103.70326881739322, 100.94601602292532, 99.7129099380836, 98.32436911157251, 101.4180143287251, 98.0492490228789, 100.67328036468105, 97.49622566908269, 102.02767937073554, 99.83429771642737, 101.9543617748643, 99.43475739466726, 100.31904518706824, 100.77971641629671, 99.46078720120413, 98.27016704394465, 99.9234835169607, 100.30410855999112, 100.05029929041832, 103.26717001368236, 98.32623942494408, 93.62358933294006, 99.04126220755256, 98.75970938834075, 100.23379802446668, 100.45047554080844, 101.75819611517646, 102.88783682728902, 100.88963349435524, 99.92221279379625, 101.83033483834137, 101.2559326750179, 95.02740943516469, 97.898264393683, 98.67906379646166, 100.3509145743557, 100.81948064477966, 101.80668501465112, 99.85989623465892, 99.63132266233644, 99.28665265127385, 98.58029538344553, 99.17994183742063, 93.75904575239618, 98.76789213830028, 98.14306520961989, 102.38067036515652, 100.42566956031217, 99.12183653000109, 96.68069216325586, 99.85224507092212, 101.18188315832421, 99.45022962825392, 101.19784588842327, 101.62937515016753, 100.4049314891664, 103.22282107576792, 98.04180628156497, 98.0928767158373, 103.34548239988806, 98.43043027197606, 97.07757107607893, 99.1243640324516, 100.47832975925232, 99.83857115735982, 98.40578762898326, 97.35777656339476, 99.82208493144468, 99.63309800114808, 100.52973691932871, 96.71775495427305, 100.67404434019907, 103.15502239924292, 104.7916618665655, 98.39881742018808, 98.45918184555572, 101.90771292350625, 100.7707777026058, 101.4076371045119, 97.77045498290032, 102.64881012611676, 97.76031380750241, 101.71615333215797, 97.7156710162573, 103.03349595101525, 97.2926868618868, 98.59062315027161, 98.877704675408, 100.41649888219139, 100.13155090048349, 102.31595679995252, 98.17498698124868, 95.01601211173302, 97.51049834204254, 100.01676844327905, 101.10727181301822, 100.14836551559526, 97.77592282087936, 99.94885490625572, 96.89588772275155, 99.70285691761075, 99.58830887250369, 99.49870945181159, 98.04741192935208, 98.4614102176901, 99.26789346026494, 101.5580854039631, 97.45651703313172, 102.33904980053693, 101.22168316783294, 99.35492954180818, 97.17505240264828, 104.25328027662601, 104.44256167458394, 96.72059079645769, 99.75754314133385, 98.59959794832868, 101.62871630006268, 98.09591979720423, 95.88818898602703, 98.25039715293131, 98.5755528602176, 99.57637060554296, 103.45667366629691, 99.11051786180218, 97.02226670159, 99.92301813389513, 99.77942042910868, 103.68433790432925, 99.90679202570266, 97.76415791987922, 99.90831800628598, 95.57929322350526, 99.60621459719027, 100.03005128357036, 98.29587594572389, 98.72292490141422, 101.4688796614303, 100.37960247595015, 100.80422786971772, 99.16930820267523, 98.61321638524902, 99.23875360163228, 100.94723164282942, 97.71412611628936, 98.28869446245601, 100.9131820930372, 102.30921956871968, 98.39499089766095, 98.82091433186633, 97.63708305898354, 102.07823385326711, 99.26039472437175, 97.26053323198799, 97.04725591372595, 100.40205156754601, 98.86477933847449, 98.65000119332848, 102.02884674249006, 102.81776482946498, 100.75544268467496, 101.37888894677748, 96.01404062705686, 100.10577004876725, 99.10167416571409, 99.6774047515595, 95.2980516008471, 100.41723692241435, 97.74225988094896, 103.64724743301255, 103.50865823704702, 96.9172929805946, 98.41813791808312, 101.17533227708496, 106.09416040212925, 99.13051427005648, 96.81198419760112, 99.00830989958351, 99.46314710501565, 98.68271181921239, 100.1440025874165, 102.97997657871089, 99.12479608800425, 102.88196589921971, 99.14103832525625, 98.7632585204249, 102.60664159173912, 99.97194613194513, 102.24922483884366, 100.61564841485225, 96.7755798694279, 102.625665936032, 100.79104112325916, 102.66959011988621, 98.52443917391811, 98.55871675603794, 102.82066502980274, 98.44412382367933, 96.63085895880951, 99.6839087191096, 100.71995988427484, 100.37623256270693, 101.25664304939815, 100.20172583280429, 101.13576747038711, 99.43801110025132, 100.91093143857995, 96.13459933658928, 99.14247119517346, 99.96140240179555, 101.06911899864218, 101.65502163740598, 98.31925543251852, 99.59074809853715, 98.17064324711095, 102.30688771331724, 101.38180411111806, 100.6633245407797, 99.43798533190244, 102.42747825082942, 95.47622669311582, 100.05266853002402, 98.71119720301516, 97.22961810789967, 101.55434720574833, 99.96552774737069, 99.69552680260489, 101.4457926203741, 100.53857261911766, 99.92389194317278, 103.01039853384009, 101.00421022437018, 103.48986695715325, 100.03042181028154, 99.46427802480613, 99.60528050340311, 98.88232872146052, 99.3544166402612, 98.25017783284716, 101.22881943093486, 100.94435141584121, 97.99150609880763, 98.39629441452117, 98.48254257559621, 98.51285209636008, 99.28448952373479, 97.76473074997762, 100.39535868171448, 99.92000452027355, 99.07121565390005, 101.63717413983336, 96.26065237737464, 102.44315909250055, 99.38402098666157, 100.76996373732672, 100.53955161947239, 100.62631570319476, 98.52104581926025, 100.35931973405867, 99.75010232245866, 100.28446226730011, 97.33693496262333, 98.5062891608646, 101.42939618652935, 100.77489320797991, 97.631227142456, 100.73857004321258, 99.91888936986497, 101.03429017013336, 101.81045394501724, 101.03143881491486, 97.85550833109582, 98.16765616590695, 99.48780924497802, 98.95770649495104, 94.70770007128019, 97.25100472909536, 100.99492644347802, 102.24374249341842, 103.87602458214405, 103.91724635534719, 101.01985269866296, 102.96856349271745, 98.63183408477016, 98.18549188191174, 98.92740505017291, 100.89179483531132, 97.94771938856475, 99.88936357072124, 98.02952264394911, 101.5653187583849, 98.01969998472917, 97.61329650129136, 102.40977464116575, 104.76071773012167, 98.52312491398152, 99.94567952115986, 98.48537766344938, 97.53459727861524, 98.1962681293708, 101.19401571073887, 102.84566104276622, 100.82161518254439, 103.83586872903409, 102.16742832662715, 101.87929733108254, 98.2088838733555, 97.91501257267805, 103.21497993593348, 103.07466790476981, 99.55803329585153, 99.46906985515224, 101.70471714175642, 97.48700800144323, 99.53535548609038, 102.20967756989165, 103.15450413486283, 102.02150032472504, 100.7065287269127, 101.34056671079004, 100.0495790497201, 102.25865145950883, 100.47098948898915, 102.78116983592648, 102.49083008274206, 101.62607766198123, 100.98649245325495, 101.58342363980758, 106.32774536965324, 101.96469149950062, 99.46826394172547, 97.95590203974027, 101.70810049278599, 100.08795799156391, 103.64780598705636, 100.72443645573189, 98.50184301073419, 98.63727783208606, 100.09200036089116, 104.2421324141655, 99.73635114289027, 100.19184101786858, 102.27727183814822, 96.54000733351884, 100.37673072856398, 95.49155323435575, 99.68242572489858, 100.03769209684891, 102.47377829428662, 102.94722514107482, 102.02432926220952, 96.6430482571296, 96.80621617701182, 99.87773239753466, 100.0100852613154, 105.72057776718337, 101.59906303309113, 97.3597676623383, 97.98057574573741, 97.89238219978132, 99.95880769929038, 97.61275859035455, 102.39086979779798, 101.50387463124618, 103.74954812121433, 101.21889102016567, 98.89404302312282, 98.95538478002682, 96.27860635943603, 104.0790044211415, 96.99007544790693, 101.71782585470766, 99.13854685228705, 100.14542366344857, 100.65409485329279, 103.56158010244285, 98.26398480996168, 101.4500193986171, 93.63377169219267, 96.86222741191332, 101.97705770570327, 97.53330035454753, 98.46928681303606, 100.27931865670142, 102.73720486894896, 96.72935291049387, 97.34169465613353, 98.54229825144327, 98.06343628524019, 98.07293091448469, 102.96540222138368, 99.14742066468561, 102.19690168526294, 101.28752509169945, 99.65470634826258, 102.47383033882984, 102.91058312856082, 99.93021324657109, 102.85306611213167, 98.2540801576289, 97.72312850456207, 101.51696003279982, 101.20610652722807, 102.88529164401575, 103.17500262481379, 96.9891192395991, 99.71072719290865, 99.7110004064626, 101.87323056701152, 99.77434153574104, 99.13291791474181, 99.6086767768662, 101.06977936759814, 97.82393070908353, 101.47724014795251, 100.83061135499392, 100.5205915266927, 97.78588005089883, 98.93902583741536, 99.28110442563933, 98.18825266649893, 100.52744080082157, 98.1535793620085, 103.57176868672094, 99.02887311972175, 100.2128738168785, 102.2566301068492, 102.41333998877303, 99.0410423052204, 105.34365738005079, 105.57137081938636, 100.47333246007602, 98.23176887588689, 99.29846460708637, 102.58928605981232, 103.04822754789994, 100.87836673237045, 95.13672106076618, 100.46950682959506, 99.15953357473168, 99.26006268983078, 98.80745540516448, 99.23974752885275, 101.4211908911432, 98.35699321387358, 97.67817156091888, 99.06003833914254, 98.0682197340053, 101.59450650854446, 101.61679068394028, 99.04060507801879, 98.67991184158336, 103.68554176298888, 99.2828106844531, 97.97146650442455, 101.73611298014386, 99.6952166728384, 100.91809125238481, 103.23136502483011, 99.55757098604833, 100.23135010215795, 101.86467144931186, 103.9175692244389, 99.22584623213167, 101.79576829979048, 102.57397313404253, 97.44349599566824, 100.21719517087908, 99.69545628984405, 96.30246704935443, 103.95179021780909, 103.01991787873197, 100.14853782149376, 99.52986684722848, 100.73625374764349, 101.10597902573235, 103.33459926569985, 98.09322653190652, 100.32225684377046, 99.68522745970458, 101.5362375349285, 98.10405412540206, 100.30714721175792, 102.9162226516634, 101.62168518677501, 97.61470292622283]}, {\"name\": \"More Variant\", \"type\": \"histogram\", \"uid\": \"66e02907-240e-4641-b0f0-97f86b8dc16c\", \"x\": [97.66366664139018, 87.38447186601921, 102.7494148767289, 102.07369067427656, 90.26630379919476, 105.30096874331593, 103.52963782818391, 96.0572052206448, 99.50395791058112, 90.39337051910128, 100.49675353640528, 104.35361553969268, 107.84107384298183, 99.6164861791607, 99.22891595296873, 93.24034384546177, 105.40629609576034, 108.88086302813024, 86.59357635781737, 105.61708355113194, 113.13439436090447, 115.20267005580563, 98.99881813653802, 93.42632433300994, 88.88472481164713, 88.70468058736773, 100.4660817646027, 104.85097173822516, 94.44793074898934, 93.77981209815187, 89.30800685622974, 99.23088852783522, 98.18224866149592, 109.57203940528191, 109.92068021773825, 94.2367559220184, 98.19260158718893, 98.0346549836032, 112.4375473209152, 88.51027346215206, 86.06642408185807, 112.2921007578181, 97.31430138322253, 95.51224526742415, 96.0974706441647, 113.81204916758448, 100.21022937938822, 91.62546826971396, 107.25140677581359, 93.61965704486273, 95.47169534372043, 109.74273666093013, 107.61134177818965, 101.63202660732884, 95.12824083279453, 92.59983177957416, 103.97033609112043, 100.97336253207311, 87.98650690662325, 108.63036730785534, 86.54251821927222, 100.91327759104887, 99.99123020977129, 115.9327565062966, 99.00184791768373, 98.36501929615281, 91.49553520184509, 93.8170466792964, 95.0823329318259, 104.92170141743438, 97.48351646876672, 120.52190057047859, 93.26244503074906, 109.35024494171871, 108.23710196618958, 92.46134369523858, 98.92755988396394, 98.31458139526293, 93.83529938520816, 88.94959946695936, 110.39942886800947, 98.36211331370339, 84.62879052327128, 73.56401538987971, 92.56960582696105, 108.60273504475535, 96.23521547468177, 116.24574981952262, 105.59898973956076, 101.67164792467152, 94.25685248824641, 104.30831798345322, 94.22285985131103, 101.70000904733016, 97.07635550218075, 98.19135314242916, 89.18269999164096, 85.25015788738095, 110.51098281503171, 92.79777916117014, 94.71270164547893, 88.47805040392387, 88.04182206527001, 100.60290059061442, 78.20055450240454, 94.56915580806691, 106.22718346332671, 97.01028446238271, 91.77819939440484, 103.72984470329736, 93.10441027846747, 87.82781539177961, 99.52468700669952, 111.1327213519731, 123.96372581887164, 108.49497948824073, 80.61932152856707, 99.24687935812422, 85.6791483128564, 91.01679156881076, 100.48399474767457, 115.86731316059488, 98.61482930250614, 84.38439438359256, 111.77682998335085, 106.18939007345817, 99.57067701890067, 100.95149468667863, 94.0101316449476, 114.51414014592046, 102.46101193772125, 114.52465169487652, 98.86333920712198, 105.64989390354697, 94.79511538823773, 95.68724036809097, 95.30148895258861, 106.86583323154042, 88.65418810267083, 88.01023196765304, 112.61283431211405, 102.39160424695265, 100.92276695281795, 108.53726692722616, 93.01653897639788, 95.45678417866978, 106.97523246007967, 93.73265457166515, 106.91257665199619, 109.77824429786547, 104.27828451836854, 105.6416712591479, 105.45967096554187, 105.81411190064104, 105.88377997453955, 107.14390467751312, 96.72152078393755, 105.83154538152596, 113.23282846739829, 107.92806515702257, 105.57912506893729, 104.0834858883012, 82.96280311907933, 93.386051793556, 110.14726599602417, 102.94052520599877, 89.97711590246195, 109.01417645383785, 101.44076579391611, 78.79027298506338, 97.02587418505722, 98.85787869195079, 104.15998917502718, 92.49927702770701, 87.49185977735964, 99.99318258067882, 109.62371411330747, 104.56134858027805, 116.2327871183686, 110.88225739267693, 97.72677245826584, 101.49651409027213, 109.35122254458409, 94.16843044648785, 98.93818163605205, 102.29981197620769, 98.69543988771598, 101.01003060205623, 110.37412120088851, 116.90873505899602, 92.54467982122081, 106.29281248261509, 95.94189094402878, 85.43497467316189, 94.34708563356519, 104.91847783226191, 91.905277522641, 84.49383557897855, 107.6961107790224, 77.44821479201, 108.8430531351773, 100.29871302140887, 101.88401422892917, 93.83223261139084, 106.5711652734692, 103.30308074173615, 107.79355854134326, 91.27266599722594, 105.97612001294722, 106.25365604660225, 104.11704400221822, 112.22493389156679, 81.96486950434169, 102.33162620941049, 82.40798551049474, 113.69239386599227, 118.43169075081367, 94.11852315062957, 120.26738529871655, 90.62236715760078, 118.50519465584824, 104.91181961942404, 99.55109995233892, 100.76184729894347, 84.70141340962296, 93.27459210893882, 105.85298682351467, 103.69523905070025, 107.80342838662136, 83.03733932983934, 106.46735014692548, 110.7117129189612, 89.07931547281461, 109.37525623862206, 95.74979807890773, 108.26050738264094, 95.87840013285089, 89.33986098320658, 102.35798352761877, 119.55089597424089, 97.76431769723587, 91.99567039290751, 108.37041258348884, 99.62798452028298, 104.10954360174044, 91.18053505091005, 91.46428773567861, 78.54854562258873, 99.55223811989646, 107.026788866833, 96.40337182255487, 91.17234922891323, 105.48772997555587, 97.90859581794652, 101.34225322351215, 116.38600304880607, 98.524500293988, 112.93806543620008, 119.74255188664483, 93.63653078773635, 94.9401920345937, 103.6718570875326, 105.82662828404276, 112.1992817856409, 105.33465239018743, 107.57235857057177, 100.16565346533513, 94.43288644043892, 122.72274480085903, 94.54712547107333, 103.5224844829207, 98.23491516597753, 110.8739865214539, 107.70859490123698, 98.98784283102152, 80.92316035560954, 109.40897889619734, 111.95030022166321, 102.51764815670015, 107.18017336641987, 105.09423252830162, 81.09080392149569, 109.4450582093059, 94.505344058794, 99.89430484389983, 98.51350932780086, 116.35104779864386, 110.1450928838124, 107.73154358785962, 82.27009616282032, 90.97449564385032, 100.74853400272833, 92.18079246796925, 85.8468687995672, 107.29694449041328, 98.21360741007359, 90.8227787927233, 75.16505264359017, 101.48547505489931, 108.55988815719338, 108.4831549459743, 107.04930706484897, 111.84912999723414, 91.03345059624357, 79.42724709523334, 85.72432358828979, 89.94272910277661, 87.91971878106486, 115.16927286961928, 95.61303932668523, 97.71272257581289, 100.87941447042604, 121.09434269705935, 117.61078092719514, 116.28528726431617, 96.18421132229766, 126.66550613312413, 92.04216487509744, 91.77712692376673, 93.26295257119703, 92.592368857981, 89.079050222848, 98.22392791517262, 109.47022690604673, 94.64736595586828, 99.33735279143288, 111.05531308617812, 98.51914852066001, 92.71601475067214, 79.3335815333473, 99.95292774627065, 87.9201598512133, 94.51444676907309, 96.07217340949528, 106.24713351176817, 102.77683416977395, 99.55355165862079, 114.30439427524144, 99.11956288124372, 96.82610293016603, 107.69308759241437, 98.5354982727269, 89.69382323480843, 101.39938019899388, 93.11071834666572, 92.87848508503501, 73.43579424293752, 89.13799496127591, 111.66695023780193, 96.30069197088986, 79.37276888221984, 104.83110754721785, 102.20826654774216, 98.23368255407108, 96.55578807483008, 106.5358016684599, 99.94424825725031, 90.9179429962292, 79.99307002043444, 119.23319862528457, 104.9305195437571, 86.82816379648993, 105.02346722067642, 104.15174949125621, 99.42077234887734, 117.00334297930945, 90.07245943820348, 95.81670696377991, 103.37458195215537, 98.06610271816342, 96.69568385505997, 104.21931447349097, 106.01568334737824, 103.73044468952871, 91.13140875801828, 109.07964902812826, 93.26462162891816, 91.54612962802011, 95.34010975247264, 97.19727697074593, 86.36530666764071, 106.92847872737025, 116.78727286589321, 109.24032133625981, 93.38455841427299, 100.18689632076149, 83.85198904988916, 104.22866491675147, 121.68730570594518, 112.59032948109011, 88.9483408273332, 110.57931107919765, 102.46763816935926, 98.67925607070421, 99.9667244192891, 110.2828322846509, 93.71130761081315, 98.57166827111686, 96.43588667781954, 85.05663951720558, 101.6095537189243, 119.87438489210126, 117.77661577770806, 103.43714978956835, 106.56648867643632, 116.39966225987641, 105.99029386993887, 97.98483401087313, 103.53666481423939, 96.4945878679836, 102.04649307312448, 102.40761854227124, 105.48304692735935, 113.03125436613523, 97.78896980597959, 91.73234483355998, 110.5222280680426, 110.10641459356549, 78.03094323949867, 117.42618582418584, 101.53468104562731, 99.19131889257007, 112.59502201969416, 76.38539706854351, 113.84012879269662, 100.91484018770797, 95.65120890647142, 101.18224427367159, 83.54653486096646, 109.12962924098001, 91.43673842518047, 98.61407291115755, 96.21785185127024, 106.21446685581371, 101.91112098374512, 100.72517330919221, 101.37616841588233, 84.83579846501094, 100.93728001642116, 109.00118059984267, 96.39101630920612, 92.10234209727001, 79.47436821863081, 87.18407422469718, 79.91607170028436, 116.23611077538705, 91.73870915062214, 108.98851931662118, 86.803956978098, 83.0025679798234, 109.64576433874484, 78.62490220817249, 105.17271391041466, 88.06267479309584, 96.77553392533436, 115.74668017059405, 99.62478410547826, 94.86982331020565, 102.95051510761544, 101.05514671684894, 80.50450365016444, 103.46183620437104, 118.27072358864315, 91.82538789339861, 81.15749479440925, 111.74329061654461, 105.4507633511133, 103.6359766299786, 91.08114560527125, 122.11709546589026, 98.82059690947777, 107.91749230421088, 88.94733242624523, 102.04283680971044, 109.96803984605789, 104.22990416368545, 113.27356447273863, 84.80847587802576, 96.25272572351484, 118.83277293629399, 109.80095536332732, 116.39399943215314, 108.0287085285416, 99.7623891497633, 116.2725450699937, 90.53609138024761, 100.07795574351881, 113.46313899837152, 98.5827177080189, 105.34889428357191, 75.05132137570106, 103.22670325822543, 97.4427220782304, 91.02356525459312, 79.09932814411935, 113.6543033442452, 91.62254070133602, 104.41087285007086, 92.46159096753762, 103.21779434856816, 103.1448158547804, 107.52955473553797, 89.9581495150779, 97.934422736213, 100.70186432750917, 103.32587387761286, 92.10658896176797, 90.43258627184544, 98.69151949517446, 90.76158455957356, 85.4395699311753, 101.15897727548827, 99.77869338153036, 106.02297339885797, 109.92652900535953, 109.88293638608849, 102.2402212377785, 85.58702948423095, 88.91658682170787, 86.89153287849778, 94.72119900132905, 110.83670033078192, 93.74574348199768, 119.99637095505612, 96.94853726263219, 112.70857277038589, 127.66896007043103, 92.97262066492496, 104.77471639131691, 93.96446941854447, 85.78431220177593, 100.88591521955533, 109.45710266020762, 105.12673821597313, 87.59915564038253, 106.05796893939544, 88.31434701731615, 95.21237817197658, 100.88624385029642, 98.34803941785502, 103.41060671000133, 109.07870806519213, 88.81164101348544, 105.79881206487767, 112.44986940156657, 111.36188368977207, 119.73103949977207, 106.59539064602521, 86.92706572296031, 108.22631868035397, 120.11641194127937, 79.10396636980173, 104.32941098262441, 91.25939430344496, 98.88957320336371, 113.09454263785935, 106.42533359537902, 103.60208944707001, 111.6305765514574, 87.91189073055727, 100.30170229964901, 108.56997794072046, 99.36078956478958, 107.53258027953798, 76.98369170279688, 99.26844567189042, 101.90146235944714, 104.39668509014403, 106.03456579524408, 97.84368469780257, 101.33372006945551, 117.68148336220857, 104.00081736451136, 96.53318243074668, 90.22328093401956, 86.3911165234324, 96.4858492984969, 99.76446054688013, 101.84613961154668, 106.27254221317796, 84.44902556369442, 92.87938324840766, 115.78656773092058, 105.03367335506175, 84.77312356755054, 120.11193858287344, 97.32250120814673, 100.36530138271146, 82.76631785271768, 89.30420469750037, 106.07204719305086, 124.012243168921, 109.253495113041, 108.81952737887521, 112.50482753640416, 105.75779663248714, 98.18423650293683, 107.06311199335624, 89.28780651899906, 105.36111725862233, 107.28866012310343, 91.0854772645748, 107.4836855129076, 92.52195730106308, 94.47384210440022, 106.93550025790508, 98.42654361822265, 97.55409193281075, 97.08271184653545, 110.53698940414546, 96.90248452646883, 107.5753783476877, 94.3316217889359, 104.86489595256427, 102.41538248067965, 104.2007845440283, 82.1098685447972, 83.31030258578537, 113.90328315679643, 79.06165260051922, 106.23942886473338, 86.76698268405009, 90.37508852208666, 107.68883853820859, 106.50811174209275, 106.08076315559317, 90.84920958263949, 97.58349422706588, 89.27587576152743, 99.90305958313266, 104.95091518993922, 90.42026846777463, 103.7228669159878, 117.21888022003712, 90.03047367631122, 88.26234435533173, 110.24810052641584, 97.89584563888035, 94.80538501757916, 100.48905169042511, 111.37871849418815, 86.02953344863465, 102.17293366698911, 119.7410595266884, 88.0099434495801, 88.89102920370152, 112.63668727081541, 99.68820186951702, 95.21777152412955, 86.27187485145072, 75.6148000903926, 101.79321052051617, 102.28264475031916, 99.8478434889969, 92.26369746375396, 108.93989073498473, 108.92369335316796, 97.54884837092513, 92.95445466908181, 94.38381403754454, 98.46803901424956, 90.0203687298058, 105.07746257604205, 105.10334911309246, 108.40285788681652, 109.4380175444194, 79.39537156058563, 105.60666270528124, 92.67353778634369, 104.08224014679242, 108.11532817562639, 103.10335683131315, 99.22185220307924, 91.01236949076083, 101.94520383279976, 93.23111376274818, 102.96870783688192, 103.58040145947187, 95.63580930331696, 100.26959899769534, 102.94914743580156, 91.57090587436204, 88.89182040008403, 114.07914334989474, 81.99408810557829, 94.55886865049433, 104.53857341213264, 100.17098988094077, 102.72132525903527, 92.70591494297744, 97.01794234175296, 85.08578709224793, 86.71023274867069, 89.71921976706506, 73.83245160862369, 90.37299526617039, 106.26954460669043, 85.72663675907006, 116.06301941824017, 91.30219658237664, 83.61391595371484, 83.67154029624356, 109.66365012404005, 113.81356300941782, 99.37543626708327, 114.45311192483899, 110.6136094936129, 90.08121588013361, 114.30931374006556, 95.11222599280299, 103.32972554355521, 95.83083741372411, 97.76100168758062, 86.78689425314876, 92.81915772689256, 107.37954288076713, 103.67258781824663, 102.7470564671153, 102.61537316476449, 103.388935787325, 114.9445987146363, 103.90914308113211, 103.8624291713314, 103.47699315147757, 102.32528335190139, 98.61576460682791, 98.55193022524492, 99.92991322946126, 93.31070820513878, 95.60418024967221, 112.67578992012483, 93.27367486492982, 88.21760913405657, 89.77035787566756, 104.56997483660871, 94.68410193717483, 97.63143589790808, 107.66217218386761, 105.93947216944777, 89.93392105777991, 93.25916601924918, 97.60220987350705, 102.84403782735824, 106.04224071106768, 89.74936711570683, 102.33856697973883, 103.1320528212539, 103.37266648014248, 110.98423284935738, 99.18990577602237, 88.65645495136503, 92.6313584322127, 102.96916075348085, 92.03088199037286, 103.23333636507374, 106.2790942736996, 105.53907731571391, 118.0428844915803, 103.46311104925515, 103.00027470310307, 108.93718550238421, 93.78913463774725, 99.22290235356733, 106.9499280127654, 81.2664848312432, 90.97999879652576, 111.33364378778045, 104.46497684173842, 92.34494008289494, 115.92007475157438, 116.26306631145613, 104.83514969626447, 76.35117693976892, 99.3981944952032, 116.88464176438654, 88.78308136363417, 91.43340787423662, 93.64344051051522, 110.8183353504655, 98.47114749158791, 96.70080839615065, 88.17351455995319, 92.54224040574533, 106.77665583628307, 111.0271122601003, 101.337534555505, 107.36650216563214, 92.48019686080794, 115.05161097448283, 102.9305875065995, 101.52399233467338, 92.53781479628448, 88.35277702705338, 95.08358111771567, 115.67286163971991, 112.66383081302864, 103.74567657108447, 90.11581295723795, 94.78002058322912, 92.9948653451089, 102.26948655205908, 95.76828866677499, 99.35897825481297, 99.86379051507895, 92.59607441211875, 91.83319833531857, 115.35003511310802, 127.93495260155521, 93.64836260304283, 102.34304057618297, 88.14805849449588, 90.51119209399369, 105.54085972167378, 111.44576820061357, 115.44747063709247, 100.26028441943836, 105.68817627530363, 101.43640143721251, 92.72327704714523, 92.50236985598508, 85.35858487570036, 86.30206139723533, 91.47144420118823, 96.3426048106019, 107.20056238196243, 96.01846158875206, 104.24789699154451, 84.84628291723308, 105.2746821872497, 109.28550848256954, 102.86919377979979, 104.41803595880555, 99.0398583903627, 97.42968311350575, 102.1363311754459, 96.85834660902616, 93.70583918835683, 94.69192597432192, 109.29838480700937, 113.83961457449034, 102.0989455546019, 88.08959477950145, 104.05046929436098, 102.0224779470728, 99.08621973480551, 95.3434843795368, 105.8987097311405, 101.18084526927491, 97.11303975583263, 92.94483285531646, 125.22162864866216, 87.58871245092807, 92.68347191973656, 108.62413966261656, 75.42524411791516, 78.4886615833644, 112.51550371529616, 112.81915878477594, 104.04995513785741, 104.79183843249061, 108.3109653620544, 101.25150820099053, 96.94358787179698, 91.11592117273766, 97.15098272441135, 106.51548921711165, 93.33251667815466, 92.45109204354738, 95.28763985738266, 121.88649392862072, 93.78070681145063, 92.72105837007209, 96.66516628744984, 96.57962597871312, 117.45089394090024, 100.57090602754162, 109.33505971766577, 82.47476414815338, 113.36786874084463, 87.40900777333417, 107.2784734781922, 94.84622731709715, 98.41464993118139, 123.29888334317118, 110.11269254817549, 88.79754165396855, 88.73053042767222, 108.89489433294314, 97.83725949510155, 83.94878926362017, 111.91314013953703, 93.49292570080455, 85.14408374424356, 96.26907920422842, 100.77763705284886, 109.27792955359831, 93.03045688174782, 89.7074219655041, 108.80364359625077, 97.4688902742841, 112.40378214497986, 92.61091069461774, 111.89537045820458, 95.80505050578388, 112.862595880289, 92.54757859319986, 105.15182936369264, 88.7496972266005, 100.7446964806648, 125.04636564078238, 97.57860572724195, 89.43840865776552, 83.15394122748297, 105.84921321315134, 87.35049954063803, 91.81956933462945, 92.384730651318, 94.36155060618911, 93.1271496084918, 108.35711221825592, 85.24667881472736, 102.55617179278252, 107.98945974099395, 108.29782333114375, 117.08943647146528, 93.6400861432958, 119.9941923575261, 94.33018557516705, 101.11759275948711, 100.81479336467507, 92.15382824080447, 88.64365174337296, 96.02974784935049, 107.44990433993542, 79.13973314772704, 97.5177849085802, 106.07489189050943, 103.585564276925, 84.78983037543615, 114.03115522805824, 97.2153870345765, 105.40283246556179, 88.84727596566609, 90.62832191631874, 117.60844304473359, 102.53647426133146, 109.59857950054732, 90.500905519869, 105.95672401295019, 108.11528958975384, 95.32278579244587, 106.70194004862496, 118.73228026814279, 107.2941477616913, 92.57381739613814, 114.53338618833907, 96.70066821098646, 91.6925178727374, 98.94893279459065, 105.55026100419728, 98.9141419404966, 114.26339370517329, 87.94161376280394, 99.58410252254632, 121.97016743382869, 94.87072088436221, 90.26454886589549, 86.27670361670536, 102.14828357509586, 91.71509713232703, 102.41664268081388, 87.41984477451291, 87.24130711214602, 115.35663778554903, 103.33090037621812, 107.79926662517765, 90.45683519408674, 113.31746022502877, 102.10954458616196, 102.73714022467087, 82.96061389118017, 113.84120429639943, 96.15064402788836, 109.01779298020722, 87.24913162588668, 100.10479476428556, 93.6867162224481, 100.47248901504219, 104.8692355076799, 99.00134165192331, 90.83557594648848, 94.1727811995913, 97.81976193624459, 95.32596418068476, 82.5813392580807, 104.76999817831827, 119.29197516523584, 103.49476118644564, 115.97162551556929, 106.10209767466131]}], {\"title\": {\"text\": \"Mean of 100\"}, \"xaxis\": {\"title\": {\"text\": \"Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Volume\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('a88eee82-3b22-4b01-91c5-078e071902a1'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); In [56]: ex_1 . mean () Out[56]: 100.06843195281844 In [57]: ex_2 . mean () Out[57]: 99.93551822004906 We can now see how the spread of these distributions are quite different. How can we measure spread? Range The simplest measure of spread is known as the range . This is the largest value in the sample subtracted from the smallest value in the sample. This can give us an idea of where the possible values of the sample lay. That is: $$ \\bar{S}_{range} = x_{max} - x_{min} $$ For instance, in our alien example, we have: In [58]: max_alien_neurons , min_alien_neurons = alien_neurons . agg ([ 'max' , 'min' ]) rng = max_alien_neurons - min_alien_neurons print ( '''Maximum: {} Minimum: {} Range: {} ''' . format ( max_alien_neurons , min_alien_neurons , rng )) Maximum: 100856570 Minimum: 100223744 Range: 632826 From this, we know the difference between the largest and smallest values. To see how the original difference compares to this, we can look at the ratio of the difference and the range. In [59]: abs ( alien_mean - alien_median ) / rng Out[59]: 0.002525117488841235 Here we can get a sense of how \"close\" the median and mean are. This ratio is necessarily between 0 and 1, with 0 representing the same point, and 1 representing the largest difference in the sample (that is $x_1 - x_2 = x_{range}$). Although simple, the range suffers from some problems in that it only can measure the differences between the largest and smallest points. It is therefore as variable as those points. Suppose we had a dataset that looked like the following: 0, 50, 50, 50, 90, 95, 100. Then, the mean is: In [60]: example_ds = pd . Series ([ 0 , 50 , 50 , 50 , 90 , 95 , 100 ]) example_ds . mean () Out[60]: 62.142857142857146 In [61]: example_ds . median () Out[61]: 50.0 Using the ratio calculation as before, we would calculate: In [62]: ( example_ds . mean () - example_ds . median ()) / ( example_ds . max () - example_ds . min ()) Out[62]: 0.12142857142857146 In [63]: data = [ go . Histogram ( x = example_ds . tolist ())] shapes = [{ 'type' : 'line' , 'name' : 'Mean' , 'line' : { 'color' : 'red' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : example_ds . mean (), 'y0' : 0 , 'x1' : example_ds . mean (), 'y1' : 5 , }, { 'type' : 'line' , 'name' : 'Median' , 'line' : { 'color' : 'black' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : example_ds . median (), 'y0' : 0 , 'x1' : example_ds . median (), 'y1' : 5 , }] layout = go . Layout ( title = 'Dummy' , xaxis = dict ( title = 'Number' ), yaxis = dict ( title = 'Volume' ), shapes = shapes ) fig = go . Figure ( data = data , layout = layout ) plt . iplot ( fig ) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"052fb4f4-b2a1-45c0-9b2b-7deadf919cac\")) { Plotly.newPlot( '052fb4f4-b2a1-45c0-9b2b-7deadf919cac', [{\"type\": \"histogram\", \"uid\": \"7ffbde38-eb02-4d50-866f-d1b754331407\", \"x\": [0, 50, 50, 50, 90, 95, 100]}], {\"shapes\": [{\"line\": {\"color\": \"red\"}, \"name\": \"Mean\", \"type\": \"line\", \"x0\": 62.142857142857146, \"x1\": 62.142857142857146, \"xref\": \"x\", \"y0\": 0, \"y1\": 5, \"yref\": \"y\"}, {\"line\": {\"color\": \"black\"}, \"name\": \"Median\", \"type\": \"line\", \"x0\": 50.0, \"x1\": 50.0, \"xref\": \"x\", \"y0\": 0, \"y1\": 5, \"yref\": \"y\"}], \"title\": {\"text\": \"Dummy\"}, \"xaxis\": {\"title\": {\"text\": \"Number\"}}, \"yaxis\": {\"title\": {\"text\": \"Volume\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('052fb4f4-b2a1-45c0-9b2b-7deadf919cac'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); Now let's do something crazy -- let's change the last value of the series to 1 million, and see what happens to the \"ratio\" of the difference between the median and mean to the range. In [64]: example_ds . replace ({ 100 : 1000000 }, inplace = True ) In [65]: example_ds . median () Out[65]: 50.0 In [66]: ( example_ds . mean () - example_ds . median ()) / ( example_ds . max () - example_ds . min ()) Out[66]: 0.142855 In [67]: data = [ go . Histogram ( x = example_ds . tolist ())] shapes = [{ 'type' : 'line' , 'name' : 'Mean' , 'line' : { 'color' : 'red' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : example_ds . mean (), 'y0' : 0 , 'x1' : example_ds . mean (), 'y1' : 6 , }, { 'type' : 'line' , 'name' : 'Median' , 'line' : { 'color' : 'black' }, 'xref' : 'x' , 'yref' : 'y' , 'x0' : example_ds . median (), 'y0' : 0 , 'x1' : example_ds . median (), 'y1' : 6 , }] layout = go . Layout ( title = 'Dummy' , xaxis = dict ( title = 'Number' ), yaxis = dict ( title = 'Volume' ), shapes = shapes ) fig = go . Figure ( data = data , layout = layout ) plt . iplot ( fig ) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"99fec4e8-d015-443a-a367-c1445f1d4778\")) { Plotly.newPlot( '99fec4e8-d015-443a-a367-c1445f1d4778', [{\"type\": \"histogram\", \"uid\": \"c6633ff1-9295-4013-bbcb-448423bc7426\", \"x\": [0, 50, 50, 50, 90, 95, 1000000]}], {\"shapes\": [{\"line\": {\"color\": \"red\"}, \"name\": \"Mean\", \"type\": \"line\", \"x0\": 142905.0, \"x1\": 142905.0, \"xref\": \"x\", \"y0\": 0, \"y1\": 6, \"yref\": \"y\"}, {\"line\": {\"color\": \"black\"}, \"name\": \"Median\", \"type\": \"line\", \"x0\": 50.0, \"x1\": 50.0, \"xref\": \"x\", \"y0\": 0, \"y1\": 6, \"yref\": \"y\"}], \"title\": {\"text\": \"Dummy\"}, \"xaxis\": {\"title\": {\"text\": \"Number\"}}, \"yaxis\": {\"title\": {\"text\": \"Volume\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('99fec4e8-d015-443a-a367-c1445f1d4778'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); Huh. Here, the mean and median are very far apart -- and the mean is quite a bit off from the \"average\" person, as only one observation pushed it up into the thousands. This is, again, due to the lack of robustness of the mean. However, our ratio measure does not seem to think there is much of a difference between the difference in this case and in the previous case. We would expect that our most extreme values in the sample may be more variable then values closer to the center. In this case, we can take ranges of specific quartiles , as discussed in the previous post, to determine variability. Interquartile range In a similar way, we can define a range between any two percentiles of the data. In this case, the range is a specific case of this, where we take the 0th and 100th percentile of the data. As discussed earlier, this may be quite variant -- these are the most extreme values of our distribution. Suppose instead we took the difference between the 25th and 75th percentiles, or the 1st and 3rd quantiles. It would follow that this measure would be more robust then the max-min range. This is known as the inter-quartile range and is (unsurprisingly) robust to outliers. That is, we can say that the interquartile range in a finite sample is: $$ \\tilde{S}_{IQR} = Q_x(.75) - Q_x(.25) $$ Where $Q_x(p)$ is the quantile function, i.e. the function that finds data which is the above $p%$ of the data. Arithmetically, we can determine this by finding the medians of the values above and below the median. Most software packages contain functions which can determine this automatically. In the case of the alien brains, we have: In [68]: iqr = alien_neurons . quantile ( . 75 ) - alien_neurons . quantile ( . 25 ) iqr Out[68]: 210608.0 This represents how distant the closest two points which account for 50% of the data are. In other words, we have determined a measure of how far away things are. Taking a similar ratio, we can determine how distant two points are. For example: In [69]: abs ( alien_mean - alien_median ) / iqr Out[69]: 0.007587366101921311 This value has a range between 0 and infinity. In general, each \"unit\" of this ratio measures how far away the two points are relative to the center 50% of the data . A small value indicates that two points are relatively \"close\", while a large value (>1) indicates they are \"distant\" relative to the center 50%. For more information on this robust measure of spread, see here Boxplots Using the information we have learned about the measures of spread and measures of central tendency, we can now culminate it together into a plot called a box and whisker plot. This plot shows the median, the inter-quartile range, and the total range in one figure. This can give us a good \"overview\" of what the data looks like in terms of quantiles. In [70]: data = go . Box ({ 'x' : alien_neurons , 'name' : 'Alien Neurons' }) plt . iplot ([ data ]) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"4deafc48-c995-4c04-94f2-58a5004b70e7\")) { Plotly.newPlot( '4deafc48-c995-4c04-94f2-58a5004b70e7', [{\"name\": \"Alien Neurons\", \"type\": \"box\", \"uid\": \"98592d07-dfc0-4fa2-acd2-8f27403193f3\", \"x\": [100507682, 100601005, 100336496, 100623165, 100754041, 100856570, 100702398, 100729273, 100411299, 100556471, 100697638, 100540953, 100411717, 100478614, 100574488, 100499210, 100852747, 100651745, 100697942, 100484243, 100397057, 100552299, 100388278, 100785268, 100546213, 100522820, 100426863, 100282560, 100397992, 100590144, 100248387, 100545909, 100517592, 100687610, 100657954, 100568996, 100569742, 100442644, 100411784, 100579139, 100520273, 100738283, 100342396, 100445818, 100624941, 100764764, 100430309, 100737396, 100761735, 100353133, 100467783, 100533562, 100415755, 100564377, 100444869, 100578210, 100630623, 100761510, 100550665, 100546729, 100360033, 100672311, 100472937, 100750441, 100616384, 100577225, 100397447, 100554639, 100617736, 100420158, 100568391, 100779155, 100415724, 100318415, 100496400, 100483601, 100511965, 100398418, 100613111, 100467889, 100696693, 100689413, 100656193, 100412745, 100548172, 100419812, 100603947, 100631853, 100453490, 100657843, 100290953, 100387413, 100512580, 100223744, 100436972, 100392013, 100836090, 100636159, 100540619, 100668141]}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('4deafc48-c995-4c04-94f2-58a5004b70e7'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); The center line represents the median, the two lines surrounding in the 25th and 75th quartiles, respectively, and the endpoints (and whiskers) represent the minimum and maximum. To compare to the non-symmetric simulated plot we discussed before, we can see large differences between the two: In [71]: data = go . Box ({ 'x' : sim , 'name' : 'Not Alien Neurons' }) plt . iplot ([ data ]) require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; window.PLOTLYENV.BASE_URL='https://plot.ly'; if (document.getElementById(\"fbd8e39c-e732-4ef5-907e-f0d095191183\")) { Plotly.newPlot( 'fbd8e39c-e732-4ef5-907e-f0d095191183', [{\"name\": \"Not Alien Neurons\", \"type\": \"box\", \"uid\": \"d2746a74-7bbe-4a50-8255-751a42831f92\", \"x\": [1815.2961130358603, 2320.218549594198, 1774.238950351985, 10129.329569604373, 1291.3107998367987, 223.3226019797967, 511.1190584745391, 2539.1462070254247, 1691.7984992130866, 3932.300750670352, 6793.957503120814, 1535.0287569346979, 2022.8973728018339, 1053.8154762349425, 973.5181073035899, 323.6513923572703, 9726.847031775475, 7135.352086198367, 3512.474945472328, 6227.505350176736, 13244.888216522466, 2867.9361099027983, 807.5146428567614, 2894.549648576427, 2244.178387714029, 3257.1038221480812, 1736.2230124900836, 924.3957750430835, 3939.8535567342283, 203.32884083827767, 14045.997332778845, 546.2147123850925, 417.5538715626165, 107.90409001348492, 1704.8438615097614, 113.8419174685519, 2439.006413127879, 1843.269218713016, 808.3472313135118, 866.3462227327186, 1505.053252145675, 1046.5330708322601, 2068.027719683339, 251.17616713782976, 141.12043094440338, 819.6818612377483, 2020.2503585291886, 417.7717118081688, 1978.642699972511, 4152.00901968332, 7141.121777756109, 294.25439730884705, 5055.263403490116, 2359.4096263832603, 737.0583169703585, 756.5588683955067, 1688.1995118447353, 1200.3525822057034, 5537.486837091894, 3052.5661838992432, 716.0370763823562, 9048.079440812544, 235.87876321395117, 779.4247291113422, 376.7574206190164, 1871.9125744152384, 1405.5064649823244, 1715.8137527463932, 8766.403226820257, 21225.42670423942, 4486.2549196354785, 416.20474169790657, 1517.5508166911504, 1267.3033729274018, 1133.9330477820738, 389.8746550213425, 67.45747393366179, 486.5432413205892, 7031.818751334337, 2086.3679690315575, 2097.541446182641, 2840.221558126296, 2919.222008028245, 5299.136151360571, 14501.064835070783, 1688.2746230691446, 3801.6947174533625, 1643.3099010076398, 204.99257950344463, 8409.984220817802, 1017.3364757112194, 1338.7638173892342, 404.5430086683285, 2607.930463755532, 171.50491673765143, 464.69817123005356, 2333.719993719836, 8551.131279451381, 8005.88791102838, 945.8413547396598]}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true} ).then(function(){ var gd = document.getElementById('fbd8e39c-e732-4ef5-907e-f0d095191183'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; }); We can see now how much of the inferences about spread can be understood through the use of quantiles and differences between them. These measures are quite robust, but suffer in the sense of efficiency. In a manner equivalent to the median and mean, these measures of variability do not take into account every data point, as the mean does, but only considers the quantiles. The next measure of spread, and the most common historically and in practice, is the variance which is defined in terms of the mean instead of in terms of quantiles. But first, we will discuss the degrees of freedom implicit in the mean. Freedom -- the dream, and the degree to which we have it It is at this point that we should discuss degrees of freedom , before jumping into variance. Degrees of freedom are a concept which many struggle with in elementary statistics, and is often glossed over in respect to statistics courses. I believe that understanding the degrees of freedom are essential in understanding how randomness ties into statistical treatment of data. It is for this reason that I have included this here. If this feels too math heavy, feel free to disregard it -- it is not necessary to understand, but helpful. If you're fond of mathematics, read on. Consider it this way. Let's say I told you we have 100 points. How many degrees of freedom do these points have? When I ask this, I essentially am asking the question how many different ways can these points vary? Well, we only know that there are 100 points -- we know nothing of how these points are distributed. Therefore, they can conceivably be any 100 points, since we have no prior information. Now, suppose that I tell you that the mean of these points is 100. Have the degrees of freedom changed? The answer is yes. We can no longer vary the numbers absolutely freely -- we are constrained in the fact that the number must have some property -- the mean -- which equals some known value. In this case, n - 1 of the points can vary, after which the final number is fixed. Let's consider an example. Imagine we pick some random numbers out of a hat and get the following: 9, 8, 2, 42, 100, -2. Suppose there is only one paper left in the hat and I told you that I, an omniscient observer, know that the mean of all the values in the hat is 1000. What is the final value? Well, we know that $$ \\bar{X}_{mean} = \\frac{\\sum_{1}&#94;{n} x_i}{n} = \\frac{\\sum_{1}&#94;{n - 1}}{n} + \\frac{x_n}{n} $$ So, it follows that: $$ x_n = n\\bar{X}_{mean} - \\sum_{1}&#94;{n-1} x_i $$ This is only using elementary algebra. In our case, the final value is $$ 7 \\bar{X}_{mean} - \\sum_{1}&#94;{6} x_i\\\\ 7 \\times 1000 - (9 + 8 + 2 + 42 + 100 - 2) $$ This is: In [72]: points_picked = pd . Series ([ 9 , 8 , 2 , 42 , 100 , - 2 ]) last_value = 7000 - points_picked . sum () last_value Out[72]: 6841 To confirm that this is correct, lets see what the mean looks like. In [73]: points_picked . append ( pd . Series ( last_value )) . mean () Out[73]: 1000.0 But we could do this for any mean! Suppose the mean was instead -1000. Then In [74]: last_value = - 7000 - points_picked . sum () last_value Out[74]: -7159 In [75]: points_picked . append ( pd . Series ( last_value )) . mean () Out[75]: -1000.0 This describes what the mean tells us about the data -- if we know the mean, one of the data points essentially becomes redundant. Now, suppose I wanted to create my own hat game, where I wanted the mean to be 42. How could I do this? There are infinitely many sets of numbers I could choose that have a mean of 42. However, they all have the constraint that if we were to remove one value, we could reconstruct it in the way above ! That is, the final value is not random but determined . This means that we have n - 1 degrees of freedom -- or that the dimensionality of our random vector is now n -1. Then, I could randomly select n - 1 numbers, and select the final number deterministically such that $$ x_7 = 7 \\times 42 - \\sum_{1}&#94;{6} x_i $$ This will ensure that my mean is always 42. In fact, there is no such other number I could choose that has a mean of 42. Conversely, the number I select will uniquely determine the mean. So the mean has one degree of freedom -- it can be determined entirely from one number, if the other numbers are known. This becomes important because the more degrees of freedom we have, the more we allow random variation to play a part in our estimates. Although randomness may seem bad, in fact having more degrees of freedom can be a good thing, as is the case in linear regression -- a topic for a different day. In general, we have In [76]: def find_point_from_mean ( series_of_less , mean ): n = len ( series_of_less ) + 1 n_final = n * mean - series_of_less . sum () return n_final In [77]: find_point_from_mean ( points_picked , 1000 ) Out[77]: 6841 Freedom isn't free Now let's tackle the first case -- we have 100 points with a mean of 100. How many different ways can we select these 100 points? Consider the following: knowing only the mean of the distribution, we can select any n - 1 points, in this case 99, arbitrarily and completely at random, and then select the final point such that: $$ x_{final} = n\\bar{X}_{mean} - \\sum_{i=1}&#94;{n-1} x_i $$ In this case, this is $$ x_{final} = 10,000 - \\sum_{i=1}&#94;{99} x_i $$ Taken another way, we can say the following: Knowing the mean, we can calculate: $$ \\tilde{x}_i = x_i - \\bar{X}_{mean}\\\\ \\forall x_i \\in S $$ Only n -1 of these values are allowed to vary -- once we know n-1 of them, the last is determined by the calculation of the mean. In general, we have that the degrees of freedom can be decomposed as follows: $$ \\begin{bmatrix}x_1 \\\\ x_2 \\\\ ... \\\\ x_n\\end{bmatrix} = \\begin{bmatrix}\\bar{X}_{mean} \\\\ \\bar{X}_{mean}\\\\ ... \\\\ \\bar{X}_{mean}\\end{bmatrix} + \\begin{bmatrix} x_1 - \\bar{X}_{mean} \\\\ x_2 - \\bar{X}_{mean}\\\\ ... \\\\ x_n - \\bar{X}_{mean}\\end{bmatrix} $$ Note that this is in vector notation, but it makes the results easier to see. The vector on the left, our data points $x_1, x_2, ..., x_n$ have n degrees of freedom -- given no additional information, they are free to vary randomly. The first vector on the right, the vector of means, has 1 degree of freedom -- if we do not know it, it can vary in one dimension. That means it can be any single number. The final vector on the right now has n - 1 degrees of freedom (the degrees of freedom of the original vector minus the degrees of freedom of the mean). This means that given a mean, our data points can vary with dimension n - 1. The final dimension is then a linear combination of the other data points. Variance But how does this have any connection to the spread of a dataset? Happy you asked! One way we can consider spread is: how far away are the observations from the mean? In order to do this, we could take the differences between each point and the mean. This would look something like this: In [78]: x_differences = alien_neurons - alien_mean x_differences Out[78]: 0 -37191.04 1 56131.96 2 -208377.04 3 78291.96 4 209167.96 5 311696.96 6 157524.96 7 184399.96 8 -133574.04 9 11597.96 10 152764.96 11 -3920.04 12 -133156.04 13 -66259.04 14 29614.96 15 -45663.04 16 307873.96 17 106871.96 18 153068.96 19 -60630.04 20 -147816.04 21 7425.96 22 -156595.04 23 240394.96 24 1339.96 25 -22053.04 26 -118010.04 27 -262313.04 28 -146881.04 29 45270.96 ... 70 23517.96 71 234281.96 72 -129149.04 73 -226458.04 74 -48473.04 75 -61272.04 76 -32908.04 77 -146455.04 78 68237.96 79 -76984.04 80 151819.96 81 144539.96 82 111319.96 83 -132128.04 84 3298.96 85 -125061.04 86 59073.96 87 86979.96 88 -91383.04 89 112969.96 90 -253920.04 91 -157460.04 92 -32293.04 93 -321129.04 94 -107901.04 95 -152860.04 96 291216.96 97 91285.96 98 -4254.04 99 123267.96 Length: 100, dtype: float64 This will give us differences for each of the points. It would be nicer to have one number to measure the variability of the data, so we can take the average of these values: In [79]: x_differences . mean () Out[79]: -6.556510925292969e-09 Hm. This value is very close to zero. This is actually expected, simply because of the definition of the arithmetic mean . Consider the following: $$ \\bar{X}_{mean} = \\frac{\\sum_{i=1}&#94;{n} x_i}{n}\\\\ \\sum_{i=1}&#94;{n}(x_i - \\bar{X}_{mean}) =\\\\ \\sum_{i=1}&#94;{n}x_i - n\\bar{X}_{mean} = \\\\ \\sum_{i=1}&#94;{n}x_i - n\\frac{\\sum_{i=1}&#94;{n} x_i}{n} =\\\\ 0 $$ Intuitively, the mean is the value which is in the \"center\" of the distribution, in the sense that the differences above the mean are equal to the differences below the mean. The mean is specifically selected such that this sum will equal to zero. But in our case, we are not very happy with this. We are not as concerned with the sign of the distance from the mean, but how far away it is. We are not interested in the direction but the magnitude . For example, if the mean is 2 and we have two points around it, 1 and 3, we would say that they are equally distanced from the mean -- the sign of the difference (-1 and 1) does not matter. How can we eliminate the sign? Mathematically, there are two general approaches to this -- we can take the absolute value or we can take the squares . The absolute value preserves the exact magnitude, while squaring does not. Why might we want to take the squares? Squaring the distance values will essentially put more weight on values which are far from the mean, and less on those close. In this sense, we get a penalization in the case of extreme values -- extreme values will make our variance larger than \"common\" values. Additionally, historically the squares have been used because they are analytically \"nicer\" -- they are smooth functions for which we can take the derivative, while the absolute value is not. In the computing age, this has become less of an issue as numerical approaches to optimization problems have taken hold, but I digress. Since the squared version is used the most in statistical literature, we will define this first. We can define the sum of squares as the following: $$ SS = \\sum_{i=1}&#94;{n}(x_i - \\bar{X}_{mean})&#94;2 $$ This gives us a sense of the total amount of squared deviations from the mean. This is a measure of spread. It may be useful to get an average of these values, i.e. the \"typical\" squared deviation from the mean. This is known as the mean squared deviation from the mean, or the variance . In the case of a known population mean , we can calculate this variance directly from our sample. In this case, all of our values are allowed to vary freely -- they are not reliant on this known population mean. So we can take the mean as follows: $$ \\hat\\sigma&#94;2 = \\frac{1}{n}\\sum_{i=1}&#94;{n}(x_i - \\mu)&#94;2 $$ Of course, this would not happen often in practice. But since the mean was known, our values are not linearly computable directly from it -- in this sense, they can be any values. If we do not, however, we must make a correction known as the Bessel's correction . The sample variance is the variance which takes this into account, as follows: $$ \\hat{s}&#94;2 = \\frac{1}{n-1}\\sum_{i=1}&#94;{n}(x_i - \\bar{X}_{mean})&#94;2 $$ Here, we divide by n-1 because the vector of $x_i - \\bar{x}_i$ is only allowed to vary in n-1 dimensions -- because it is determined once the other points are calculated. This is how degrees of freedom relates to the sample variance. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Beginner Statistics","url":"category/beginner-statistics/sumstatsmeasuresofspread.html","loc":"category/beginner-statistics/sumstatsmeasuresofspread.html"},{"title":"Summary Statistics Part 1: Central Tendency","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Summary Statistics (and what they mean) Welcome! In this (very first) post, we are going to be going over a few basic statistical concepts involving summary statistics and how we can use them. This is a great place to start for getting some idea on how statistics can work for you! Statistics courses usually start with a discussion of summary statistics, and for good reason. Summary statistics are the essential building blocks of statistics. When we talk about expectation, or prediction, we are actually talking about a summary statistic -- in many cases, and algorithms, the mean. For the most part, summary statistics can give us a good idea of the underlying distribution and, in some cases, are sufficient in describing a set of data points for a particular algorithm. Don't Be Another Statistic The first question that will come up immediately when discussing this is what exactly a statistic is. In everyday language many people use statistic to mean a way of summarizing data into a single data point. When people say things like \"You are not just a statistic!\", what they are generally referring to is how statistics are aggregates of data. That is, statistics cannot capture all of the truth, but only an average. So is it fair to say that statistics are purporting to be cold-hard facts gathered from data? Not exactly. Statistics are gathered from sample data, and are often used as an estimation of the population. In statistician speak, a population is the theoretical overarching group that we wish to infer about. For instance, the population can be men living in the United States, all of the atoms in the universe, or the set of all possible combinations of people into couples. A sample is a subset of the population, a smaller group derived from it. We use statistics derived from the sample to make inferences about the population, but by definition these are not exact -- they depend on the sample that we choose. Almost surely, if we were to choose another sample we would come up with a different statistic. Therefore, a statistician would not take a summary statistic to be the hard, cold \"truth\", but a signal, or estimation, of the \"cold hard truth.\" Statistics vs Statistic Unfortunately, much of the confusion about the nature of a statistic has to do with the field known as statistics. Confusing, but true. Statistics is generally what people are referring to when they talk about the hand-wavy idea -- \"gathering insights from data.\" But this treats data as though it is a fixed, constant thing. This couldn't be further from the case! This is exactly what makes statistics such an interesting field -- statistics deals with random variation. Statistics isn't used for cases of absolute certainty, like many of the sciences do, but revels in the uncertainty of real life. Indeed, nearly everything has random variation involved in it, and therefore nearly everything is in the scope of statistics. The way we can quantify uncertainty is by using the theories of probability. But that is for another post! In general, we do not say that a statistic is the \"ground truth\" but a description of sample data. This sample statistic is then used to estimate the </b> population parameters.</b> This comes from the initial distinction that many people make -- samples themselves are not a representation of the ground truth. When a statistic is used as a statement about the population, we call this statistic an estimator of the population parameter. In fact, population parameters are not nearly as interesting as sample statistics. A population parameter is not probabilistic at all -- if it is obtainable, then it will be a single value with no variation. Sample statistics, however, do vary, and sometimes considerably based on how the data is sampled and how large the sample is. Throughout this exercise, I am going to be using some code to give examples of how these things work. I will only be displaying code that I believe is helpful for the task at hand, and I will create a future article describing how this code is written using python. In this post, which I will be calling a \"framework\" post, I will only be describing how these things work. Then, in a \"application\" post, I will show how to write code to solve these problems with real-world data. Class Grades Now, onto an example. Suppose we have a class of 7th graders who had gotten the following grades on the previous exam: 95, 80, 50, 80, 100, 94. Let's start with the situation where this is the entire class. In this case, we are dealing with the population. That means, if we take the common 'statistics', we will not have a statistic at all but a parameter. This distinction makes it clear that we are not estimating anything, but are looking at the \"cold, hard truth.\" The population is then \"the grades of 7th graders on math test last week.\" If, however, we were trying to estimate their performance in the class overall from this test alone, then this is a sample , presuming there were other tests. Thus, the phrasing of the question is a large distinction. In [1]: from itertools import combinations import numpy as np import pandas as pd from scipy import stats import matplotlib as plt % matplotlib inline In [2]: class_grades = pd . Series ({ 'John' : 95 , 'Mary' : 80 , 'Jacob' : 50 , 'Jose' : 80 , 'Sarah' : 100 , 'Laura' : 94 }) class_grades Out[2]: John 95 Mary 80 Jacob 50 Jose 80 Sarah 100 Laura 94 dtype: int64 Central Tendency Given a set of data points, where do we start? A good start is determining the central tendency or what we often call the average. Here, I use the word average as a general case of central tendency -- we want to know what the average student in this class looks like. All of the following examples assumes that we have some finite sample of a finite population, but can be extended in the more general case. Arithmetic Mean One common example of an average is the arithmetic mean. We are all familiar with this from our schooling days: \\begin{equation} \\bar{X}_{mean} = \\frac{ \\sum_{i=0}&#94;{n} x_{i} }{n} \\end{equation} Here, we say that we sum over all of the possible values, and divide by the total number. We can see the results on our simple dataset above: $$ 95 + 80 + 50 + 80 + 100 + 94 = 499 = T \\\\ \\bar{x} = \\frac{T}{6} = 83.166 $$ In [3]: mean = class_grades . mean () mean Out[3]: 83.16666666666667 Median Another measure of central tendency is the median. The median is the value which half of the data is smaller and half is larger than. If there is an even number of points, we take the average of the two closest to the \"center\" of the ranked numbers. For example, we first list the points from smallest to largest: $$ 50, 80, 80, 94, 95, 100 $$ Then, we iteratively remove points from each side until we arrive at a single value (if the total number of points is odd) or two values (if it is even). This is shown below: $$ 50, 80, 80, 94, 95, 100\\\\ 80, 80, 94, 95\\\\ 80, 94\\\\ $$ Now that we have two values (since 6 = n is even), we take an average of these values. That is: $$ \\frac{(80 + 94)}{2} = 87 $$ Note that we can also express this as follows: Rank the $X_i$ from smallest to largest, where $i = 1, ..., n$. Define $X&#94;{(i)}$ as the $i$th order statistic , where $i$ is the rank in this list. Then: $$ \\tilde{X}_{median} = \\begin{cases} X&#94;{(\\frac{n+1}{2})}, & \\text{if n is odd}\\\\ \\frac{X&#94;{(\\frac{n+2}{2})} + X&#94;{(\\frac{n}{2})}}{2}, & \\text{if n is even} \\end{cases} $$ Then, $n$ in this case is 6, which is even. So we take the average of the 3rd and 4th order statistic, 80 and 94. This is the same result we had derived earlier. In [4]: median = class_grades . median () median Out[4]: 87.0 Mode Finally there is the mode. The mode is simply the most likely value, or the most recurring value. Thus there can be multiple modes if there are two values which are equally likely and are the most recurring in the dataset. We can summarize this by looking at the frequencies of each data point. For convenience, I have done this using pandas. In [5]: class_grades . value_counts () Out[5]: 80 2 95 1 94 1 100 1 50 1 dtype: int64 Because 80 occurs twice, it is the mode. In [6]: mode = class_grades . mode () mode Out[6]: 0 80 dtype: int64 For all unique values $u_j$ of $x_i$ in the sample, let $f(u_j) = \\sum_{x_i} 1, \\forall x_i = u_j$ Then, $f(u_j)$ is the frequency of unique value $u_j$. Then: $$ \\hat{X}_{mode} = \\{ u_j \\mid f(u_j) = \\max_{u_j}f(u_j) \\} $$ The set notation implies that it is possible for there to be multiple modes. If there is only one mode, such as in the case of the class grades, then we say that the sample is unimodal. Other Measures of Central Tendency These are all of the canonical measures of central tendency that you have likely heard about before. However, there are others as well such as those listed here . Check them out -- they're pretty interesting! For fun, I will show some examples below. Trimean The trimean is the weighted arithmetic mean of the median and two quartiles. That's a lot to unpack, so let me explain. By weighted, we mean that the observations are multiplied by some set of constants that place a magnitude on a particular observation. Higher weighted variables are considered more \"important\" to the calculation. Instead of dividing by the sample size, we divide instead by the sum of the weights . Another way of looking at this is that each observation is considered to have a probability of occurring, $\\frac{w_i}{\\sum_{i}w_i}$. Then, the weighted average is a generalization of the arithmetic average explained before, where the arithmetic average weighs each value equally, i.e, $w_i = c$ for all $i$. Then we arrive at the same formula we saw in equation (1). A quartile is the point that is greater then some multiple of 25% of the data. If there is no such discrete number, we take a weighted average to determine its value. It is called a quartile because it separates the data into four segments. The first quartile is the data point which is greater than 25% of the data, the second is the median (50% of the data), the third is for 75% of the data, and the forth quartile is also the maximum, greater than all of the data. Interestingly, this is often not considered a quartile, but by the same logic it can be considered one. The trimean is then defined as: $$ TM = \\frac{Q_1 + 2M + Q_3}{4} $$ Intuitively, this is the average of the Median (M) and the midhinge, defined as: $$ MH = \\frac{Q_1 + Q_3}{2} $$ This is calculated below: In [7]: def trimean ( series ): T = series . quantile ( . 25 ) + 2 * series . median () + series . quantile ( . 75 ) TM = T / 4 return ( TM ) TM = trimean ( class_grades ) TM Out[7]: 87.1875 In practice, it turns out that this estimator is a remarkably efficient estimator of the population, meaning it can accurately estimate the population mean if calculated on a sample with relatively fewer points than other estimators. For a symmetric distribution like the normal distribution, it is the most efficient as compared with the median, and other L-3 estimators. See here for more information. It is also is more robust than the mean, which will be discussed further below. Winsorized Mean This will be a good segue into the next section, which examines the most appropriate method of central tendency to use. The Winsorized Mean attempts to mitigate the effect of outliers -- values that are very far from what we would call the \"average\" value. If this doesn't make sense yet, don't worry. I'll be discussing it further later in the section on robustness. For now, we will just examine what this will look like. In the Winsorized mean, we will take the most extreme values of our sample and replace them with the most extreme remaining values. In this case, this is 50 and 100. So, our new, adjusted, sample to calculate the central tendency is: $$ \\tilde{S} = {80, 80, 80, 94, 95, 95} $$ Here, we replaced 50 with 80 -- the next smallest value -- and 100 with 95 -- the next largest value. In this case, the data is quite small, so we would likely not want to do this, but for a large dataset this can be useful. We then take the average of the remaining values. $$ \\frac{ \\sum_i \\tilde{s}_{i} }{n},\\\\ \\forall \\tilde{s}_i \\in \\tilde{S} $$ If you don't understand the notation, don't worry. We're just taking an average of our \"new\" sample. I just did it to be precise. In general, we can take the largest and smallest p% of data and replace it with the most extreme values within this range. This value is arbitrary, but is often taken to be 10 to 25% of the ends replaced. In this example, we take the top and bottom 10%, which trims the most extreme values on both sides. In [8]: def winsorized_mean ( series , percent_removed ): ## Taking the value which is greater than/less than percent_removed bot_quant = series . quantile ( percent_removed ) top_quant = series . quantile ( 1 - percent_removed ) #Finding the values to replace bottom = series [ series < bot_quant ] top = series [ series > top_quant ] #Replacements rep_bottom = min ( series [ series > bot_quant ]) rep_top = max ( series [ series < top_quant ]) replacement_dic = { b : rep_bottom for b in bottom } replacement_dic . update ({ t : rep_top for t in top }) # Make replacements, find mean S_tilde = series . replace ( replacement_dic ) winsorized_mean = S_tilde . mean () return ( winsorized_mean ) wm = winsorized_mean ( class_grades , . 1 ) wm Out[8]: 87.33333333333333 But wait! How can you just replace values like that! I know, it seems dishonest. The idea is that these values are extremely unlikely. In the case of 6 people, this is probably not the case. But imagine we had the following values: $$ 0, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 100 $$ In [9]: ex_outliers = pd . Series ( np . concatenate ([[ 0 ], np . repeat ( 95 , 18 ), np . repeat ( 96 , 12 ), [ 100 ]])) ex_outliers . mean () Out[9]: 92.5625 But, would we say that the average student received a grade of 92? This seems like an underestimation. Naively, if we choose the Winsorized mean, we would get the following: In [10]: winsorized_mean ( ex_outliers , . 1 ) Out[10]: 95.40625 This seems like a more accurate representation of the data. In the cases of outliers, one must be careful to examine the distribution of the data well before naively using one measure of central tendency, as the results may be very misleading. Which to choose? This is not always clear, as we saw above for the Windsorized mean. If we look at a histogram of the values, we can get a sense of the shape of the distribution. It turns out that the shape can help us determine which measure of central tendency best describes the distribution. In [11]: plt . pyplot . figure ( figsize = ( 15 , 10 )) plot = class_grades . hist () plot . axvline ( x = mean , color = 'red' , label = 'Arithmetic Mean' ) plot . axvline ( x = median , color = 'black' , label = 'Median' ) plot . axvline ( x = mode [ 0 ], color = 'green' , label = 'Mode' ) plot . axvline ( x = TM , color = 'yellow' , label = 'Trimean' ) plot . axvline ( x = wm , color = 'purple' , label = 'Winsorized Mean' ) plot . legend () Out[11]: <matplotlib.legend.Legend at 0x11662c5da58> All of these represent central tendency. To see this more easily, let's consider it on a larger dataset. In [12]: likelihood_estim = stats . beta . fit ( class_grades / 100 ) random_var = pd . Series ( np . random . beta ( likelihood_estim [ 0 ], likelihood_estim [ 1 ], 100 )) * 100 random_var = random_var . floordiv ( 1 ) C:\\Users\\ginge\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:437: RuntimeWarning: invalid value encountered in sqrt sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b) In [13]: plt . pyplot . figure ( figsize = ( 15 , 10 )) plot = random_var . hist ( bins = 30 ) plot . axvline ( x = random_var . mean (), color = 'red' , label = 'Arithmetic Mean' ) plot . axvline ( x = random_var . median (), color = 'black' , label = 'Median' ) plot . axvline ( x = random_var . mode ()[ 0 ], color = 'green' , label = 'Mode' ) plot . axvline ( x = winsorized_mean ( random_var , . 1 ), color = 'yellow' , label = 'Winsorized Mean' ) plot . axvline ( x = trimean ( random_var ), color = 'purple' , label = \"Trimean\" ) plot . legend () Out[13]: <matplotlib.legend.Legend at 0x11662e02d30> We see that this is a skewed distribution -- in particular it is left skewed . A majority of the students did well on the exam, but there were some who did particularly poorly, with some extreme values on the far left. In this case, where there are many extreme values, the mean is not a good \"average\" -- it is dragged down by the very small values in the tail. We can see this as the mean is close to 70, but it appears that the \"average\" student did better than this. The median is a more robust measure, because it is less sensitive to anomalies in the sample. The mode is not very useful in this case, as it is at the bin with the largest values. The \"average\" student likely did worse than this. In general, as a rule of thumb, for a unimodal distribution (meaning there is only one mode), it is often but not always the case that: Let $\\bar{X}_{median}$ be the median of a distribution and $\\bar{X}_{mean}$ be the arithmetic mean. Then: if $\\bar{X}_{median} << \\bar{X}_{mean}$, X is right skewed if $\\bar{X}_{median} \\approx \\bar{X}_{mean}$, X is approximately symmetric if $\\bar{X}_{median} >> \\bar{X}_{mean}$, X is left skewed This can be used as a guideline to see how skewed our distribution is. However, it is not foolproof - in some cases this fails. See this wikipedia article for more information. For instance, consider -6, -4, 0, 0, 2, 8. The mean and median are zero, but this distribution is skewed to the left, i.e. not symmetric. In [14]: plt . pyplot . figure ( figsize = ( 15 , 10 )) example = pd . Series ([ - 6 , - 4 , 0 , 0 , 2 , 8 ]) example . hist () plot . axvline ( x = example . mean (), color = 'red' , label = 'Arithmetic Mean' ) plot . axvline ( x = example . median (), color = 'black' , label = 'Median' ) plot . legend () Out[14]: <matplotlib.legend.Legend at 0x11662ea32e8> In general, since the median is a more robust measure, if we are given a sample and wish to estimate the behavior of the population and we believe that the skewed values are anomalies , the median is a better \"guess\" of the central tendency. Interestingly, the two \"non-typical\" central tendency estimators, the Windsorized mean and the Trimean, lay between the mean and the median. The Windsorized mean and Trimean are both more robust then the mean, meaning they are less sensitive to extreme values. This is directly dealt with in the Windsorized mean and is implicit in the Trimean in a method similar to taking the median. Notice also that the median and mean tell us different things about the data. The mean uses all of the information available, and each data point contributes equally to the evaluation of it. On the other hand, the median \"cuts away\" all of the data not at the 50% mark. In this way, the median can be seen as an extreme version of the Windsorized Mean where we cut out the bottom 49% and 51%. In this case, we are seeing a trade-off between robustness which is the variability of the estimator under anomalies and varying sample distributions, and power (or efficiency ), which can determine a more stable solution with less data assuming certain assumptions are met. For instance, if we know that the population distribution follows some \"known\" distribution, it can often be shown that the mean is a sufficient, unbiased estimator of the true population mean. In the case of the normal distribution, it is the most efficient estimator of the population mean, while the median is relatively inefficient. This means that the median will require more data to obtain the same level of accuracy as the mean. To sum it all up -- the mean is often the most efficient estimator in certain simplifying conditions, but is not robust. On the other hand, the median is robust , but not as efficient. Samples of samples of samples, oh my! Why do we care about these measures of central tendency? Well, let's take a look at how they function in terms of predicting a population parameter. Suppose, as we talked about before, the population in a simplistic example is 95, 80, 50, 80, 100, 94. Let's consider all possible samples of 3 of this data. There are 6 data points and we wish to choose 3. This means there are 6 choose 3, or 20 possible samples. The possible samples are: In [15]: possible_samples = combinations ( class_grades , 3 ) list ( possible_samples ) Out[15]: [(95, 80, 50), (95, 80, 80), (95, 80, 100), (95, 80, 94), (95, 50, 80), (95, 50, 100), (95, 50, 94), (95, 80, 100), (95, 80, 94), (95, 100, 94), (80, 50, 80), (80, 50, 100), (80, 50, 94), (80, 80, 100), (80, 80, 94), (80, 100, 94), (50, 80, 100), (50, 80, 94), (50, 100, 94), (80, 100, 94)] We remember from before that the population mean is 83.16666. This is a population parameter -- it is not a statistic. However, suppose we sampled randomly from this population and retrieved the sample data: 80, 94, 80. Then our estimate of the population mean would be 84.6. Remember when I said that the statistic is never the \"cold hard\" truth? Here is a direct example. However, there are some nice properties of this. Consider the means and medians of all the samples: In [16]: sample_dict = {} for i , x in enumerate ( combinations ( class_grades , 3 )): sample_dict [ i ] = x sample_results = pd . DataFrame ( sample_dict ) . T sample_results [ 'mean' ] = sample_results . mean ( axis = 1 ) sample_results [ 'median' ] = sample_results . iloc [:, 0 : 3 ] . median ( axis = 1 ) sample_results Out[16]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 mean median 0 95 80 50 75.000000 80.0 1 95 80 80 85.000000 80.0 2 95 80 100 91.666667 95.0 3 95 80 94 89.666667 94.0 4 95 50 80 75.000000 80.0 5 95 50 100 81.666667 95.0 6 95 50 94 79.666667 94.0 7 95 80 100 91.666667 95.0 8 95 80 94 89.666667 94.0 9 95 100 94 96.333333 95.0 10 80 50 80 70.000000 80.0 11 80 50 100 76.666667 80.0 12 80 50 94 74.666667 80.0 13 80 80 100 86.666667 80.0 14 80 80 94 84.666667 80.0 15 80 100 94 91.333333 94.0 16 50 80 100 76.666667 80.0 17 50 80 94 74.666667 80.0 18 50 100 94 81.333333 94.0 19 80 100 94 91.333333 94.0 We see that both the mean and the median vary around the true population mean for each sample. This is the sampling distribution of the sample mean. This is what has a distribution and can vary! Remember, our population parameter is fixed, but the variation implicit in each sample is what controls the distribution here. Since this too is a distribution, we can examine statistics about it. In [17]: sample_results . drop ([ 0 , 1 , 2 ], axis = 1 , inplace = True ) sample_results . mean ( axis = 0 ) Out[17]: mean 83.166667 median 87.200000 dtype: float64 In [18]: mean Out[18]: 83.16666666666667 Hmm, that seems odd. It turns out that the expectation, or arithmetic mean, of the sampling distribution of the sample mean is equal to the true population mean! This property actually follows directly from the definition of the arithmetic mean. We're going to go into some maths here, but feel free to skip over it if you don't want to. The point here is that the sample mean is an unbiased estimator of the population mean . Theorum 1: If $S$ is a sample of size $k$ from a population of size $N$ drawn randomly and without replacement , then the mean of the sample, $\\bar{X}_S$, is an unbiased estimator of the population mean. Let $\\bar{X}_P$ be the population mean. Then $$ \\bar{X}_P = \\frac{ \\sum_{i=1}&#94;{N} x_{i} }{N}\\\\ $$ Let $\\bar{X}_s$ be the mean of a sample of size k, called $S_s$. Then, $$ \\bar{X}_s = \\frac{ \\sum_j x_{j, s} }{k}\\\\ $$ Where $X_{j,s}$ is the $j$th observation from sample $s$. It follows that there are ${N}\\choose{k}$ possible samples, ie, $s$ runs from $1$ to ${N}\\choose{k}$. Let $M =$ ${N}\\choose{k}$. Then: $$ \\sum_{s=1}&#94;{M} \\frac{\\bar{X}_s}{M} =\\frac{\\sum_{s=1}&#94;{M} \\sum_j \\frac{x_{j, s}}{k}}{M}\\\\ =\\frac{\\sum_{s=1}&#94;{M} \\sum_j x_{j, s}}{kM} $$ Each value of the population will appear in ${N}\\choose{k}$ - ${N-1}\\choose{k}$ = $M - \\frac{M(N-k)}{N}$ samples. We can say this because it is the total number of possible samples ${N}\\choose{k}$ minus the total number of samples of size $k$ which do not contain observation $j$, ${N-1}\\choose{k}$. So then we have: $$ \\frac{M - \\frac{M(N-k)}{N}}{kM} \\sum_i x_i $$ Expanding the left hand side: $$ \\frac{M - \\frac{M(N-k)}{N}}{kM} = \\frac{1}{k} - \\frac{N-k}{kN} =\\frac{1}{N} $$ so $$ \\sum_{s=1}&#94;{M} \\frac{\\bar{X}_s}{M} = \\frac{ \\sum_{i=1}&#94;{N} x_{i} }{N}\\\\ $$ But, we now see that this is exactly equal to the population mean, $\\bar{X}_P$! Since we weighed each sample equally in this expectation, this is equivalent to sampling randomly without replacement. This means that we have proven the result -- the sample mean is an unbiased estimator of the population mean. This is a powerful result! Hopefully you can begin to see why statistics is so exciting now! We have proven that any inference about the population mean using a sample mean will, on average, be accurate. However, it is important to note that while the sample mean is unbiased, it does not make it the most accurate estimator. This will be covered in the next post, when we discuss the Measures of Spread. We've seemed to disregard the median in this case. Why is this? Well, the median is not an unbiased estimator of the population mean. However, we see that the case changes quite a bit when we take the medians! In [19]: sample_results . median ( axis = 0 ) Out[19]: mean 83.166667 median 87.000000 dtype: float64 In [20]: median Out[20]: 87.0 In this case we see that both the mean and the median are equal to the population values. What gives?! Well, it turns out that the sample median is a median unbiased estimator of the population median. This one is a bit tougher to prove, so I will leave it for now. Perhaps we can get back to it when we discuss probability density functions, as it requires some use of this. What about the mean? Why is the mean a median unbiased estimator of the population mean? The reason is because of the Central Limit Theorum, but this is something that will take some time to discuss! However, because the sampling distribution of the sample mean will tend to a normal distribution relatively quickly, it also becomes symmetric quickly. In this case, the median converges towards the mean. That is why we see that the mean in this case is again equal to the median. We can look at a histogram to see the details: In [21]: plt . pyplot . figure ( figsize = ( 15 , 10 )) sample_results [ 'mean' ] . hist () Out[21]: <matplotlib.axes._subplots.AxesSubplot at 0x11662e70278> Conclusion In this first post, we went over what a statistic is and the distinction between a sample and a population. We also discussed measures of central tendencies and their relation to sampling distributions. In the next post, we will be discussing the Measures of Spread which will shed light further on the sampling distribution of the sample mean. Hope you enjoyed! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Beginner Statistics","url":"category/beginner-statistics/sumstatscentraltendency.html","loc":"category/beginner-statistics/sumstatscentraltendency.html"},{"title":"NYPD Stop and Frisk","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } The Results of Stop and Frisk: What Contributes Most to Arrests? Note: All of the code associated with this project, as well as the data used, is accessible at my GitHub repository here . The code is omitted here for brevity. For the complete code used in this project, please visit the GitHub repository listed above, or check out this article which also includes the R code as well as some unannotated intermediate results. Introduction In this project I will be looking at a dataset available from the city of New York about the results of the Stop, Question and Frisk policy. Which factors lead to the highest likelihood of arrest? The data is a collection of 22,564 cases of Stop, Question and Frisk in the City of New York in 2015. There are 112 variables which were measured. A majority of the variables in the dataset are categorical variables relating to the incident itself, while a few represent the age, race, height, weight, and sex of the person who was on the receiving end of the policy. Stop and Frisk has been a controversial policy in New York City for quite some time. Many feel that it is a violation of privacy, that it is unconstitutional, or that the policy is inherently racist - that it disproportionately affects minorities and people of color. Meanwhile, there are others who support the policy, believing stop and frisk to keep people safe from terrorists and other wrongdoers. As a result of this and other recent controversies involving police across the country, the NYPD has been getting a lot of negative press over the way it addresses these racial problems. What I aim to discover by analyzing this dataset are the main contributing factors to whether a person is arrested or not in a stop and frisk incident. I will be using a few different methods of analysis to determine the best model to use in predicting whether a person will be arrested or not. Because the response variable, arstmade, is a qualitative, binary variable, I will be using categorical methods. These include logistic regression, K-Nearest Neighbors analysis and tree methods (like bagging, random forests, boosting). Data The data comes from the City of New York. It is a collection of 22,564 observations of 112 variables. Some of these variables had to be removed, as they did not contribute any information (for instance, they were the same value for all observations) or they had too many missing values. After removing these variables from the dataset, I had 75 variables to work with, with 22,563 observations. For example, lineCM was a redundant variable, as it had 1's for all observations. I also removed apt number, state and zip, as many of these values were left blank. Overall, none of the variables I was very interested in had any missing values, so removing these variables likely had very little effect on the analysis, if any. There were two variables for height (ht_inch and ht_feet) which I combined into one (height). The response variable I used for all of the following analyses was arstmade, which was a categorical variable that had values of \"Y\" for yes and \"N\" for no. Many of the categorical variables in the dataset followed this pattern. The percentage of arrests in all cases was 0.18, meaning that around 18% of the stops resulted in an arrest. The mean age of people who were stopped and frisked was around 29 years. Most of the people who were stopped were males (92.42%). Force was used in about 27% of the cases. In investigating whether blacks were targeted more frequently and if they were arrested more frequently, I created a categorical variable that was 1 if the person was black and 0 otherwise. Below is a bar graph of the arrests, with the colorings indicating the percentage who were black and non-black. It does not seem from these graphs alone that blacks were more likely to be arrested, since they have roughly half of the bars in both instances. However, it does seem like there are a disproportionate number of blacks who are stopped and frisked in the first place, which is shown in the second graph. With blacks making up roughly 23% of the population, it is surprising that almost double that (53%) of the people who were stopped were black In [4]: ggplot ( mydata , aes ( arstmade )) + geom_bar ( aes ( fill = black )) + ggtitle ( \"Bar Graph of Arrests for Blacks vs. Non-Blacks\" ) + xlab ( \"Was the person arrested?\" ) + ylab ( \"Numer of Incidences\" ) + scale_fill_discrete ( name = \"Race\" , labels = c ( \"Non-Blacks\" , \"Blacks\" )) In [5]: ggplot ( mydata , aes ( black )) + geom_bar ( fill = \"red\" ) + ggtitle ( \"Blacks vs. Non-Blacks Who Were Stopped and Frisked\" ) + xlab ( \"Was the person black?\" ) + ylab ( \"Number of Incidents\" ) Some more interesting things found in the descriptive statistics: Around 6.7 times more people were arrested than given summonses. That is, only 2% of the people were given summonses. None of the people who were stopped had a machine gun, so I removed this variable from the data. I removed any variable which had levels that were exactly one, as this indicated that there was no variation between observations. Although the suspected crime variable (crimsusp) was of interest to me in my analysis, I found the data to be inconsistent in how it was recorded. For instance, if it was a felony, the officer had data entered that had both \"FEL\" and \"FELONY\" in two different cases. Of course, R would not be able to recognize the fact that these are the same, and would treat them as separate variables. As such, I decided to remove any variables which had levels larger than 10, as this would indicate that the data was too separated to be meaningful. Since much of this information is contained in the categorical variables (such as the rs variables, which had different values for different reasons for stopping the person), it was relatively inconsequential in my analysis to do so. There were also groupings which could raise doubt as to whether the information recorded was accurate. Of primary concern to me was pf_other (physical force used: other), rs_other (reason for search: other) and ac_other (additional circumstances: other). These are not very informative, and could be raise a speculative point about whether these were truly extraordinary cases or if they were omitted for other reasons. Of course, that is merely speculation, but it is important to note that this is a source of potential inconsistency and unreliability from the dataset. Even worse, some of these variables contributed a lot to the models which I have fit. Below shows a bar graph of the number of arrests conditional on whether the reason for search was classified as \"other.\" In [6]: ggplot ( mydata , aes ( sb_other )) + geom_bar ( aes ( fill = arstmade )) + ggtitle ( \"Arrests Conditional on if Reason for Search classified as OTHER\" ) + xlab ( \"Was the reason for search classifed as other?\" ) + ylab ( \"Number of Incidents\" ) + scale_fill_discrete ( name = \"Arrest Status\" , labels = ( c ( \"Not Arrested\" , \"Arrested\" ))) This confirms the results of the analysis below, as this variable has a large effect on whether the person was arrested or not. If the person was classified as being searched for other reasons not specified, they were arrested quite often. This leads to a limitation of the data and interpretation - we can not determine what the true reasons were. sb_other accounted for around 10.7% of all the cases, and 57.6% of all the people who were searched. Analysis and Model Fitting Logistic Regression I separated the data into two sets - test data and training data. The training data was randomly sampled from ¾ of the data. I began my analysis by using a logistic regression model to predict arstmade on all of the other variables. This was because the response variable was categorical, so it was necessary to use a logistic model instead of a linear model with normal errors. I then used stepwise reduction to determine the best fit and to reduce the amount of variables used. Since there were a great deal of variables that came up insignificant in the full model, it reduced the model quite a lot. I used the glm function using the binomial family to model the data. Below is a summary of the results of the models: In [11]: table1 arrest.test fit1 N Y 0 4513 397 1 126 590 In [12]: misclasserrorsfull table2 misclasserrorstepwise 0.0945609669392108 arrest.test fitted2 N Y 0 4508 401 1 131 586 0.0929612513330963 Using the stepwise regression model determined by the AIC produced a marginally better misclassification error, from .095 to .093 (or 9.5 % to 9.3%). This isn't a very big improvement, though. Surprisingly, the model does not find any of the race factors to be significant in determining whether an arrest was made or not besides Q, which stands for the White-Hispanics. That is, all of the levels of the \"race\" variable other than \"White-Hispanic\" came up insignificant. All of these coefficients are positive besides \"U\", which stood for \"unknown\", which essentially means that if the person's race was known, the odds of arrest are higher. The full summary of the stepwise regression is included in the appendix(1). When the stepwise regression was performed, we could see that contraband and knife/cutting instrument variables were highly significant in determining whether a person would get arrested or not. These variables are both very significant in the reduced logistic model. The variables that represent the different boroughs were all found to be significant, all with negative values. This suggests that the variable that was not included in the factors (the Bronx) had a higher likelihood of being arrested than any of the other four boroughs. Since the largest coefficient is that of Staten Island it means that, all else equal, a person from Staten Island who was stopped and frisked was less likely to be arrested than a person from Manhattan. The model also indicates that people who had a weapon were more likely to be arrested during a stop and frisk. This is logical, as if the police had found a weapon, it is quite likely that the person would be arrested. If the officer was in uniform, interestingly, a person would be less likely to be arrested, according to the model. If the police officer stopped the person because they knew them (indicated by rf_knowlY), the person was less likely to be arrested. If the reason the officer used force was to defend themselves, the person was less likely to be arrested than if the reason for force was that the person was suspected of running away. If the person is searched, they had a higher chance of being arrested than if they were not searched. KNN The next model I used was the K-Nearest Neighbors approach. K-Nearest Neighbors is a non-parametric method, so it does not make assumptions about the underlying distribution of the variables. K-Nearest Neighbors works by finding the nearest data points to the ones you are testing them against and assigning a classification based on the nearest k points. I have used k=5 and k=10 in this model to see if they can accurately predict the chances of arrest. Below are the tables for predicted vs actual arrest values for the test set, as well as the misclassification error, for the 10-nearest neighbor method (as this was the most successful.) In [15]: table3 round ( KNNMisclass , 3 ) arrest.test knn.predict N Y N 4479 749 Y 160 238 0.162 The 10-Nearest Neighbor model was the most successful of the different k's I used (I tried 1, 5, 10, and 20). Still, it doesn't produce very good outcomes compared to the logistic model. In fact, if I were to guess that none of the people would get arrested, I would have an error of about 18%, so this model is only marginally better than the trivial method. The failure of this method is due to the fact that the variables cannot exactly be scaled, and the distances are affected by this. As there are many categorical variables and few continuous ones, high numbers of the continuous variables may have influenced the predictions, since the KNN function in R uses Euclidian distances to predict the outcomes. To rectify this, I perform the K-NN method using only the categorical variables. The predictions are slightly better in this model, as shown by the confusion matrix and misclassification rate below. In [16]: table4 round ( KNNMisclass2 , 3 ) arrest.test knn.predict2 N Y N 4547 582 Y 92 405 0.12 Interestingly, while the error is still larger than the logistic models, or in fact any of the models I used in the analysis, it is more accurate at predicting an arrest when an arrest was made than any of the earlier models, suggested by the second row of the confusion matrix above. That is, while it produces more overall error than any of the models I've used, it also produces the smallest type I error out of any of the models (the false positives). Tree-Based Methods I will now use tree-based methods (a single tree, Random Forest, Bagging and Boosting) in order to predict whether a person will be arrested or not. The first model I use will be an unpruned tree using all the variables. The tree selects groupings of the variables which produces the least errors in predictions, and lists decision trees based on the conditional results of each tree. It determines these factors by a popular vote in the case of classification trees, so that the most common outcome is the one which is predicted by the tree. The tree is posted below. In [17]: tree . arrest <- tree ( arstmade ~ . , mydata [ train , ]) In [18]: plot ( tree . arrest , main = \"Unpruned Tree\" ) text ( tree . arrest , cex = 0.9 ) This tree has six nodes, so it is relatively simple. If the statement is true, you go to the right, and if it is false you go to the left. The top node is whether the person was searched or not. This makes sense, as if a person is searched, the police are more likely to find a reason to arrest the person (because of illegal goods, etc). It is already evident that this tree can be pruned. For the trhsloc and pf_hcuff variables, either decision results in the same response. This means that the variable is redundant, and can be removed from the tree. The values that are included are: searched, repcmd (reporting officers command, which takes values from 1 to 999), contrabn (contraband), sb_hdobj (basis of search being a hard object), trhsloc P,T (whether the location was a transit location or housing location), and pf_hcuff(force used was handcuffing). Some of these are quite interesting: the fact that the officers command has an influence on whether the person was arrested or not, and also the fact that regardless of whether the person was handcuffed or not, they were not reported as arrested if they reach the bottom left node. This defies our common sense - as we often expect someone who is handcuffed to be arrested. Based on the prior conditional factors, the tree says that if someone is handcuffed given they don't have contraband, they weren't searched, and the reporting officers command was less than 805, they would be classified as not being arrested. Since we already have seen that we should prune this tree, I will find the correct number of nodes to prune to by plotting the cross-validation errors. In [19]: cv . arrest <- cv . tree ( tree . arrest , FUN = prune . misclass ) In [20]: plot ( cv . arrest $ size , cv . arrest $ dev , type = \"b\" , xlab = \"Number of Nodes\" , ylab = \"Deviance\" , main = \"Determining Best Reduction of Trees by Deviance\" ) points ( 3 , cv . arrest $ dev [ 3 ], col = \"red\" ) There is a clear leveling off at 3, marked with a red point, so we will prune the next tree to three nodes. In [21]: prune . arrest <- prune . misclass ( tree . arrest , best = 3 ) In [22]: plot ( prune . arrest ) text ( prune . arrest ) This tree is extremely small, and only considers two variables - whether a person was searched and whether the reason for the search was that they had a hard object. Below, I post the tables for the pruned and unpruned trees, along with their misclassification errors. In [23]: tree . pred <- predict ( tree . arrest , newdata = mydata . test , type = \"class\" ) table5 <- table ( tree . pred , arrest . test ) misclassificationunprune <- 1 - sum ( diag ( table5 )) / nrow ( mydata . test ) pruned . pred <- predict ( prune . arrest , newdata = mydata . test , type = \"class\" ) table6 <- table ( pruned . pred , arrest . test ) misclassificationprune <- 1 - sum ( diag ( table6 )) / nrow ( mydata . test ) In [24]: table5 round ( misclassificationunprune , 3 ) table6 round ( misclassificationprune , 3 ) arrest.test tree.pred N Y N 4426 447 Y 213 540 0.117 arrest.test pruned.pred N Y N 4466 486 Y 173 501 0.117 The misclassification errors are quite high for the single trees, which is expected since one tree will rarely be sufficient in predicting the outcome. They perform roughly the same on the data, which indicates that the pruning was effective - we were able to reduce the nodes without significantly effecting the accuracy of the models. It is notable that the pruned tree reduced Type I error, which is more desirable in this case. Still, both trees performed better on the overall error than the KNN approach. Next, I will use the bagging method. The bagging method, or bootstrap aggregation, uses bootstrap samples repeatedly to create many trees, and then averages these trees to make predictions. In the case of a classification problem such as this one, bagging will predict by the majority vote. Performing bagging with 300 trees reports the following confusion matrix and misclassification error: In [25]: bag . arrest <- randomForest ( arstmade ~ . , data = mydata [ train , ], mtry = ( ncol ( mydata ) - 1 ), importance = TRUE , ntree = 300 ) bag . pred <- predict ( bag . arrest , newdata = mydata . test , type = \"class\" ) table7 <- table ( bag . pred , arrest . test ) misclassificationbagging <- 1 - sum ( diag ( table7 )) / nrow ( mydata . test ) In [26]: table7 round ( misclassificationbagging , 3 ) arrest.test bag.pred N Y N 4505 285 Y 134 702 0.074 This is a large improvement over any of the previous methods we have used. In order to make the results more easily interpretable and prevent overfitting, I will reduce the number of trees used. Looking at the plot below can help us determine the correct number of trees to use : In [27]: plot ( bag . arrest , main = \"Trees vs Errors\" ) This plot determines the errors produced by each amount of trees. Using this, we can see visually where the line appears to stabilize and use this information to minimize the loss in accuracy from removing the trees. The green line shows the errors for the affirmative case (which is more likely), the red line for the negative case, and the black line for the overall error (the same as the misclassification error above). The plot appears to level off at around n=25. When I recreated the model using only 25 trees, I found the misclassification error to be 0.076. The error and confusion matrix will be included in the appendix. Although this is slightly higher than the model using 300 trees, it it a very small reduction in accuracy for a rather large increase in the interpretability and utility of the model. Now that we have determined a good amount of trees, we can look at an importance plot to see which variables create the most variations in the errors. Since this is a categorical variable, it will be most useful to use the right graph, which uses the Gini index. In [28]: bag . arrest2 <- randomForest ( arstmade ~ . , data = mydata [ train , ], mtry = ( ncol ( mydata ) - 1 ), importance = TRUE , ntree = 25 ) bag . pred2 <- predict ( bag . arrest2 , newdata = mydata . test , type = \"class\" ) table8 <- table ( bag . pred2 , arrest . test ) misclassificationbagging2 <- 1 - sum ( diag ( table8 )) / nrow ( mydata . test ) varImpPlot ( bag . arrest2 ) The variable with the most importance is sb_other, which is reason for search:other. This is a troubling thing, as described in the data section, because this is not a very informative variable. We can see that race now does have some importance in determining the arrests, as well as some other variables that were ommited from the logistic regression model. Interestingly, age, weight and height are included quite highly as well. Once again, whether the person was searched, had contraband, or was handcuffed is determined as important, which is consistent with our findings from the logistic regression. By using a sample of the variables in each tree and performing the bagging method on a different subset for each iteration, we can implement a Random Forest method. This method is useful since it allows some variation in the trees, since they will not only be dominated by the most important variables. Using two numbers for the number of variables used, I produced two random forest models. Below are their confusion matrices and misclassification errors. In [29]: table7 misclassificationbagging table8 misclassificationbagging2 arrest.test bag.pred N Y N 4505 285 Y 134 702 0.0744756487735514 arrest.test bag.pred2 N Y N 4490 277 Y 149 710 0.0757198720227515 The misclassification errors for the two are nearly identical. They perform very similarly to the bagging method. I would prefer the second model, as it predicts better in the case that the prediction and observed value are both yes than they are both no. By using a similar method to the bagging method earlier, we determine a good reduction in the amount of trees is to 40. Using 40 trees, we get the following confusion matrix and misclassification error. In [31]: table11 misclassRF3 arrest.test RF3.pred N Y N 4515 293 Y 124 694 0.0741201564166371 In this case, the error actually was reduced. This can be accounted for by the fact that it simplified the model, which resulted in the random forest model with 40 trees actually predicting better than the more complex model. This suggests that the increase in bias by using a simpler model with 40 trees was less than the decrease in variance of the model on the testing data. This model performs the best of all the models I have used, and is the most successful at predicting whether a person is arrested or not when they are stopped and frisked, with about a 7.2% misclassification rate. Conclusions Below is a table summarizing all of the models that I've used, and their misclassifcation errors on the test data. In [32]: Method <- c ( \"Full Logistic Model\" , \"Reduced Logistic Model\" , \"10-NN Full Model\" , \"5-NN Reduced Model\" , \"Pruned Tree\" , \"Unpruned Tree\" , \"Bagging (n=300)\" , \"Bagging (n=25)\" , \"Random Forest I (n=300)\" , \"Random Forest II (n=300)\" , \"Random Forest III (n=40)\" ) TestError <- c ( misclasserrorsfull , misclasserrorstepwise , KNNMisclass , KNNMisclass2 , misclassificationprune , misclassificationunprune , misclassificationbagging , misclassificationbagging2 , misclassRF , misclassRF2 , misclassRF3 ) TestError <- round ( TestError , 3 ) data . frame ( Method , TestError ) # error: Yes when No Er1 <- table1 [ 2 , 1 ] / sum ( table1 [ 2 , ]) Er2 <- table2 [ 2 , 1 ] / sum ( table2 [ 2 , ]) Er3 <- table3 [ 2 , 1 ] / sum ( table3 [ 2 , ]) Er4 <- table4 [ 2 , 1 ] / sum ( table4 [ 2 , ]) Er5 <- table5 [ 2 , 1 ] / sum ( table5 [ 2 , ]) Er6 <- table6 [ 2 , 1 ] / sum ( table6 [ 2 , ]) Er7 <- table7 [ 2 , 1 ] / sum ( table7 [ 2 , ]) Er8 <- table8 [ 2 , 1 ] / sum ( table8 [ 2 , ]) Er9 <- table9 [ 2 , 1 ] / sum ( table9 [ 2 , ]) Er10 <- table10 [ 2 , 1 ] / sum ( table10 [ 2 , ]) Er11 <- table11 [ 2 , 1 ] / sum ( table11 [ 2 , ]) # error: No when Yes Er21 <- table1 [ 1 , 2 ] / sum ( table1 [ 1 , ]) Er22 <- table2 [ 1 , 2 ] / sum ( table2 [ 1 , ]) Er23 <- table3 [ 1 , 2 ] / sum ( table3 [ 1 , ]) Er24 <- table4 [ 1 , 2 ] / sum ( table4 [ 1 , ]) Er25 <- table5 [ 1 , 2 ] / sum ( table5 [ 1 , ]) Er26 <- table6 [ 1 , 2 ] / sum ( table6 [ 1 , ]) Er27 <- table7 [ 1 , 2 ] / sum ( table7 [ 1 , ]) Er28 <- table8 [ 1 , 2 ] / sum ( table8 [ 1 , ]) Er29 <- table9 [ 1 , 2 ] / sum ( table9 [ 1 , ]) Er210 <- table10 [ 1 , 2 ] / sum ( table10 [ 1 , ]) Er211 <- table11 [ 1 , 2 ] / sum ( table11 [ 1 , ]) FalsePositive <- round ( c ( Er1 , Er2 , Er3 , Er4 , Er5 , Er6 , Er7 , Er8 , Er9 , Er10 , Er11 ), 3 ) FalseNegative <- round ( c ( Er21 , Er22 , Er23 , Er24 , Er25 , Er26 , Er27 , Er28 , Er29 , Er210 , Er211 ), 3 ) Method TestError Full Logistic Model 0.095 Reduced Logistic Model 0.093 10-NN Full Model 0.162 5-NN Reduced Model 0.120 Pruned Tree 0.117 Unpruned Tree 0.117 Bagging (n=300) 0.074 Bagging (n=25) 0.076 Random Forest I (n=300) 0.074 Random Forest II (n=300) 0.073 Random Forest III (n=40) 0.074 In [33]: data . frame ( Method , TestError , FalsePositive , FalseNegative ) Method TestError FalsePositive FalseNegative Full Logistic Model 0.095 0.176 0.081 Reduced Logistic Model 0.093 0.183 0.082 10-NN Full Model 0.162 0.402 0.143 5-NN Reduced Model 0.120 0.185 0.113 Pruned Tree 0.117 0.283 0.092 Unpruned Tree 0.117 0.257 0.098 Bagging (n=300) 0.074 0.160 0.059 Bagging (n=25) 0.076 0.173 0.058 Random Forest I (n=300) 0.074 0.137 0.064 Random Forest II (n=300) 0.073 0.146 0.060 Random Forest III (n=40) 0.074 0.152 0.061 I have also included the false positive and false negative results, as these can help to determine which models fit the best. The Random Forest model which used 40 trees and 39 variables performed the best out of all the methods used. It is clear that the bagging and random forest methods were superior to the logistic and KNN methods. Of the simpler methods, the reduced Logistic Model using stepwise reduction with the AIC performed the best. Despite my original inclinations, we can see from the importance plots on the bagging model and the summaries of the logistic model that race was not a very significant factor in determining whether a person would be arrested or not. However, as we saw before from the bar graphs, there was a significantly larger portion of blacks who were stopped and frisked than the general population. This suggests that a black person is more likely to be stopped, but not significantly more or less likely than other races to be arrested after they are stopped. Which raises the question: why stop more black people if they are no more likely to be arrested after the frisk than other races? Another variable of interest was sb_other. This variable indicates that there was an \"other reason for stopping the subject.\" As such, this variable is difficult to interpret. However, the variable was quite significant with a high coefficient in the logistic model, and was rated as the most important variable by a large margin in the bagging models. This is a point of difficulty in the interpretations. This may indicate that there needs to be more disclosure about the reason a person was searched, since the sb variables in their current state fail to capture much of the reasons for arrest. In both the logisitic and bagging methods, the variables for contraband and knife/cutting object came up as significant, and had a significant effect on whether the person was arrested or not. This is logical: if the officer found a weapon on contraband on the person, they were much more likely to be arrested. This was far more significant than other factors about the person, in particular the cs variables, which list the reasons why the person was stopped, or the age, weight, gender and race variables, which are the physical attributes of the person. This suggests that the physical attributes of a person are not nearly as important as criminal possession in predicting an arrest, which is in support of the stop and frisk's usage. For instance, being stopped due to the clothing you wear (cs_cloth) or being perceived as a lookout (cs_lkout) were not nearly as significant as carrying a suspicious object (cs_object) or if they were searched (searched), and actually had negative coefficients. So it appears that, most of the time, the probability of being arrested was largely reliant on whether the person was searched or not, or found to have an object. This matches up with the significance and postive coefficient of cs_drgtr, which was the variable representing the cause of search being for a suspected drug transaction. One would conclude that if a person was being suspected for a drug transaction, they would also be more likely to have contraband or perhaps a weapon than if they were not. Interestingly, the frisked variable was not found to be significant in the logistic regression model, suggesting that frisking, as compared to searching, was not very significant in arrest, and therefore not too effective a measure to stop criminal activity. In both models, searching had a stronger effect than frisking in determining whether a person was arrested or not. The success of the random forest/bagging methods as compared to the simpler methods suggests that the relationship between whether a person is arrested or not and the various variables in the dataset is quite complex, and that it cannot be estimated as well using the simpler techniques. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Projects","url":"category/projects/nypd_stop_frisk.html","loc":"category/projects/nypd_stop_frisk.html"},{"title":"NYPD Stop and Frisk -- Full Code","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } The Results of Stop and Frisk: What Contributes Most to Arrests? Note: All of the code associated with this project, as well as the data used, is accessible at my GitHub repository here . This contains all of the code used in this project , unannotated. Introduction In this project I will be looking at a dataset available from the city of New York about the results of the Stop, Question and Frisk policy. Which factors lead to the highest likelihood of arrest? The data is a collection of 22,564 cases of Stop, Question and Frisk in the City of New York in 2015. There are 112 variables which were measured. A majority of the variables in the dataset are categorical variables relating to the incident itself, while a few represent the age, race, height, weight, and sex of the person who was on the receiving end of the policy. Stop and Frisk has been a controversial policy in New York City for quite some time. Many feel that it is a violation of privacy, that it is unconstitutional, or that the policy is inherently racist - that it disproportionately affects minorities and people of color. Meanwhile, there are others who support the policy, believing stop and frisk to keep people safe from terrorists and other wrongdoers. As a result of this and other recent controversies involving police across the country, the NYPD has been getting a lot of negative press over the way it addresses these racial problems. What I aim to discover by analyzing this dataset are the main contributing factors to whether a person is arrested or not in a stop and frisk incident. I will be using a few different methods of analysis to determine the best model to use in predicting whether a person will be arrested or not. Because the response variable, arstmade, is a qualitative, binary variable, I will be using categorical methods. These include logistic regression, K-Nearest Neighbors analysis and tree methods (like bagging, random forests, boosting). In [3]: set.seed ( 43 ) install.packages ( 'tree' ) require ( ggplot2 ) require ( tree ) require ( class ) require ( randomForest ) download_link <- \"http://www.nyc.gov/html/nypd/downloads/zip/analysis_and_planning/2015_sqf_csv.zip\" tmp <- tempfile () download.file ( download_link , tmp ) mydata <- read.csv ( unz ( tmp , \"2015_sqf_csv.csv\" )) unlink ( tmp ) sum ( is.na ( mydata )) nrow ( mydata ) * ncol ( mydata ) names ( mydata ) napercol <- list () for ( i in 1 : ncol ( mydata )) { napercol[[i]] <- sum ( is.na ( mydata[ , i] )) } mydata <- mydata[ , napercol == 0 ] lvllist <- list () for ( i in 1 : ncol ( mydata )) { lvllist[[i]] <- length ( levels ( mydata[ , i] )) } attach ( mydata ) height <- 12 * ht_feet + ht_inch mydata <- data.frame ( mydata , height ) mydata <- mydata[ , ( lvllist < 10 ) & ( lvllist != 1 ) ] mydata <- mydata[ , - c ( 1 , 2 , 3 , 4 , 15 , 16 , 18 , 78 , 79 , 83 , 84 ) ] mydata <- na.omit ( mydata ) mydata <- mydata[mydata $ age < 100 , ] train <- sample ( 1 : nrow ( mydata ), 3 * nrow ( mydata ) / 4 ) mydata.test <- mydata[ - train , ] arrest.test <- mydata $ arstmade[ - train] attach ( mydata ) # descriptive sum ( arstmade == \"Y\" ) / nrow ( mydata ) sum ( sex == \"M\" ) / nrow ( mydata ) sum ( forceuse != \" \" ) / nrow ( mydata ) sum ( race == \"B\" ) / nrow ( mydata ) sum ( sumissue == \"Y\" ) / nrow ( mydata ) sum ( arstmade == \"Y\" ) / sum ( sumissue == \"Y\" ) sum ( sb_other == \"Y\" ) / nrow ( mydata ) sum ( sb_other == \"Y\" ) / sum ( searched == \"Y\" ) sum ( pf_other == \"Y\" ) / nrow ( mydata ) mean ( mydata $ age ) black <- as.factor ( race == \"B\" ) white <- as.factor ( race == \"W\" ) nonwhite <- as.factor ( race != \"W\" ) summary ( mydata ) Installing package into 'C:/Users/ginge/Anaconda3/Lib/R/library' (as 'lib' is unspecified) package 'tree' successfully unpacked and MD5 sums checked The downloaded binary packages are in C:\\Users\\ginge\\AppData\\Local\\Temp\\RtmpMrc3nQ\\downloaded_packages Loading required package: ggplot2 Loading required package: tree Loading required package: class Loading required package: randomForest randomForest 4.6-12 Type rfNews() to see new features/changes/bug fixes. Attaching package: 'randomForest' The following object is masked from 'package:ggplot2': margin 173895 2527056 'year' 'pct' 'ser_num' 'datestop' 'timestop' 'recstat' 'inout' 'trhsloc' 'perobs' 'crimsusp' 'perstop' 'typeofid' 'explnstp' 'othpers' 'arstmade' 'arstoffn' 'sumissue' 'sumoffen' 'compyear' 'comppct' 'offunif' 'officrid' 'frisked' 'searched' 'contrabn' 'adtlrept' 'pistol' 'riflshot' 'asltweap' 'knifcuti' 'machgun' 'othrweap' 'pf_hands' 'pf_wall' 'pf_grnd' 'pf_drwep' 'pf_ptwep' 'pf_baton' 'pf_hcuff' 'pf_pepsp' 'pf_other' 'radio' 'ac_rept' 'ac_inves' 'rf_vcrim' 'rf_othsw' 'ac_proxm' 'rf_attir' 'cs_objcs' 'cs_descr' 'cs_casng' 'cs_lkout' 'rf_vcact' 'cs_cloth' 'cs_drgtr' 'ac_evasv' 'ac_assoc' 'cs_furtv' 'rf_rfcmp' 'ac_cgdir' 'rf_verbl' 'cs_vcrim' 'cs_bulge' 'cs_other' 'ac_incid' 'ac_time' 'rf_knowl' 'ac_stsnd' 'ac_other' 'sb_hdobj' 'sb_outln' 'sb_admis' 'sb_other' 'repcmd' 'revcmd' 'rf_furt' 'rf_bulg' 'offverb' 'offshld' 'forceuse' 'sex' 'race' 'dob' 'age' 'ht_feet' 'ht_inch' 'weight' 'haircolr' 'eyecolor' 'build' 'othfeatr' 'addrtyp' 'rescode' 'premtype' 'premname' 'addrnum' 'stname' 'stinter' 'crossst' 'aptnum' 'city' 'state' 'zip' 'addrpct' 'sector' 'beat' 'post' 'xcoord' 'ycoord' 'dettypCM' 'lineCM' 'detailCM' The following object is masked _by_ .GlobalEnv: height The following objects are masked from mydata (pos = 3): ac_assoc, ac_cgdir, ac_evasv, ac_incid, ac_inves, ac_other, ac_proxm, ac_rept, ac_stsnd, ac_time, age, arstmade, asltweap, build, city, contrabn, cs_bulge, cs_casng, cs_cloth, cs_descr, cs_drgtr, cs_furtv, cs_lkout, cs_objcs, cs_other, cs_vcrim, detailCM, explnstp, forceuse, frisked, inout, knifcuti, offshld, offunif, offverb, othpers, othrweap, perobs, pf_baton, pf_drwep, pf_grnd, pf_hands, pf_hcuff, pf_other, pf_pepsp, pf_ptwep, pf_wall, pistol, race, radio, recstat, repcmd, revcmd, rf_attir, rf_bulg, rf_furt, rf_knowl, rf_othsw, rf_rfcmp, rf_vcact, rf_vcrim, rf_verbl, riflshot, sb_admis, sb_hdobj, sb_other, sb_outln, searched, sex, sumissue, timestop, trhsloc, typeofid, weight 0.175984356946049 0.924317838414363 0.274686694516043 0.529419607146031 0.0261310105768376 6.73469387755102 0.107501555417296 0.577326968973747 0.026486534530264 27.6311883388143 timestop recstat inout trhsloc perobs typeofid Min. : 0 : 2845 I: 4211 H: 3357 Min. : 0.00 O: 432 1st Qu.: 507 1:14661 O:18291 P:18245 1st Qu.: 1.00 P:12960 Median :1623 9: 10 T: 900 Median : 1.00 R: 623 Mean :1377 A: 4986 Mean : 2.64 V: 8487 3rd Qu.:2052 3rd Qu.: 2.00 Max. :2359 Max. :535.00 explnstp othpers arstmade sumissue offunif frisked searched N: 28 N:15780 N:18542 N:21914 N: 9965 N: 7289 N:18312 Y:22474 Y: 6722 Y: 3960 Y: 588 Y:12537 Y:15213 Y: 4190 contrabn pistol riflshot asltweap knifcuti othrweap pf_hands N:21379 N:22337 N:22499 N:22501 N:21813 N:22228 N:18771 Y: 1123 Y: 165 Y: 3 Y: 1 Y: 689 Y: 274 Y: 3731 pf_wall pf_grnd pf_drwep pf_ptwep pf_baton pf_hcuff pf_pepsp N:21279 N:22191 N:22087 N:22234 N:22497 N:19111 N:22496 Y: 1223 Y: 311 Y: 415 Y: 268 Y: 5 Y: 3391 Y: 6 pf_other radio ac_rept ac_inves rf_vcrim rf_othsw ac_proxm N:21906 N:13142 N:15906 N:19561 N:17472 N:18858 N:14543 Y: 596 Y: 9360 Y: 6596 Y: 2941 Y: 5030 Y: 3644 Y: 7959 rf_attir cs_objcs cs_descr cs_casng cs_lkout rf_vcact cs_cloth N:20949 N:21580 N:14248 N:17837 N:20095 N:20834 N:21555 Y: 1553 Y: 922 Y: 8254 Y: 4665 Y: 2407 Y: 1668 Y: 947 cs_drgtr ac_evasv ac_assoc cs_furtv rf_rfcmp ac_cgdir rf_verbl N:21138 N:18194 N:20724 N:15766 N:19860 N:17541 N:22287 Y: 1364 Y: 4308 Y: 1778 Y: 6736 Y: 2642 Y: 4961 Y: 215 cs_vcrim cs_bulge cs_other ac_incid ac_time rf_knowl ac_stsnd N:20590 N:20804 N:14637 N:12148 N:15037 N:21242 N:21837 Y: 1912 Y: 1698 Y: 7865 Y:10354 Y: 7465 Y: 1260 Y: 665 ac_other sb_hdobj sb_outln sb_admis sb_other repcmd N:19947 N:21063 N:22204 N:22229 N:20083 Min. : 1 Y: 2555 Y: 1439 Y: 298 Y: 273 Y: 2419 1st Qu.: 66 Median :106 Mean :229 3rd Qu.:186 Max. :878 revcmd rf_furt rf_bulg offverb offshld forceuse sex Min. : 1.0 N:15913 N:20577 :15175 :12749 :16321 F: 1509 1st Qu.: 66.0 Y: 6589 Y: 1925 V: 7327 S: 9753 DO: 98 M:20799 Median :106.0 DS: 2145 Z: 194 Mean :229.4 OR: 284 3rd Qu.:186.0 OT: 1687 Max. :878.0 SF: 1461 SW: 506 race age weight build city B :11913 Min. : 0.00 Min. : 1.0 H: 2159 BRONX :4740 Q : 5082 1st Qu.:19.00 1st Qu.:150.0 M:10958 BROOKLYN :6334 W : 2505 Median :24.00 Median :170.0 T: 8861 MANHATTAN:3923 P : 1407 Mean :27.63 Mean :171.3 U: 191 QUEENS :5710 A : 1100 3rd Qu.:33.00 3rd Qu.:185.0 Z: 333 STATEN IS:1795 Z : 298 Max. :99.00 Max. :999.0 (Other): 197 detailCM height Min. : 6.00 Min. :36.00 1st Qu.: 20.00 1st Qu.:67.00 Median : 27.00 Median :69.00 Mean : 37.79 Mean :68.83 3rd Qu.: 46.00 3rd Qu.:71.00 Max. :113.00 Max. :95.00 Data The data comes from the City of New York. It is a collection of 22,564 observations of 112 variables. Some of these variables had to be removed, as they did not contribute any information (for instance, they were the same value for all observations) or they had too many missing values. After removing these variables from the dataset, I had 75 variables to work with, with 22,563 observations. For example, lineCM was a redundant variable, as it had 1's for all observations. I also removed apt number, state and zip, as many of these values were left blank. Overall, none of the variables I was very interested in had any missing values, so removing these variables likely had very little effect on the analysis, if any. There were two variables for height (ht_inch and ht_feet) which I combined into one (height). The response variable I used for all of the following analyses was arstmade, which was a categorical variable that had values of \"Y\" for yes and \"N\" for no. Many of the categorical variables in the dataset followed this pattern. The percentage of arrests in all cases was 0.18, meaning that around 18% of the stops resulted in an arrest. The mean age of people who were stopped and frisked was around 29 years. Most of the people who were stopped were males (92.42%). Force was used in about 27% of the cases. In investigating whether blacks were targeted more frequently and if they were arrested more frequently, I created a categorical variable that was 1 if the person was black and 0 otherwise. Below is a bar graph of the arrests, with the colorings indicating the percentage who were black and non-black. It does not seem from these graphs alone that blacks were more likely to be arrested, since they have roughly half of the bars in both instances. However, it does seem like there are a disproportionate number of blacks who are stopped and frisked in the first place, which is shown in the second graph. With blacks making up roughly 23% of the population, it is surprising that almost double that (53%) of the people who were stopped were black In [4]: ggplot ( mydata , aes ( arstmade )) + geom_bar ( aes ( fill = black )) + ggtitle ( \"Bar Graph of Arrests for Blacks vs. Non-Blacks\" ) + xlab ( \"Was the person arrested?\" ) + ylab ( \"Numer of Incidences\" ) + scale_fill_discrete ( name = \"Race\" , labels = c ( \"Non-Blacks\" , \"Blacks\" )) In [5]: ggplot ( mydata , aes ( black )) + geom_bar ( fill = \"red\" ) + ggtitle ( \"Blacks vs. Non-Blacks Who Were Stopped and Frisked\" ) + xlab ( \"Was the person black?\" ) + ylab ( \"Number of Incidents\" ) Some more interesting things found in the descriptive statistics: Around 6.7 times more people were arrested than given summonses. That is, only 2% of the people were given summonses. None of the people who were stopped had a machine gun, so I removed this variable from the data. I removed any variable which had levels that were exactly one, as this indicated that there was no variation between observations. Although the suspected crime variable (crimsusp) was of interest to me in my analysis, I found the data to be inconsistent in how it was recorded. For instance, if it was a felony, the officer had data entered that had both \"FEL\" and \"FELONY\" in two different cases. Of course, R would not be able to recognize the fact that these are the same, and would treat them as separate variables. As such, I decided to remove any variables which had levels larger than 10, as this would indicate that the data was too separated to be meaningful. Since much of this information is contained in the categorical variables (such as the rs variables, which had different values for different reasons for stopping the person), it was relatively inconsequential in my analysis to do so. There were also groupings which could raise doubt as to whether the information recorded was accurate. Of primary concern to me was pf_other (physical force used: other), rs_other (reason for search: other) and ac_other (additional circumstances: other). These are not very informative, and could be raise a speculative point about whether these were truly extraordinary cases or if they were omitted for other reasons. Of course, that is merely speculation, but it is important to note that this is a source of potential inconsistency and unreliability from the dataset. Even worse, some of these variables contributed a lot to the models which I have fit. Below shows a bar graph of the number of arrests conditional on whether the reason for search was classified as \"other.\" In [6]: ggplot ( mydata , aes ( sb_other )) + geom_bar ( aes ( fill = arstmade )) + ggtitle ( \"Arrests Conditional on if Reason for Search classified as OTHER\" ) + xlab ( \"Was the reason for search classifed as other?\" ) + ylab ( \"Number of Incidents\" ) + scale_fill_discrete ( name = \"Arrest Status\" , labels = ( c ( \"Not Arrested\" , \"Arrested\" ))) This confirms the results of the analysis below, as this variable has a large effect on whether the person was arrested or not. If the person was classified as being searched for other reasons not specified, they were arrested quite often. This leads to a limitation of the data and interpretation - we can not determine what the true reasons were. sb_other accounted for around 10.7% of all the cases, and 57.6% of all the people who were searched. Analysis and Model Fitting Logistic Regression I separated the data into two sets - test data and training data. The training data was randomly sampled from ¾ of the data. I began my analysis by using a logistic regression model to predict arstmade on all of the other variables. This was because the response variable was categorical, so it was necessary to use a logistic model instead of a linear model with normal errors. I then used stepwise reduction to determine the best fit and to reduce the amount of variables used. Since there were a great deal of variables that came up insignificant in the full model, it reduced the model quite a lot. I used the glm function using the binomial family to model the data. Below is a summary of the results of the models: In [7]: logistfullmodel <- glm ( arstmade ~ ., data = mydata[train , ] , family = binomial ) summary ( logistfullmodel ) # step(logistfullmodel) stepwiselogmodel <- glm ( formula = arstmade ~ recstat + inout + trhsloc + perobs + typeofid + sumissue + offunif + frisked + searched + contrabn + pistol + knifcuti + othrweap + pf_hands + pf_wall + pf_grnd + pf_drwep + pf_hcuff + pf_pepsp + pf_other + radio + ac_rept + rf_vcrim + rf_othsw + ac_proxm + rf_attir + cs_objcs + cs_casng + cs_lkout + cs_cloth + cs_drgtr + ac_evasv + ac_assoc + rf_rfcmp + rf_verbl + cs_vcrim + cs_bulge + cs_other + rf_knowl + ac_other + sb_hdobj + sb_other + revcmd + rf_furt + rf_bulg + forceuse + sex + race + age + weight + city + detailCM , family = binomial , data = mydata[train , ] ) summary ( stepwiselogmodel ) Call: glm(formula = arstmade ~ ., family = binomial, data = mydata[train, ]) Deviance Residuals: Min 1Q Median 3Q Max -3.7188 -0.3688 -0.2544 -0.1509 3.8891 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -3.603e-01 1.098e+00 -0.328 0.742736 timestop -5.247e-05 3.830e-05 -1.370 0.170732 recstat1 3.513e-01 1.029e-01 3.414 0.000640 *** recstat9 -1.984e+00 2.315e+00 -0.857 0.391350 recstatA -1.814e-01 1.186e-01 -1.530 0.126081 inoutO -8.448e-01 8.111e-02 -10.415 < 2e-16 *** trhslocP -8.829e-01 1.264e-01 -6.987 2.81e-12 *** trhslocT -1.433e+00 1.497e-01 -9.576 < 2e-16 *** perobs 8.119e-03 3.385e-03 2.398 0.016477 * typeofidP 4.639e-02 2.062e-01 0.225 0.822032 typeofidR -1.221e+00 3.381e-01 -3.612 0.000303 *** typeofidV -1.538e-01 2.087e-01 -0.737 0.461056 explnstpY -5.317e-01 7.951e-01 -0.669 0.503720 othpersY 8.174e-02 7.156e-02 1.142 0.253323 sumissueY -2.921e+00 2.354e-01 -12.411 < 2e-16 *** offunifY -2.842e-01 3.264e-01 -0.871 0.383957 friskedY 1.868e-01 1.029e-01 1.816 0.069326 . searchedY 1.743e+00 2.208e-01 7.893 2.95e-15 *** contrabnY 3.129e+00 1.397e-01 22.406 < 2e-16 *** pistolY 2.889e+00 3.064e-01 9.428 < 2e-16 *** riflshotY -9.084e+00 1.970e+02 -0.046 0.963216 asltweapY 9.640e+00 1.970e+02 0.049 0.960966 knifcutiY 2.090e+00 1.459e-01 14.327 < 2e-16 *** othrweapY 1.924e+00 2.089e-01 9.209 < 2e-16 *** pf_handsY 1.730e-01 9.642e-02 1.794 0.072817 . pf_wallY -2.660e-01 1.438e-01 -1.850 0.064294 . pf_grndY 7.378e-01 2.149e-01 3.433 0.000597 *** pf_drwepY -6.845e-01 2.622e-01 -2.610 0.009050 ** pf_ptwepY -1.893e-01 2.868e-01 -0.660 0.509344 pf_batonY 2.162e+00 1.520e+00 1.422 0.155040 pf_hcuffY 1.308e+00 9.645e-02 13.564 < 2e-16 *** pf_pepspY 3.710e+00 1.173e+00 3.162 0.001568 ** pf_otherY -2.753e-01 1.954e-01 -1.409 0.158894 radioY -4.752e-01 6.943e-02 -6.844 7.70e-12 *** ac_reptY 2.874e-01 7.863e-02 3.655 0.000257 *** ac_invesY 5.950e-02 9.443e-02 0.630 0.528644 rf_vcrimY -2.614e-01 9.061e-02 -2.885 0.003912 ** rf_othswY -2.411e-01 9.555e-02 -2.523 0.011633 * ac_proxmY 1.581e-01 6.608e-02 2.393 0.016729 * rf_attirY -3.667e-01 1.361e-01 -2.695 0.007042 ** cs_objcsY 5.588e-01 1.324e-01 4.219 2.45e-05 *** cs_descrY 1.136e-01 8.865e-02 1.281 0.200124 cs_casngY -1.454e-01 9.321e-02 -1.560 0.118861 cs_lkoutY -4.338e-01 1.205e-01 -3.599 0.000319 *** rf_vcactY -8.072e-02 1.335e-01 -0.605 0.545450 cs_clothY -3.673e-01 1.809e-01 -2.031 0.042294 * cs_drgtrY 3.498e-01 1.206e-01 2.901 0.003719 ** ac_evasvY 2.235e-01 8.377e-02 2.668 0.007640 ** ac_assocY -5.466e-01 1.345e-01 -4.063 4.84e-05 *** cs_furtvY -2.918e-02 8.263e-02 -0.353 0.723996 rf_rfcmpY -2.335e-01 1.029e-01 -2.270 0.023184 * ac_cgdirY 1.199e-01 8.096e-02 1.481 0.138624 rf_verblY -3.992e-01 2.927e-01 -1.364 0.172692 cs_vcrimY -3.357e-01 1.384e-01 -2.426 0.015256 * cs_bulgeY -4.862e-01 1.482e-01 -3.281 0.001033 ** cs_otherY -1.467e-01 7.321e-02 -2.004 0.045122 * ac_incidY 4.553e-02 7.148e-02 0.637 0.524196 ac_timeY -4.144e-02 7.612e-02 -0.544 0.586213 rf_knowlY -4.205e-01 1.562e-01 -2.692 0.007095 ** ac_stsndY -2.085e-01 1.926e-01 -1.083 0.278930 ac_otherY -3.115e-01 9.911e-02 -3.143 0.001673 ** sb_hdobjY -6.270e-01 2.079e-01 -3.016 0.002558 ** sb_outlnY 2.030e-01 2.446e-01 0.830 0.406604 sb_admisY 1.097e-01 2.662e-01 0.412 0.680126 sb_otherY 1.280e+00 2.151e-01 5.951 2.66e-09 *** repcmd -3.224e-04 6.206e-04 -0.520 0.603369 revcmd 8.321e-04 6.175e-04 1.348 0.177806 rf_furtY -1.473e-01 9.015e-02 -1.634 0.102289 rf_bulgY -3.050e-01 1.374e-01 -2.220 0.026416 * offverbV -2.356e-02 1.051e-01 -0.224 0.822675 offshldS -3.050e-02 3.115e-01 -0.098 0.922004 forceuseDO -7.150e-01 4.305e-01 -1.661 0.096764 . forceuseDS -6.897e-01 1.305e-01 -5.286 1.25e-07 *** forceuseOR -8.379e-02 2.432e-01 -0.345 0.730402 forceuseOT 3.347e-01 1.257e-01 2.664 0.007725 ** forceuseSF -5.223e-02 1.308e-01 -0.399 0.689594 forceuseSW -5.030e-01 2.170e-01 -2.318 0.020476 * sexM -2.052e-01 1.171e-01 -1.752 0.079809 . sexZ -7.004e-01 4.190e-01 -1.671 0.094626 . raceB 3.875e-02 1.589e-01 0.244 0.807283 raceI 8.685e-02 5.556e-01 0.156 0.875776 raceP 2.571e-01 1.889e-01 1.361 0.173603 raceQ 3.531e-01 1.623e-01 2.176 0.029566 * raceU 2.086e-01 4.130e-01 0.505 0.613431 raceW 1.073e-01 1.809e-01 0.593 0.552966 raceZ 5.422e-01 3.251e-01 1.668 0.095401 . age 8.302e-03 2.664e-03 3.117 0.001830 ** weight -1.064e-03 1.022e-03 -1.041 0.297954 buildM -4.270e-02 1.113e-01 -0.384 0.701347 buildT -1.117e-02 1.210e-01 -0.092 0.926426 buildU -1.004e-01 3.264e-01 -0.308 0.758299 buildZ -7.310e-01 2.973e-01 -2.459 0.013934 * cityBROOKLYN -8.185e-01 8.534e-02 -9.592 < 2e-16 *** cityMANHATTAN -6.850e-01 9.098e-02 -7.529 5.10e-14 *** cityQUEENS -5.335e-01 9.414e-02 -5.667 1.45e-08 *** citySTATEN IS -1.102e+00 1.562e-01 -7.053 1.75e-12 *** detailCM 8.680e-03 1.159e-03 7.492 6.78e-14 *** height -2.539e-03 1.019e-02 -0.249 0.803203 --- Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 15712.6 on 16875 degrees of freedom Residual deviance: 8277.2 on 16778 degrees of freedom AIC: 8473.2 Number of Fisher Scoring iterations: 10 Call: glm(formula = arstmade ~ recstat + inout + trhsloc + perobs + typeofid + sumissue + offunif + frisked + searched + contrabn + pistol + knifcuti + othrweap + pf_hands + pf_wall + pf_grnd + pf_drwep + pf_hcuff + pf_pepsp + pf_other + radio + ac_rept + rf_vcrim + rf_othsw + ac_proxm + rf_attir + cs_objcs + cs_casng + cs_lkout + cs_cloth + cs_drgtr + ac_evasv + ac_assoc + rf_rfcmp + rf_verbl + cs_vcrim + cs_bulge + cs_other + rf_knowl + ac_other + sb_hdobj + sb_other + revcmd + rf_furt + rf_bulg + forceuse + sex + race + age + weight + city + detailCM, family = binomial, data = mydata[train, ]) Deviance Residuals: Min 1Q Median 3Q Max -3.7416 -0.3693 -0.2555 -0.1531 3.8643 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -1.1394455 0.3563078 -3.198 0.001384 ** recstat1 0.3575529 0.1023959 3.492 0.000480 *** recstat9 -2.0037225 2.3393201 -0.857 0.391699 recstatA -0.1811463 0.1180715 -1.534 0.124978 inoutO -0.8198646 0.0803864 -10.199 < 2e-16 *** trhslocP -0.8738981 0.1249270 -6.995 2.65e-12 *** trhslocT -1.4117556 0.1472958 -9.584 < 2e-16 *** perobs 0.0085851 0.0033665 2.550 0.010767 * typeofidP 0.0553679 0.2048434 0.270 0.786934 typeofidR -1.2301359 0.3365018 -3.656 0.000257 *** typeofidV -0.1420737 0.2072662 -0.685 0.493051 sumissueY -2.9274054 0.2337174 -12.525 < 2e-16 *** offunifY -0.2300162 0.0709762 -3.241 0.001192 ** friskedY 0.1596321 0.0999233 1.598 0.110144 searchedY 1.8727029 0.1564972 11.966 < 2e-16 *** contrabnY 3.1108031 0.1387840 22.415 < 2e-16 *** pistolY 2.9397144 0.3037615 9.678 < 2e-16 *** knifcutiY 2.0781429 0.1408105 14.758 < 2e-16 *** othrweapY 1.9085458 0.2061663 9.257 < 2e-16 *** pf_handsY 0.1829775 0.0958719 1.909 0.056318 . pf_wallY -0.2684473 0.1426597 -1.882 0.059872 . pf_grndY 0.7069531 0.2111336 3.348 0.000813 *** pf_drwepY -0.7202203 0.2427153 -2.967 0.003004 ** pf_hcuffY 1.3038209 0.0958149 13.608 < 2e-16 *** pf_pepspY 3.6381377 1.1662366 3.120 0.001811 ** pf_otherY -0.2736084 0.1936878 -1.413 0.157766 radioY -0.4540335 0.0686508 -6.614 3.75e-11 *** ac_reptY 0.3203196 0.0716227 4.472 7.74e-06 *** rf_vcrimY -0.2302783 0.0885105 -2.602 0.009276 ** rf_othswY -0.2195720 0.0938505 -2.340 0.019305 * ac_proxmY 0.1764237 0.0639188 2.760 0.005778 ** rf_attirY -0.3508092 0.1347952 -2.603 0.009254 ** cs_objcsY 0.5277556 0.1306460 4.040 5.35e-05 *** cs_casngY -0.1567943 0.0897938 -1.746 0.080783 . cs_lkoutY -0.4306545 0.1190220 -3.618 0.000297 *** cs_clothY -0.3454175 0.1787932 -1.932 0.053367 . cs_drgtrY 0.3362326 0.1183804 2.840 0.004507 ** ac_evasvY 0.2346666 0.0809086 2.900 0.003727 ** ac_assocY -0.5555065 0.1340808 -4.143 3.43e-05 *** rf_rfcmpY -0.2040480 0.1014848 -2.011 0.044365 * rf_verblY -0.4083410 0.2922657 -1.397 0.162366 cs_vcrimY -0.3965895 0.1264841 -3.135 0.001716 ** cs_bulgeY -0.4881904 0.1440797 -3.388 0.000703 *** cs_otherY -0.1770344 0.0673632 -2.628 0.008587 ** rf_knowlY -0.4071034 0.1555024 -2.618 0.008845 ** ac_otherY -0.3129862 0.0982278 -3.186 0.001441 ** sb_hdobjY -0.7305307 0.1589738 -4.595 4.32e-06 *** sb_otherY 1.1601221 0.1583057 7.328 2.33e-13 *** revcmd 0.0004988 0.0001588 3.142 0.001681 ** rf_furtY -0.1420974 0.0805927 -1.763 0.077874 . rf_bulgY -0.2908946 0.1356321 -2.145 0.031974 * forceuseDO -0.7594367 0.4329658 -1.754 0.079425 . forceuseDS -0.6950447 0.1298365 -5.353 8.64e-08 *** forceuseOR -0.0864302 0.2400623 -0.360 0.718823 forceuseOT 0.3274358 0.1251247 2.617 0.008874 ** forceuseSF -0.0552919 0.1300915 -0.425 0.670820 forceuseSW -0.4997659 0.2145224 -2.330 0.019824 * sexM -0.2124173 0.1120586 -1.896 0.058014 . sexZ -0.6879402 0.4163837 -1.652 0.098498 . raceB 0.0408446 0.1577469 0.259 0.795693 raceI 0.0878653 0.5519119 0.159 0.873510 raceP 0.2519675 0.1881200 1.339 0.180441 raceQ 0.3582209 0.1613654 2.220 0.026423 * raceU 0.2148683 0.4095903 0.525 0.599866 raceW 0.1083503 0.1798309 0.603 0.546833 raceZ 0.5206662 0.3238037 1.608 0.107842 age 0.0073152 0.0026085 2.804 0.005042 ** weight -0.0012546 0.0008145 -1.540 0.123469 cityBROOKLYN -0.8072589 0.0847163 -9.529 < 2e-16 *** cityMANHATTAN -0.6764624 0.0904685 -7.477 7.58e-14 *** cityQUEENS -0.5136538 0.0932366 -5.509 3.61e-08 *** citySTATEN IS -1.0791310 0.1548114 -6.971 3.16e-12 *** detailCM 0.0090240 0.0011467 7.870 3.56e-15 *** --- Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 15712.6 on 16875 degrees of freedom Residual deviance: 8297.6 on 16803 degrees of freedom AIC: 8443.6 Number of Fisher Scoring iterations: 6 In [8]: plot ( stepwiselogmodel ) In [9]: fit1 <- predict ( stepwiselogmodel , newdata = mydata.test , type = \"response\" ) fit1 <- ifelse ( fit1 > 0.5 , 1 , 0 ) sum ( fit1 ) / nrow ( mydata.test ) table1 <- table ( fit1 , arrest.test ) misclasserrorstepwise <- 1 - sum ( diag ( table1 )) / nrow ( mydata.test ) round ( misclasserrorstepwise , 3 ) fitted3 <- ifelse ( fit1 > 0.17 , 1 , 0 ) sum ( fitted3 ) / nrow ( mydata.test ) fit2 <- predict ( logistfullmodel , newdata = mydata.test , type = \"response\" ) fitted2 <- ifelse ( fit2 > 0.5 , 1 , 0 ) sum ( fitted2 ) / nrow ( mydata.test ) table2 <- table ( fitted2 , arrest.test ) misclasserrorsfull <- 1 - sum ( diag ( table2 )) / nrow ( mydata.test ) round ( misclasserrorsfull , 3 ) 0.127266263775329 0.093 0.127266263775329 0.127444009953786 0.095 In [11]: table1 arrest.test fit1 N Y 0 4513 397 1 126 590 In [12]: misclasserrorsfull table2 misclasserrorstepwise 0.0945609669392108 arrest.test fitted2 N Y 0 4508 401 1 131 586 0.0929612513330963 Using the stepwise regression model determined by the AIC produced a marginally better misclassification error, from .095 to .093 (or 9.5 % to 9.3%). This isn't a very big improvement, though. Surprisingly, the model does not find any of the race factors to be significant in determining whether an arrest was made or not besides Q, which stands for the White-Hispanics. That is, all of the levels of the \"race\" variable other than \"White-Hispanic\" came up insignificant. All of these coefficients are positive besides \"U\", which stood for \"unknown\", which essentially means that if the person's race was known, the odds of arrest are higher. The full summary of the stepwise regression is included in the appendix(1). When the stepwise regression was performed, we could see that contraband and knife/cutting instrument variables were highly significant in determining whether a person would get arrested or not. These variables are both very significant in the reduced logistic model. The variables that represent the different boroughs were all found to be significant, all with negative values. This suggests that the variable that was not included in the factors (the Bronx) had a higher likelihood of being arrested than any of the other four boroughs. Since the largest coefficient is that of Staten Island it means that, all else equal, a person from Staten Island who was stopped and frisked was less likely to be arrested than a person from Manhattan. The model also indicates that people who had a weapon were more likely to be arrested during a stop and frisk. This is logical, as if the police had found a weapon, it is quite likely that the person would be arrested. If the officer was in uniform, interestingly, a person would be less likely to be arrested, according to the model. If the police officer stopped the person because they knew them (indicated by rf_knowlY), the person was less likely to be arrested. If the reason the officer used force was to defend themselves, the person was less likely to be arrested than if the reason for force was that the person was suspected of running away. If the person is searched, they had a higher chance of being arrested than if they were not searched. KNN The next model I used was the K-Nearest Neighbors approach. K-Nearest Neighbors is a non-parametric method, so it does not make assumptions about the underlying distribution of the variables. K-Nearest Neighbors works by finding the nearest data points to the ones you are testing them against and assigning a classification based on the nearest k points. I have used k=5 and k=10 in this model to see if they can accurately predict the chances of arrest. Below are the tables for predicted vs actual arrest values for the test set, as well as the misclassification error, for the 10-nearest neighbor method (as this was the most successful.) In [14]: train1 <- model.matrix ( arstmade ~ ., data = mydata[train , ] ) test1 <- model.matrix ( arstmade ~ ., data = mydata.test ) knn.predict <- knn ( train1 , test1 , arstmade[train] , k = 10 ) table3 <- table ( knn.predict , arrest.test ) KNNMisclass <- 1 - sum ( diag ( table3 )) / nrow ( mydata.test ) round ( KNNMisclass , 3 ) train2 <- model.matrix ( arstmade ~ ., data = mydata[train , ] ) [ , 7 : 60 ] test2 <- model.matrix ( arstmade ~ ., data = mydata.test ) [ , 7 : 60 ] knn.predict2 <- knn ( train2 , test2 , arstmade[train] , k = 5 ) table4 <- table ( knn.predict2 , arrest.test ) KNNMisclass2 <- 1 - sum ( diag ( table4 )) / nrow ( mydata.test ) round ( KNNMisclass2 , 3 ) 0.162 0.12 In [15]: table3 round ( KNNMisclass , 3 ) arrest.test knn.predict N Y N 4479 749 Y 160 238 0.162 The 10-Nearest Neighbor model was the most successful of the different k's I used (I tried 1, 5, 10, and 20). Still, it doesn't produce very good outcomes compared to the logistic model. In fact, if I were to guess that none of the people would get arrested, I would have an error of about 18%, so this model is only marginally better than the trivial method. The failure of this method is due to the fact that the variables cannot exactly be scaled, and the distances are affected by this. As there are many categorical variables and few continuous ones, high numbers of the continuous variables may have influenced the predictions, since the KNN function in R uses Euclidian distances to predict the outcomes. To rectify this, I perform the K-NN method using only the categorical variables. The predictions are slightly better in this model, as shown by the confusion matrix and misclassification rate below. In [16]: table4 round ( KNNMisclass2 , 3 ) arrest.test knn.predict2 N Y N 4547 582 Y 92 405 0.12 Interestingly, while the error is still larger than the logistic models, or in fact any of the models I used in the analysis, it is more accurate at predicting an arrest when an arrest was made than any of the earlier models, suggested by the second row of the confusion matrix above. That is, while it produces more overall error than any of the models I've used, it also produces the smallest type I error out of any of the models (the false positives). Tree-Based Methods I will now use tree-based methods (a single tree, Random Forest, Bagging and Boosting) in order to predict whether a person will be arrested or not. The first model I use will be an unpruned tree using all the variables. The tree selects groupings of the variables which produces the least errors in predictions, and lists decision trees based on the conditional results of each tree. It determines these factors by a popular vote in the case of classification trees, so that the most common outcome is the one which is predicted by the tree. The tree is posted below. In [17]: tree.arrest <- tree ( arstmade ~ ., mydata[train , ] ) In [18]: plot ( tree.arrest , main = \"Unpruned Tree\" ) text ( tree.arrest , cex = 0.9 ) This tree has six nodes, so it is relatively simple. If the statement is true, you go to the right, and if it is false you go to the left. The top node is whether the person was searched or not. This makes sense, as if a person is searched, the police are more likely to find a reason to arrest the person (because of illegal goods, etc). It is already evident that this tree can be pruned. For the trhsloc and pf_hcuff variables, either decision results in the same response. This means that the variable is redundant, and can be removed from the tree. The values that are included are: searched, repcmd (reporting officers command, which takes values from 1 to 999), contrabn (contraband), sb_hdobj (basis of search being a hard object), trhsloc P,T (whether the location was a transit location or housing location), and pf_hcuff(force used was handcuffing). Some of these are quite interesting: the fact that the officers command has an influence on whether the person was arrested or not, and also the fact that regardless of whether the person was handcuffed or not, they were not reported as arrested if they reach the bottom left node. This defies our common sense - as we often expect someone who is handcuffed to be arrested. Based on the prior conditional factors, the tree says that if someone is handcuffed given they don't have contraband, they weren't searched, and the reporting officers command was less than 805, they would be classified as not being arrested. Since we already have seen that we should prune this tree, I will find the correct number of nodes to prune to by plotting the cross-validation errors. In [19]: cv.arrest <- cv.tree ( tree.arrest , FUN = prune.misclass ) In [20]: plot ( cv.arrest $ size , cv.arrest $ dev , type = \"b\" , xlab = \"Number of Nodes\" , ylab = \"Deviance\" , main = \"Determining Best Reduction of Trees by Deviance\" ) points ( 3 , cv.arrest $ dev[3] , col = \"red\" ) There is a clear leveling off at 3, marked with a red point, so we will prune the next tree to three nodes. In [21]: prune.arrest <- prune.misclass ( tree.arrest , best = 3 ) In [22]: plot ( prune.arrest ) text ( prune.arrest ) This tree is extremely small, and only considers two variables - whether a person was searched and whether the reason for the search was that they had a hard object. Below, I post the tables for the pruned and unpruned trees, along with their misclassification errors. In [23]: tree.pred <- predict ( tree.arrest , newdata = mydata.test , type = \"class\" ) table5 <- table ( tree.pred , arrest.test ) misclassificationunprune <- 1 - sum ( diag ( table5 )) / nrow ( mydata.test ) pruned.pred <- predict ( prune.arrest , newdata = mydata.test , type = \"class\" ) table6 <- table ( pruned.pred , arrest.test ) misclassificationprune <- 1 - sum ( diag ( table6 )) / nrow ( mydata.test ) In [24]: table5 round ( misclassificationunprune , 3 ) table6 round ( misclassificationprune , 3 ) arrest.test tree.pred N Y N 4426 447 Y 213 540 0.117 arrest.test pruned.pred N Y N 4466 486 Y 173 501 0.117 The misclassification errors are quite high for the single trees, which is expected since one tree will rarely be sufficient in predicting the outcome. They perform roughly the same on the data, which indicates that the pruning was effective - we were able to reduce the nodes without significantly effecting the accuracy of the models. It is notable that the pruned tree reduced Type I error, which is more desirable in this case. Still, both trees performed better on the overall error than the KNN approach. Next, I will use the bagging method. The bagging method, or bootstrap aggregation, uses bootstrap samples repeatedly to create many trees, and then averages these trees to make predictions. In the case of a classification problem such as this one, bagging will predict by the majority vote. Performing bagging with 300 trees reports the following confusion matrix and misclassification error: In [25]: bag.arrest <- randomForest ( arstmade ~ ., data = mydata[train , ] , mtry = ( ncol ( mydata ) - 1 ), importance = TRUE , ntree = 300 ) bag.pred <- predict ( bag.arrest , newdata = mydata.test , type = \"class\" ) table7 <- table ( bag.pred , arrest.test ) misclassificationbagging <- 1 - sum ( diag ( table7 )) / nrow ( mydata.test ) In [26]: table7 round ( misclassificationbagging , 3 ) arrest.test bag.pred N Y N 4505 285 Y 134 702 0.074 This is a large improvement over any of the previous methods we have used. In order to make the results more easily interpretable and prevent overfitting, I will reduce the number of trees used. Looking at the plot below can help us determine the correct number of trees to use : In [27]: plot ( bag.arrest , main = \"Trees vs Errors\" ) This plot determines the errors produced by each amount of trees. Using this, we can see visually where the line appears to stabilize and use this information to minimize the loss in accuracy from removing the trees. The green line shows the errors for the affirmative case (which is more likely), the red line for the negative case, and the black line for the overall error (the same as the misclassification error above). The plot appears to level off at around n=25. When I recreated the model using only 25 trees, I found the misclassification error to be 0.076. The error and confusion matrix will be included in the appendix. Although this is slightly higher than the model using 300 trees, it it a very small reduction in accuracy for a rather large increase in the interpretability and utility of the model. Now that we have determined a good amount of trees, we can look at an importance plot to see which variables create the most variations in the errors. Since this is a categorical variable, it will be most useful to use the right graph, which uses the Gini index. In [28]: bag.arrest2 <- randomForest ( arstmade ~ ., data = mydata[train , ] , mtry = ( ncol ( mydata ) - 1 ), importance = TRUE , ntree = 25 ) bag.pred2 <- predict ( bag.arrest2 , newdata = mydata.test , type = \"class\" ) table8 <- table ( bag.pred2 , arrest.test ) misclassificationbagging2 <- 1 - sum ( diag ( table8 )) / nrow ( mydata.test ) varImpPlot ( bag.arrest2 ) The variable with the most importance is sb_other, which is reason for search:other. This is a troubling thing, as described in the data section, because this is not a very informative variable. We can see that race now does have some importance in determining the arrests, as well as some other variables that were ommited from the logistic regression model. Interestingly, age, weight and height are included quite highly as well. Once again, whether the person was searched, had contraband, or was handcuffed is determined as important, which is consistent with our findings from the logistic regression. By using a sample of the variables in each tree and performing the bagging method on a different subset for each iteration, we can implement a Random Forest method. This method is useful since it allows some variation in the trees, since they will not only be dominated by the most important variables. Using two numbers for the number of variables used, I produced two random forest models. Below are their confusion matrices and misclassification errors. In [29]: table7 misclassificationbagging table8 misclassificationbagging2 arrest.test bag.pred N Y N 4505 285 Y 134 702 0.0744756487735514 arrest.test bag.pred2 N Y N 4490 277 Y 149 710 0.0757198720227515 The misclassification errors for the two are nearly identical. They perform very similarly to the bagging method. I would prefer the second model, as it predicts better in the case that the prediction and observed value are both yes than they are both no. By using a similar method to the bagging method earlier, we determine a good reduction in the amount of trees is to 40. Using 40 trees, we get the following confusion matrix and misclassification error. In [30]: RF.arrest <- randomForest ( arstmade ~ ., data = mydata[train , ] , mtry = 9 , importance = TRUE , ntree = 300 ) RF.pred <- predict ( RF.arrest , newdata = mydata.test , type = \"class\" ) table9 <- table ( RF.pred , arrest.test ) misclassRF <- 1 - sum ( diag ( table9 )) / nrow ( mydata.test ) varImpPlot ( RF.arrest , main = \"Imporance of Variables\" ) RF2.arrest <- randomForest ( arstmade ~ ., data = mydata[train , ] , mtry = ( ncol ( mydata ) - 1 ) / 2 , importance = TRUE , ntree = 300 ) RF2.pred <- predict ( RF2.arrest , newdata = mydata.test , type = \"class\" ) table10 <- table ( RF2.pred , arrest.test ) misclassRF2 <- 1 - sum ( diag ( table10 )) / nrow ( mydata.test ) varImpPlot ( RF2.arrest ) plot ( RF2.arrest ) RF3.arrest <- randomForest ( arstmade ~ ., data = mydata[train , ] , mtry = ( ncol ( mydata ) - 1 ) / 2 , importance = TRUE , ntree = 40 ) RF3.pred <- predict ( RF3.arrest , newdata = mydata.test , type = \"class\" ) table11 <- table ( RF3.pred , arrest.test ) misclassRF3 <- 1 - sum ( diag ( table11 )) / nrow ( mydata.test ) In [31]: table11 misclassRF3 arrest.test RF3.pred N Y N 4515 293 Y 124 694 0.0741201564166371 In this case, the error actually was reduced. This can be accounted for by the fact that it simplified the model, which resulted in the random forest model with 40 trees actually predicting better than the more complex model. This suggests that the increase in bias by using a simpler model with 40 trees was less than the decrease in variance of the model on the testing data. This model performs the best of all the models I have used, and is the most successful at predicting whether a person is arrested or not when they are stopped and frisked, with about a 7.2% misclassification rate. Conclusions Below is a table summarizing all of the models that I've used, and their misclassifcation errors on the test data. In [32]: Method <- c ( \"Full Logistic Model\" , \"Reduced Logistic Model\" , \"10-NN Full Model\" , \"5-NN Reduced Model\" , \"Pruned Tree\" , \"Unpruned Tree\" , \"Bagging (n=300)\" , \"Bagging (n=25)\" , \"Random Forest I (n=300)\" , \"Random Forest II (n=300)\" , \"Random Forest III (n=40)\" ) TestError <- c ( misclasserrorsfull , misclasserrorstepwise , KNNMisclass , KNNMisclass2 , misclassificationprune , misclassificationunprune , misclassificationbagging , misclassificationbagging2 , misclassRF , misclassRF2 , misclassRF3 ) TestError <- round ( TestError , 3 ) data.frame ( Method , TestError ) # error: Yes when No Er1 <- table1[2 , 1 ] / sum ( table1[2 , ] ) Er2 <- table2[2 , 1 ] / sum ( table2[2 , ] ) Er3 <- table3[2 , 1 ] / sum ( table3[2 , ] ) Er4 <- table4[2 , 1 ] / sum ( table4[2 , ] ) Er5 <- table5[2 , 1 ] / sum ( table5[2 , ] ) Er6 <- table6[2 , 1 ] / sum ( table6[2 , ] ) Er7 <- table7[2 , 1 ] / sum ( table7[2 , ] ) Er8 <- table8[2 , 1 ] / sum ( table8[2 , ] ) Er9 <- table9[2 , 1 ] / sum ( table9[2 , ] ) Er10 <- table10[2 , 1 ] / sum ( table10[2 , ] ) Er11 <- table11[2 , 1 ] / sum ( table11[2 , ] ) # error: No when Yes Er21 <- table1[1 , 2 ] / sum ( table1[1 , ] ) Er22 <- table2[1 , 2 ] / sum ( table2[1 , ] ) Er23 <- table3[1 , 2 ] / sum ( table3[1 , ] ) Er24 <- table4[1 , 2 ] / sum ( table4[1 , ] ) Er25 <- table5[1 , 2 ] / sum ( table5[1 , ] ) Er26 <- table6[1 , 2 ] / sum ( table6[1 , ] ) Er27 <- table7[1 , 2 ] / sum ( table7[1 , ] ) Er28 <- table8[1 , 2 ] / sum ( table8[1 , ] ) Er29 <- table9[1 , 2 ] / sum ( table9[1 , ] ) Er210 <- table10[1 , 2 ] / sum ( table10[1 , ] ) Er211 <- table11[1 , 2 ] / sum ( table11[1 , ] ) FalsePositive <- round ( c ( Er1 , Er2 , Er3 , Er4 , Er5 , Er6 , Er7 , Er8 , Er9 , Er10 , Er11 ), 3 ) FalseNegative <- round ( c ( Er21 , Er22 , Er23 , Er24 , Er25 , Er26 , Er27 , Er28 , Er29 , Er210 , Er211 ), 3 ) Method TestError Full Logistic Model 0.095 Reduced Logistic Model 0.093 10-NN Full Model 0.162 5-NN Reduced Model 0.120 Pruned Tree 0.117 Unpruned Tree 0.117 Bagging (n=300) 0.074 Bagging (n=25) 0.076 Random Forest I (n=300) 0.074 Random Forest II (n=300) 0.073 Random Forest III (n=40) 0.074 In [33]: data.frame ( Method , TestError , FalsePositive , FalseNegative ) Method TestError FalsePositive FalseNegative Full Logistic Model 0.095 0.176 0.081 Reduced Logistic Model 0.093 0.183 0.082 10-NN Full Model 0.162 0.402 0.143 5-NN Reduced Model 0.120 0.185 0.113 Pruned Tree 0.117 0.283 0.092 Unpruned Tree 0.117 0.257 0.098 Bagging (n=300) 0.074 0.160 0.059 Bagging (n=25) 0.076 0.173 0.058 Random Forest I (n=300) 0.074 0.137 0.064 Random Forest II (n=300) 0.073 0.146 0.060 Random Forest III (n=40) 0.074 0.152 0.061 I have also included the false positive and false negative results, as these can help to determine which models fit the best. The Random Forest model which used 40 trees and 39 variables performed the best out of all the methods used. It is clear that the bagging and random forest methods were superior to the logistic and KNN methods. Of the simpler methods, the reduced Logistic Model using stepwise reduction with the AIC performed the best. Despite my original inclinations, we can see from the importance plots on the bagging model and the summaries of the logistic model that race was not a very significant factor in determining whether a person would be arrested or not. However, as we saw before from the bar graphs, there was a significantly larger portion of blacks who were stopped and frisked than the general population. This suggests that a black person is more likely to be stopped, but not significantly more or less likely than other races to be arrested after they are stopped. Which raises the question: why stop more black people if they are no more likely to be arrested after the frisk than other races? Another variable of interest was sb_other. This variable indicates that there was an \"other reason for stopping the subject.\" As such, this variable is difficult to interpret. However, the variable was quite significant with a high coefficient in the logistic model, and was rated as the most important variable by a large margin in the bagging models. This is a point of difficulty in the interpretations. This may indicate that there needs to be more disclosure about the reason a person was searched, since the sb variables in their current state fail to capture much of the reasons for arrest. In both the logisitic and bagging methods, the variables for contraband and knife/cutting object came up as significant, and had a significant effect on whether the person was arrested or not. This is logical: if the officer found a weapon on contraband on the person, they were much more likely to be arrested. This was far more significant than other factors about the person, in particular the cs variables, which list the reasons why the person was stopped, or the age, weight, gender and race variables, which are the physical attributes of the person. This suggests that the physical attributes of a person are not nearly as important as criminal possession in predicting an arrest, which is in support of the stop and frisk's usage. For instance, being stopped due to the clothing you wear (cs_cloth) or being perceived as a lookout (cs_lkout) were not nearly as significant as carrying a suspicious object (cs_object) or if they were searched (searched), and actually had negative coefficients. So it appears that, most of the time, the probability of being arrested was largely reliant on whether the person was searched or not, or found to have an object. This matches up with the significance and postive coefficient of cs_drgtr, which was the variable representing the cause of search being for a suspected drug transaction. One would conclude that if a person was being suspected for a drug transaction, they would also be more likely to have contraband or perhaps a weapon than if they were not. Interestingly, the frisked variable was not found to be significant in the logistic regression model, suggesting that frisking, as compared to searching, was not very significant in arrest, and therefore not too effective a measure to stop criminal activity. In both models, searching had a stronger effect than frisking in determining whether a person was arrested or not. The success of the random forest/bagging methods as compared to the simpler methods suggests that the relationship between whether a person is arrested or not and the various variables in the dataset is quite complex, and that it cannot be estimated as well using the simpler techniques. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Projects","url":"category/projects/nypd_stop_frisk_full.html","loc":"category/projects/nypd_stop_frisk_full.html"}]};