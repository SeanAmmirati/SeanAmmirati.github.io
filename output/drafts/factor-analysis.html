
<!DOCTYPE HTML>
<!--
	Dopetrope 2.0 by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
			<title>Stats Works</title>
			<meta http-equiv="content-type" content="text/html; charset=utf-8" />
			<meta charset="utf-8" />
			<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,900,300italic" rel="stylesheet" />
				<link rel="stylesheet" href="/theme/css/pygment.css" />
			<noscript>
				<link rel="stylesheet" href="/theme/css/skel-noscript.css" />
				<link rel="stylesheet" href="/theme/css/style.css" />
				<link rel="stylesheet" href="/theme/css/style-desktop.css" />
			</noscript>
	</head>
	<body class="no-sidebar">
		<!-- Header Wrapper -->
			<div id="header-wrapper">
				<div class="container">
					<div class="row">
						<div class="12u">
						
							<!-- Header -->
								<section id="header">
									
									<!-- Logo -->
									<h1><a href="https://seanammirati.github.io/">Stats Works</a></h1>
									
									<!-- Nav -->
										<nav id="nav">
											<ul>
														<li><a href="/">Home</a></li>
														<li><a href="/pages/topics">Topics</a></li>
														<li><a href="/pages/about">About</a></li>
											</ul>
										</nav>

								</section>

						</div>
					</div>
				</div>
			</div>
		
		<!-- Main Wrapper -->
			<div id="main-wrapper">
				<div class="container">
<div class="row">
	<div class="12u">
			<section>
				<div>
					<div class="row">
						<div class="12u skel-cell-mainContent">
							<!-- Content -->
								<article class="box is-post">
									<div class="post-infos">
										<ul class="tags">
											<li><a class="button" href="category/r_markdown">R_markdown</a></li>
										</ul>
									</div>

									<div class="pennant pennant-alt date">2018-09-16</div>
									<h2>Factor Analysis</h2>
									<h2>Factor Analysis</h2>
<h1>Overview</h1>
<p><em>Note: All of the code associated with this project can be found on my GitHub repository located <a href="https://github.com/SeanAmmirati/stats-works/blob/master/projects/Factor%20Analysis%20-%20Case%20Study/factor_analysis.R">here</a>.</em></p>
<p>In this project, I will be introducing the concept of factor analysis and use it to analyze a dataset of responses to a psychological survey. </p>
<p>Factor analysis is similar to principal components analysis, in that we are working only with a single group of variables (in this case, the response) and we wish to reduce the number of variables we use in total in order to simplify our data. This gives us a sense of what the underlying nature of the data is, and how it is organized. We wish to reduce the redundancy of the variables by limiting them to a smaller number of factors which can adequately explain the variations in the full set of variables. </p>
<p>Factor analysis is considered somewhat controversial by statisticians and is not encouraged by all schools of thought. This is because factor analysis is often difficult to validate in practice, as the number of factors or the interpretations are not always clear from the analysis itself. </p>
<p>Although at first glance factor analysis and principal component analysis may seem very similar, there are key differences which separate the two methods. First, in principal component analysis we aim to maximize the total variance of the variables in question, but in factor analysis we wish to account for the covariance between the variables. Secondly, while principal components analysis uses linear combinations of the variables themselves, in factor analysis we create a linear combination of factors which define the variables. </p>
<p>To give a concrete example, the factors that we are looking at are some underlying attributes of the variables that we believe to be correlated in some way. For instance, let’s say there we have students’ test scores for different classes: physics, chemistry, statistics, English, history, etc. We may expect that there would be some underlying factors that would affect an individual’s ability to perform well in these classes. Perhaps this would be something like quantitative reasoning skills, critical thinking ability, or reading level and skill. We wish to reduce the variables to a smaller subset that can use these factors (which are not observed but can be derived from the data using factor analysis) to simplify our dataset. We would then use factor analysis to determine the correct number of factors and the effects these factors have on each of the variables. </p>
<p>It is quite easy to see how in practice this could be quite difficult to implement. This contributes to the skepticism of some statisticians to its use in the first place. Often times, the data doesn’t easily lend itself to such a simplistic interpretation, and it is unclear what these factors can be and how they should be interpreted. </p>
<hr>
<h1>The Model</h1>
<p>Our model is constructed as follows: For each observation vector of <span class="math">\(p\)</span> variables, we have </p>
<div class="math">$$
y_1 - \mu_1 = \lambda_{1 1}f_1 + \lambda_{1 2}f_2 + ... + \lambda_{1 m}f_m + \epsilon_1 \\
y_2 - \mu_2 = \lambda_{2 1}f_1 + \lambda_{2 2}f_2 + ... + \lambda_{2 m}f_m + \epsilon_2 \\
... \\
y_p - \mu_p = \lambda_{p 1}f_1 + \lambda_{p 2}f_2 + ... + \lambda_{p m}f_m + \epsilon_p
$$</div>
<p>On the left side of the equations, <span class="math">\(y_1, ..., y_p\)</span> are the variables in the dataset, and <span class="math">\(\mu_1, ..., \mu_p\)</span> are the corresponding means of these variables. We do this in order to center the variables. </p>
<p>On the right side of the equations,  <span class="math">\(\lambda_{i j}\)</span> are the <strong>loadings</strong> for the <span class="math">\(ith\)</span> variable and <span class="math">\(jth\)</span> factor, <span class="math">\(f_1, f_2, ..., f_m\)</span> are the <span class="math">\(m\)</span> factors, and <span class="math">\(\epsilon_1, \epsilon_2, ..., \epsilon_p\)</span> are the <span class="math">\(p\)</span> error terms associated with each variable. </p>
<p>Our goal in doing factor analysis is to find some <span class="math">\(m &lt;&lt; p\)</span> such that the factors specified above are appropriate for the <span class="math">\(p\)</span> variables of interest. </p>
<p>In doing this, we are defining the original <span class="math">\(p\)</span> variables into a linear combination of <span class="math">\(m\)</span> factors. The <span class="math">\(f\)</span>s in the above model are the <span class="math">\(m\)</span> factors themselves, while the lambdas are the loadings, which serve as weights for each factor for each of the <span class="math">\(p\)</span> variables.</p>
<p>While this may seem similar to a more typical <strong>multiple regression model</strong>, there are key differences.</p>
<p>Perhaps the most important thing to note here is that the <span class="math">\(fs\)</span> are unobserved random variables, not fixed effects like in multiple regression. Factor analysis only represents one observation vector, while multiple regression represents all of the observations simultaneously -- in this way, factor analysis is looking more to <em>individual</em> variation as opposed to <em>aggregate</em> or population level aggregation. </p>
<p>Our model can be written more simply in matrix notation as: </p>
<div class="math">$$
\begin{equation}
\vec{y} - \vec{\mu} = \Lambda\vec{f} + \vec{\epsilon}
\end{equation}
$$</div>
<p>
where
</p>
<div class="math">$$
\vec{y} = \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_p \end{bmatrix} \\
\vec{\mu} = \begin{bmatrix} \mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{bmatrix} \\
\vec{f} = \begin{bmatrix} f_1 \\ f_2 \\ \vdots \\ f_m \end{bmatrix} \\
\vec{\epsilon} = \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_p \end{bmatrix} \\
\Lambda = \begin{bmatrix} \lambda_{1 1}  ... \lambda_{1 m} \\
                          \vdots       \ddots\vdots         \\
                          \lambda_{p 1} ... \lambda_{p m}
          \end{bmatrix}
$$</div>
<p><strong>Assumptions</strong>: In performing factor analysis, we assume that the following holds:</p>
<ol>
<li>
<p><span class="math">\(\mathbb{E}[\vec{f}] = \vec{0}\)</span></p>
</li>
<li>
<p><span class="math">\(\Sigma_{\vec{f}} = I_{mxm}\)</span> </p>
</li>
<li>
<p><span class="math">\(\mathbb{E}[\vec{\epsilon}] = \vec{0}\)</span></p>
</li>
<li>
<p><span class="math">\(\Sigma_{\vec{\epsilon}} = \Phi_{mxm} \text{, where } \Phi{pxp} = <div class="math">\begin{pmatrix} \sigma^2_{\epsilon_1}  &amp; 0 &amp; \dots &amp; 0 \\ 0 &amp; \sigma^2_{\epsilon_2}  &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \dots &amp; \sigma^2_{\epsilon_p} \end{pmatrix}</div>\)</span></p>
</li>
<li><span class="math">\(\Sigma_{\vec{f}, \vec{\epsilon}} = 0_{mxm}\)</span></li>
</ol>
<p><em>Notationally, I mean <span class="math">\(\Sigma_{\vec{X}}\)</span> to be the square covariance matrix of a vector <span class="math">\(\vec{X}\)</span> with itself, where the <span class="math">\(i, j\)</span>th element is the covariance of the <span class="math">\(i\)</span>th entry in <span class="math">\(\vec{X}\)</span>  with the <span class="math">\(j\)</span>th entry. It is therefore a <strong>positive semi-definite symmetric</strong> matrix with variances in the diagonal.</em> </p>
<p><em>I mean <span class="math">\(\Sigma_{\vec{X}, \vec{Y}}\)</span> to be the covariances of each element in <span class="math">\(\vec{X}\)</span>  with each element in <span class="math">\(\vec{Y}\)</span>. This is not a square matrix, but relates the covariance of the individual elements of the two vectors.</em> </p>
<p>These assumptions follow naturally from the model itself. For instance, as <span class="math">\(\mathbb{E}[\vec{y} - \vec{\mu}] = \vec{0}\)</span>, it follows that both episilon and the factors themselves must also have an expected value of zero. We assume that the factors are uncorrelated, as we wish to minimize the number of variables used (so, we wish to have no correlation between the factors themselves.) </p>
<p>The <span class="math">\(\Phi\)</span> matrix shows that there are no covariance between the errors, only a <em>specific variance</em> for each error term, meaning the factors account for the correlations amongst the <span class="math">\(y\)</span>s. This is exactly the goal of factor analysis, so these assumptions are self-checking -- if in recreating the model it is not clear what the factors should be or what number of them there should be, it is saying that these assumptions have not been met.</p>
<p>In achieving our goal in factor analysis of reducing the variables used, we wish to express the covariance of <span class="math">\(\vec{y}\)</span> in terms of the loadings <span class="math">\(\Lambda\)</span> and the variances of the errors, <span class="math">\(Phi\)</span> using some number of factors <span class="math">\(m\)</span> which is less than the original number of variables <span class="math">\(p.\)</span></p>
<p>We can show that the population covariance matrix <span class="math">\(\Sigma_{\vec{y}-\vec{\mu}}\)</span> can be written as follows:
  </p>
<div class="math">$$ \Sigma_{\vec{y}-\vec{\mu}} = \Lambda \Lambda{'} + \Phi$$</div>
<p>
This follows from assumption 2 and 5 above. We can see then that the variance in this case will be a combination of some <em>signal</em> -- or explained -- variance in the latent variable loadings, and some <em>random</em> or unexplained variance in the error terms. This seperates Factor analysis from Principle Component Analysis -- in PCA, we make no distinction between explained and unexplained variance except in terms of the number of components selected. Here, we make this distinction for a number of latent variables. </p>
<p>It is also of note that we can rotate the loadings by an orthogonal matrix without effecting their ability to reproduce this population covariance matrix. As such the loadings are not unique. We will use these rotations when we perform analysis using this method. The rotations prove useful as the results given in the loadings may not make it clear which variables are effected by which factors. By rotating the coordinate axis, we can more easily interpret the results from the factor analysis
.
The variances of each of the individual <span class="math">\(y\)</span>s can be written as follows:
</p>
<div class="math">$$
Var[y_i] = h^2_i + \phi_i
$$</div>
<p>
where <span class="math">\(h_i^2 = \lambda_{i 1}^2 + \lambda_{i 2}^2 + ... + \lambda_{i m}^2\)</span> and <span class="math">\(\phi_i\)</span> is the <em>specific variance</em> for the ith error term, that is, the ith diagonal of Ψ. Thus we can separate the variance of each of the <span class="math">\(y\)</span>s into a communal and specific part, which is <span class="math">\(h_i^2\)</span> and <span class="math">\(\phi_i\)</span> respectively. As such, the diagonal elements can be easily estimated using the loadings and the specific variance, while the off diagonal elements depend on the selection of the loadings alone. Since factor analysis is largely dealing with the estimations of the loadings, it accounts for the covariations between the variables, rather than the total variance as in principal component analysis.</p>
<p>There are four different methods to obtain the loadings <span class="math">\(\Lambda\)</span> from a sample. These are the principal component method, the principal factor method, the iterated principal factor method, and the maximum likelihood method. These will be explored later in the coding.</p>
<p>Another difficulty is determining the number of factors, <span class="math">\(m\)</span>. There are four approaches: we can select the number of variables <span class="math">\(m\)</span> which accounts for a prespecified amount of variance of the variables, we can choose <span class="math">\(m\)</span> to be the number of eigenvalues of the correlation matrix <span class="math">\(R\)</span> which is greater than the average of the eigenvalues, we can use a scree plot to determine where there is a leveling of the eigenvalues of <span class="math">\(R\)</span>, or we can test the hypothesis using a chi-squared distribution if the number of factors is the true number of factors. Again, this will be shown further in the coding. </p>
<h1>Data</h1>
<p>The dataset I will be using to illustrate the benefits and limitations of factor analysis is collected data from an online personality questionnaire. The link can be found <a href="http://personality-testing.info/_rawdata/AS+SC+AD+DO.zip">here</a>.</p>
<p>In this study, 1,005 participants were prompted with 40 statements to rate on a scale of one to five. This scale is used frequently and is known as the likert scale. It ranges from 1 (strongly disagree) to 5 (strongly agree). The data was partitioned into four sections, with every ten statements designed to be related to some attributes of the population; in particular, it was looking for their assertiveness, social confidence, adventurousness, and dominance. The questions were designed to discover the prevalence of these attributes through the responses to the statements in the survey. </p>
<p>This seems like an ideal dataset to use factor analysis on, because the goal of the dataset seems to be precisely what factor analysis is used for. That is, we have some variables (the questions) that have some underlying, unobservable factor (initially hypothesized to be assertiveness, social confidence, adventurousness and dominance) that ties them all together. We are not very interested in the individual answers to the questions themselves, but of the behavior of the underlying factors that exist which are unobservable. </p>
<p>Some examples of questions are printed below: </p>
<p>AS2. I try to lead others.</p>
<p>SC4. I express myself easily.</p>
<p>AD6. I dislike changes.</p>
<p>DO8. I challenge others' points of view.</p>
<p>By looking at the coding markers of each of the questions, we can get a sense of how this survey was distributed and why. If, after doing factor analysis, there are four factors (that is, <span class="math">\(m = 4\)</span>) and these factors are inclusive of each of the ten questions, we can then say that the data reflects these attributes well. </p>
<p>Therefore, the goal of this analysis is to see </p>
<ol>
<li>if the data supports the idea that these factors are well separated in the variables, 
  and </li>
<li>if not, is there a better set of factors that can describe the individual more effectively. </li>
</ol>
<p>After doing some research, it seems that many personality scales fail to truly describe individuals completely. A very popular scale, the Myers Briggs Type Indicator (MBTI), has been purported by many to effectively separate all personalities into one of sixteen types. However, when researchers used factor analysis on data testing for the four underling dimensions of the Myers Briggs tests, they found conflicting results. One of these analyses confirmed the four-dimensionality of the data, while the other suggested there to be six, rather than the four purported by the Myers Briggs test.The motivation for choosing this topic and subsequent dataset was to test these findings for myself. Although I was unable to find an adequate dataset with questions relating to the Myers Briggs tests, I used this dataset to see how well factor analysis can truly separate personality types from a series of related statements. </p>
<h1>Analysis</h1>
<div class="highlight"><pre><span class="code-line"><span></span><span class="kn">require</span><span class="p">(</span>psych<span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## Loading required package: psych</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,</span>
<span class="code-line">## logical.return = TRUE, : there is no package called &#39;psych&#39;</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>tmp <span class="o">&lt;-</span> <span class="kp">tempfile</span><span class="p">()</span></span>
<span class="code-line">download.file<span class="p">(</span><span class="s">&quot;http://personality-testing.info/_rawdata/AS+SC+AD+DO.zip&quot;</span><span class="p">,</span> tmp<span class="p">)</span></span>
<span class="code-line">data <span class="o">&lt;-</span> read.csv<span class="p">(</span><span class="kp">unz</span><span class="p">(</span>tmp<span class="p">,</span> <span class="s">&#39;AS+SC+AD+DO/data.csv&#39;</span><span class="p">))</span></span>
<span class="code-line"><span class="kp">unlink</span><span class="p">(</span>tmp<span class="p">)</span></span>
<span class="code-line"></span>
<span class="code-line">data <span class="o">&lt;-</span> data<span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">40</span><span class="p">]</span></span>
<span class="code-line"><span class="kp">head</span><span class="p">(</span>data<span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##   AS1 AS2 AS3 AS4 AS5 AS6 AS7 AS8 AS9 AS10 SC1 SC2 SC3 SC4 SC5 SC6 SC7 SC8</span>
<span class="code-line">## 1   4   4   3   3   5   4   1   3   1    1   5   3   3   5   5   3   1   1</span>
<span class="code-line">## 2   4   3   4   4   3   2   3   3   4    3   4   4   2   4   4   3   2   2</span>
<span class="code-line">## 3   5   4   4   5   3   3   2   2   1    1   4   4   5   5   4   3   1   2</span>
<span class="code-line">## 4   4   3   3   2   3   3   4   3   4    1   2   2   2   4   2   5   3   4</span>
<span class="code-line">## 5   4   4   4   4   4   3   2   1   2    0   2   3   5   4   4   3   2   4</span>
<span class="code-line">## 6   3   4   4   3   3   3   3   2   3    3   3   3   2   3   2   3   4   3</span>
<span class="code-line">##   SC9 SC10 AD1 AD2 AD3 AD4 AD5 AD6 AD7 AD8 AD9 AD10 DO1 DO2 DO3 DO4 DO5</span>
<span class="code-line">## 1   1    2   5   5   5   5   0   1   2   4   0    3   1   1   3   1   3</span>
<span class="code-line">## 2   4    3   2   4   4   3   4   4   4   4   3    4   4   4   3   2   3</span>
<span class="code-line">## 3   2    1   4   4   4   4   3   3   2   2   2    2   4   3   3   3   3</span>
<span class="code-line">## 4   4    1   4   5   5   4   3   3   2   2   1    4   3   3   3   3   4</span>
<span class="code-line">## 5   3    2   4   5   5   5   2   2   2   2   2    2   4   4   4   3   4</span>
<span class="code-line">## 6   3    4   3   3   3   3   4   4   4   4   4    4   4   3   3   4   4</span>
<span class="code-line">##   DO6 DO7 DO8 DO9 DO10</span>
<span class="code-line">## 1   2   5   4   2    1</span>
<span class="code-line">## 2   2   3   3   2    2</span>
<span class="code-line">## 3   4   4   5   2    3</span>
<span class="code-line">## 4   4   4   5   3    1</span>
<span class="code-line">## 5   3   5   5   4    4</span>
<span class="code-line">## 6   4   3   4   4    3</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>R <span class="o">&lt;-</span> cor<span class="p">(</span>data<span class="p">)</span></span>
<span class="code-line"><span class="kp">head</span><span class="p">(</span>R<span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##           AS1       AS2       AS3       AS4       AS5       AS6        AS7</span>
<span class="code-line">## AS1 1.0000000 0.4137723 0.3682398 0.4448159 0.3221669 0.2931655 -0.3267101</span>
<span class="code-line">## AS2 0.4137723 1.0000000 0.6344424 0.4177133 0.4526988 0.4913432 -0.4684408</span>
<span class="code-line">## AS3 0.3682398 0.6344424 1.0000000 0.3838178 0.4944641 0.5456192 -0.4765066</span>
<span class="code-line">## AS4 0.4448159 0.4177133 0.3838178 1.0000000 0.3028295 0.3159420 -0.2751444</span>
<span class="code-line">## AS5 0.3221669 0.4526988 0.4944641 0.3028295 1.0000000 0.4661230 -0.3747829</span>
<span class="code-line">## AS6 0.2931655 0.4913432 0.5456192 0.3159420 0.4661230 1.0000000 -0.3557865</span>
<span class="code-line">##            AS8        AS9       AS10       SC1       SC2       SC3</span>
<span class="code-line">## AS1 -0.2608312 -0.1858184 -0.1295499 0.4285056 0.4112874 0.4072301</span>
<span class="code-line">## AS2 -0.2919509 -0.3102848 -0.1228974 0.2794722 0.3792339 0.3238358</span>
<span class="code-line">## AS3 -0.2718920 -0.2233892 -0.1374873 0.2048219 0.3419072 0.3159997</span>
<span class="code-line">## AS4 -0.2203457 -0.1744766 -0.2328334 0.2882361 0.3799405 0.3611323</span>
<span class="code-line">## AS5 -0.1977530 -0.2327827 -0.1506424 0.2195033 0.2735981 0.2906018</span>
<span class="code-line">## AS6 -0.2394912 -0.2095667 -0.1155672 0.2035914 0.2631961 0.2504064</span>
<span class="code-line">##           SC4       SC5        SC6        SC7        SC8        SC9</span>
<span class="code-line">## AS1 0.8052136 0.4244275 -0.3740276 -0.3269790 -0.3873580 -0.3303758</span>
<span class="code-line">## AS2 0.3479028 0.3992569 -0.3088470 -0.3360871 -0.2557838 -0.3088422</span>
<span class="code-line">## AS3 0.3174110 0.3650399 -0.2719931 -0.2595922 -0.1857361 -0.2824092</span>
<span class="code-line">## AS4 0.4341378 0.6259835 -0.3247033 -0.4924797 -0.2697620 -0.2852133</span>
<span class="code-line">## AS5 0.3072572 0.3285196 -0.2106510 -0.2028605 -0.1917232 -0.2209485</span>
<span class="code-line">## AS6 0.2835608 0.2812656 -0.1879648 -0.2157404 -0.1811293 -0.1834070</span>
<span class="code-line">##           SC10       AD1        AD2       AD3       AD4        AD5</span>
<span class="code-line">## AS1 -0.4089318 0.1875949 0.15643465 0.1487799 0.1392974 -0.1847433</span>
<span class="code-line">## AS2 -0.3170253 0.1590446 0.11190079 0.1109313 0.1276431 -0.1652769</span>
<span class="code-line">## AS3 -0.2710233 0.1806743 0.09430766 0.1307351 0.1278203 -0.1418593</span>
<span class="code-line">## AS4 -0.2724498 0.1518371 0.14846325 0.1152092 0.1269040 -0.1358413</span>
<span class="code-line">## AS5 -0.2355771 0.2342433 0.17200751 0.1535967 0.2325989 -0.1615080</span>
<span class="code-line">## AS6 -0.1954802 0.1327174 0.17447845 0.1674757 0.1681196 -0.1139023</span>
<span class="code-line">##            AD6        AD7         AD8          AD9       AD10       DO1</span>
<span class="code-line">## AS1 -0.1393561 -0.1082207 -0.11934587 -0.092401403 -0.1487103 0.1031671</span>
<span class="code-line">## AS2 -0.1608323 -0.1895181 -0.03349077  0.002088379 -0.1154262 0.2551933</span>
<span class="code-line">## AS3 -0.1397227 -0.1615780 -0.06755426 -0.002385583 -0.1043186 0.2574269</span>
<span class="code-line">## AS4 -0.1123102 -0.1202723 -0.06264240 -0.096320454 -0.1239163 0.1601098</span>
<span class="code-line">## AS5 -0.2199267 -0.1792749 -0.09872212 -0.050800773 -0.1073202 0.2189824</span>
<span class="code-line">## AS6 -0.1192533 -0.1122125 -0.04246729 -0.043489608 -0.1163537 0.2377874</span>
<span class="code-line">##            DO2        DO3       DO4       DO5       DO6       DO7</span>
<span class="code-line">## AS1 0.09393072 0.05655698 0.1736394 0.1128714 0.2045945 0.2821300</span>
<span class="code-line">## AS2 0.26932527 0.20737706 0.3264103 0.2162572 0.3004144 0.2971938</span>
<span class="code-line">## AS3 0.27971084 0.24749086 0.3568029 0.2513066 0.3279393 0.2882716</span>
<span class="code-line">## AS4 0.15038853 0.12135381 0.2166474 0.1918464 0.2673106 0.2415963</span>
<span class="code-line">## AS5 0.22601369 0.15205653 0.2137453 0.1715335 0.1811936 0.2429682</span>
<span class="code-line">## AS6 0.25424424 0.22620592 0.3082356 0.2454524 0.2617313 0.2924134</span>
<span class="code-line">##           DO8       DO9      DO10</span>
<span class="code-line">## AS1 0.1982907 0.1183617 0.1488767</span>
<span class="code-line">## AS2 0.2598124 0.3015476 0.2841464</span>
<span class="code-line">## AS3 0.2657068 0.2976032 0.3326947</span>
<span class="code-line">## AS4 0.2472153 0.1542765 0.2298038</span>
<span class="code-line">## AS5 0.2532139 0.2470171 0.2718944</span>
<span class="code-line">## AS6 0.3185667 0.2968619 0.2707137</span>
</pre></div>


<p>I begin by importing the dataset and only using the variables pertaining to the questions. The next step is to find the correlation matrix. This is the preferred matrix to work with, as it makes many of the computations easier to do (as compared with the covariance matrix itself). We can see immediately that this is a covariance matrix, as there are ones in the diagonal. However, it does not appear to have particularly strong or easily discernible groups of correlations between the variables, which implies that factor analysis may not perform as well as we’d had hoped.</p>
<p>I did not produce the entire matrix, as it is a 40x40 matrix. Instead, I use the head function to display the first six rows of the matrix. </p>
<p>There were forty questions on the questionaire, with every ten representing a "factor" of one's personality. We are using factor analysis to  determine whether there is statistical evidence that these groupings represent latent 'factors'. </p>
<h3>Selecting <span class="math">\(m\)</span></h3>
<p>As mentioned before, it often is not clear how many factors, <span class="math">\(m\)</span>, we should use in the factor analysis. In this example, it would be preferable to use four, as that is how the data is designed. However, as we will see, four factors are not sufficient to separate the variables. </p>
<p>In order to perform factor analysis, we must find the correlation matrix of the dataset. This makes many of the calculations quite simple. </p>
<p>The next step will be determining how many factors we should use.  </p>
<div class="highlight"><pre><span class="code-line"><span></span>R <span class="o">&lt;-</span> cor<span class="p">(</span>data<span class="p">)</span></span>
</pre></div>


<p>Once we have the correlation matrix, the eigenvalues will tell us the optimal number of ways to reduce the features.</p>
<div class="highlight"><pre><span class="code-line"><span></span><span class="kp">eigen</span><span class="p">(</span>R<span class="p">)</span><span class="o">$</span>values</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##  [1] 9.2102905 4.2476023 2.7109404 2.1236229 1.5857626 1.4029742 1.2549875</span>
<span class="code-line">##  [8] 1.0702245 0.9805980 0.9329088 0.8759874 0.8103524 0.7940435 0.7709803</span>
<span class="code-line">## [15] 0.7300965 0.6806931 0.6657701 0.6360141 0.5896871 0.5632701 0.5500684</span>
<span class="code-line">## [22] 0.5214415 0.5079724 0.4900886 0.4713010 0.4559068 0.4351443 0.4127115</span>
<span class="code-line">## [29] 0.3918664 0.3757153 0.3598197 0.3499867 0.3393500 0.3158847 0.2952949</span>
<span class="code-line">## [36] 0.2555521 0.2354301 0.2258390 0.2038526 0.1699676</span>
</pre></div>


<p>There are numerous methods to select the number of eigenvectors/eigenvalues we want to include. Each eigenvalue represents the proportion of variance explained by that eigenvector (a linear combination of the variables). We want to select eigenvectors/values such that we can explain a good deal of the variance with a smaller number of linear combinations of the features. </p>
<p>The first method involves choosing an arbitrary threshold. In this example, at 19 latent variables (that is, reducing the forty variables nearly in half) we have acheieved a threshold of variance explained greater than 60%.</p>
<div class="highlight"><pre><span class="code-line"><span></span><span class="kp">sum</span><span class="p">(</span><span class="kp">eigen</span><span class="p">(</span>R<span class="p">)</span><span class="o">$</span>values<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">19</span><span class="p">])</span><span class="o">/</span><span class="m">40</span> <span class="c1">##choose 19</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## [1] 0.8018384</span>
</pre></div>


<p>Another method is to select eigenvectors such that each corresponding eigenvalue is greater than one. This means that the eigenvector of variables contributes more to the variance of the features than any single feature alone. Using this method, we come up with 8 linear combinations.</p>
<div class="highlight"><pre><span class="code-line"><span></span><span class="kp">sum</span><span class="p">(</span><span class="kp">eigen</span><span class="p">(</span>R<span class="p">)</span><span class="o">$</span>values <span class="o">&gt;</span> <span class="m">1</span><span class="p">)</span> <span class="c1">##choose 8</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## [1] 8</span>
</pre></div>


<p>The final methodology is using a scree plot and determining where the eigenvalues level off. This is at 9 linear combinations of the features.</p>
<div class="highlight"><pre><span class="code-line"><span></span>scree<span class="p">(</span>R<span class="p">)</span><span class="c1">##choose 9</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## Error in scree(R): could not find function &quot;scree&quot;</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>fa.parallel<span class="p">(</span>data<span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## Error in fa.parallel(data): could not find function &quot;fa.parallel&quot;</span>
</pre></div>


<p>Three different methods were explored to determine the amount of factors, <span class="math">\(m\)</span>, to use. Unfortunately, it seems right from the beginning that four factors will not be enough to adequately describe the variables. The three methods provide very different numbers – 19, 8 and 9. I will use 9, as it appears to be a middle ground between the two, and the scree plot does flatten out significantly. Also, we do not wish to use nearly half of the number of variables as factors! Even 9 factors is quite high. </p>
<p>This is where factor analysis and principle component analysis begin to differ. In PCA, we simply use the eigenvectors of the correlation matrix as variables, or 'principle components'. This does not account for the noise in the principle components themselves -- it is not trying to find any signal here. </p>
<p>Factor analysis considers that these components are representations of some latent variables, that which are the true 'signal' in the correlation matrix, while the remainder is noise. Factor analysis is controversial because it attempts to estimate this latency by approximating correlation matrices, as we saw above. </p>
<p>Now that we have determined m, the number of factors, we will aim to create the loadings matrix to estimate the covariance matrix, as explained above. There are four methods by which we can estimate the loadings matrices. The loadings matrix in each case will be a <span class="math">\(p x m\)</span> matrix, and will use the eigenvalues of the correlation matrix. The first method we will use is the principal components method. </p>
<h3>Principal Components Method</h3>
<div class="highlight"><pre><span class="code-line"><span></span>eigenvectors <span class="o">&lt;-</span> <span class="kp">eigen</span><span class="p">(</span>R<span class="p">)</span><span class="o">$</span>vectors<span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">]</span></span>
<span class="code-line">loadings <span class="o">&lt;-</span> eigenvectors <span class="o">%*%</span> <span class="p">(</span><span class="kp">diag</span><span class="p">(</span><span class="m">1</span><span class="p">,</span>nrow <span class="o">=</span> <span class="m">9</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="kp">eigen</span><span class="p">(</span>R<span class="p">)</span><span class="o">$</span>values<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">])</span><span class="o">^</span><span class="m">.5</span><span class="p">)</span></span>
<span class="code-line">loadings </span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##             [,1]         [,2]        [,3]          [,4]        [,5]</span>
<span class="code-line">##  [1,] -0.6277856  0.119554084  0.33171585 -0.0517100760  0.19589620</span>
<span class="code-line">##  [2,] -0.6628787 -0.132540591  0.11886326  0.2214725941  0.22140567</span>
<span class="code-line">##  [3,] -0.6390134 -0.197196788  0.05624741  0.2311725131  0.23664371</span>
<span class="code-line">##  [4,] -0.6038332 -0.001172604  0.25194869  0.0287228625  0.19716616</span>
<span class="code-line">##  [5,] -0.5623461 -0.075542614 -0.04215597  0.0889017298  0.31622038</span>
<span class="code-line">##  [6,] -0.5588305 -0.202629294 -0.02405988  0.1321338363  0.30155513</span>
<span class="code-line">##  [7,]  0.5610817 -0.101431288 -0.01542818 -0.4286785091 -0.17991988</span>
<span class="code-line">##  [8,]  0.4195786 -0.089834730  0.04744726 -0.4219788203 -0.09239017</span>
<span class="code-line">##  [9,]  0.3666707 -0.121246001  0.12235117 -0.2673284202 -0.19228688</span>
<span class="code-line">## [10,]  0.2834756 -0.191213944  0.13406289 -0.2440643282 -0.18539624</span>
<span class="code-line">## [11,] -0.5196860  0.270565545  0.30577781 -0.3423029175 -0.11245766</span>
<span class="code-line">## [12,] -0.6564641  0.068827634  0.31328652 -0.2478632919 -0.34403345</span>
<span class="code-line">## [13,] -0.5998907  0.074604175  0.26507843 -0.1892944458 -0.07212877</span>
<span class="code-line">## [14,] -0.6074783  0.096622639  0.34093184 -0.1742184243  0.20372042</span>
<span class="code-line">## [15,] -0.6248483  0.011604348  0.28844967 -0.1296150311  0.17592820</span>
<span class="code-line">## [16,]  0.5974964 -0.234896621 -0.29156288  0.0140733681  0.45380545</span>
<span class="code-line">## [17,]  0.5405337 -0.286677830 -0.22708170 -0.1085333297 -0.06070240</span>
<span class="code-line">## [18,]  0.5065189 -0.420628297 -0.27874397  0.0715082012  0.18189460</span>
<span class="code-line">## [19,]  0.5780675 -0.232627930 -0.26378683 -0.0556981294  0.44299196</span>
<span class="code-line">## [20,]  0.5219373 -0.216594655 -0.13173681 -0.1032620489 -0.04359939</span>
<span class="code-line">## [21,] -0.3992462  0.160965015 -0.36037555 -0.3690507373  0.03464572</span>
<span class="code-line">## [22,] -0.3394289  0.150689800 -0.26903653 -0.5548752336  0.16905090</span>
<span class="code-line">## [23,] -0.3320934 -0.027645815 -0.28907100 -0.5582492767  0.25327472</span>
<span class="code-line">## [24,] -0.3658667  0.108273914 -0.38501438 -0.4940891181  0.19559323</span>
<span class="code-line">## [25,]  0.3796437 -0.447822215  0.39727206 -0.1408538430  0.10110562</span>
<span class="code-line">## [26,]  0.3772945 -0.495954442  0.47234291 -0.1033727528  0.11469191</span>
<span class="code-line">## [27,]  0.3799486 -0.444134704  0.49194137 -0.1387764590  0.13915859</span>
<span class="code-line">## [28,]  0.2576489 -0.483342987  0.37297134 -0.1416818547  0.21231287</span>
<span class="code-line">## [29,]  0.2062744 -0.354617033  0.26543767 -0.0007295079  0.06470126</span>
<span class="code-line">## [30,]  0.3334748 -0.402402498  0.39061932 -0.1902953021  0.08669907</span>
<span class="code-line">## [31,] -0.4064146 -0.347591815 -0.19534506 -0.1439862302 -0.08445037</span>
<span class="code-line">## [32,] -0.4213233 -0.421047564 -0.21614195 -0.1475954934 -0.14140091</span>
<span class="code-line">## [33,] -0.3177238 -0.558528507 -0.21188225 -0.0260375231 -0.11058613</span>
<span class="code-line">## [34,] -0.4535206 -0.568930452 -0.13969631  0.0740933171 -0.20728453</span>
<span class="code-line">## [35,] -0.3733466 -0.534136456 -0.20889608  0.0462874732 -0.18328216</span>
<span class="code-line">## [36,] -0.4519620 -0.486894058  0.02868335 -0.0237170894 -0.22067245</span>
<span class="code-line">## [37,] -0.4792771 -0.359058583 -0.17026707  0.0243226733  0.01058587</span>
<span class="code-line">## [38,] -0.4884591 -0.361002718 -0.23670362 -0.0576248626  0.04542125</span>
<span class="code-line">## [39,] -0.3794872 -0.555721465 -0.09478251  0.1039076241 -0.19174868</span>
<span class="code-line">## [40,] -0.4024135 -0.549377337 -0.11356106  0.1869168187 -0.12464387</span>
<span class="code-line">##               [,6]          [,7]          [,8]         [,9]</span>
<span class="code-line">##  [1,] -0.256426344 -0.0051466920 -0.1050080325 -0.217875830</span>
<span class="code-line">##  [2,]  0.132387083 -0.2481776856  0.0048103856  0.073391368</span>
<span class="code-line">##  [3,]  0.106747616 -0.3142731034  0.0725529294 -0.009258277</span>
<span class="code-line">##  [4,] -0.096650456  0.2237402385  0.3933113732  0.175740568</span>
<span class="code-line">##  [5,]  0.101831072 -0.3414194020  0.0325078492  0.085362217</span>
<span class="code-line">##  [6,]  0.073081367 -0.2777839481 -0.0712005483  0.093765748</span>
<span class="code-line">##  [7,] -0.065822588  0.1121413950  0.1320328403  0.243711028</span>
<span class="code-line">##  [8,]  0.008179850 -0.1017128152  0.1404356750  0.359181871</span>
<span class="code-line">##  [9,] -0.331672078 -0.1723038527  0.3330872957 -0.293884580</span>
<span class="code-line">## [10,] -0.106304884 -0.4565341789 -0.0821946123 -0.171057932</span>
<span class="code-line">## [11,] -0.001271796 -0.1320537729 -0.2283180107  0.265527940</span>
<span class="code-line">## [12,]  0.087823904 -0.1132566054  0.0377935294 -0.011283238</span>
<span class="code-line">## [13,]  0.033343619  0.0308950899  0.1426224411 -0.200220801</span>
<span class="code-line">## [14,] -0.252897043  0.0281370136 -0.0346131237 -0.254485357</span>
<span class="code-line">## [15,] -0.039241251  0.1844820354  0.4216051360  0.098786819</span>
<span class="code-line">## [16,] -0.094810107  0.0093078526  0.0096644094  0.016502011</span>
<span class="code-line">## [17,] -0.083413069 -0.3147783298 -0.2285523728 -0.186028731</span>
<span class="code-line">## [18,]  0.002006571  0.0463524348  0.3018104199 -0.260546935</span>
<span class="code-line">## [19,] -0.109840640  0.0355312724  0.0666607568  0.098413082</span>
<span class="code-line">## [20,]  0.070382456 -0.2508050668  0.2867068313  0.083829363</span>
<span class="code-line">## [21,] -0.123678525 -0.1924745951  0.1507108412 -0.019742963</span>
<span class="code-line">## [22,]  0.011646505 -0.0474249609 -0.1572321905  0.166900898</span>
<span class="code-line">## [23,] -0.005346193  0.1102181121 -0.1334792270 -0.157127058</span>
<span class="code-line">## [24,]  0.064851965 -0.0003570599  0.0709592952 -0.068600025</span>
<span class="code-line">## [25,]  0.076120098  0.0523492570 -0.1131530027  0.095050608</span>
<span class="code-line">## [26,]  0.018459564  0.1824386999 -0.1389626180 -0.114702885</span>
<span class="code-line">## [27,]  0.013283974  0.1229109140 -0.0973772037 -0.116962488</span>
<span class="code-line">## [28,]  0.117125266  0.1369392140 -0.1222056233  0.146276756</span>
<span class="code-line">## [29,]  0.099806178 -0.2945216155  0.1256130100 -0.077929380</span>
<span class="code-line">## [30,]  0.083796843 -0.1520357393 -0.0181765447  0.107031691</span>
<span class="code-line">## [31,]  0.611418809  0.1300478000 -0.0035088423 -0.175680364</span>
<span class="code-line">## [32,]  0.569277998  0.1274642030  0.0120766707 -0.147817867</span>
<span class="code-line">## [33,] -0.064299580  0.1599389824  0.0008566237  0.011078551</span>
<span class="code-line">## [34,] -0.111993462  0.0128182266  0.0851071945  0.058119259</span>
<span class="code-line">## [35,] -0.242376556  0.0930813931 -0.0879622294  0.120472821</span>
<span class="code-line">## [36,] -0.121746325  0.0211133535  0.0949324784 -0.117122331</span>
<span class="code-line">## [37,] -0.329825553  0.0814961168 -0.2338333561  0.027777255</span>
<span class="code-line">## [38,] -0.266631231  0.1774163361 -0.1496133363 -0.028050715</span>
<span class="code-line">## [39,] -0.083409801 -0.1393220930 -0.0449142959  0.188743726</span>
<span class="code-line">## [40,] -0.136300169 -0.0389545949  0.0957233294  0.133687572</span>
</pre></div>


<p>We first determine the loadings by multiplying the first <span class="math">\(m\)</span> eigenvectors (in this case, 9) by the square roots of their corresponding eigenvalues. This produces the above matrix, a unsightly <span class="math">\(40x9\)</span> matrix. Each column corresponds to a different loading. </p>
<p>To determine the communalities and specific variances of the variables, we can square the entries in each of the rows of the loadings matrix. This will give us the <span class="math">\(h^2_i\)</span> vector, from which we can also determine the specific variances. </p>
<div class="highlight"><pre><span class="code-line"><span></span>hisq <span class="o">&lt;-</span> <span class="kp">apply</span><span class="p">(</span><span class="kp">apply</span><span class="p">(</span>loadings<span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="kr">function</span><span class="p">(</span>x<span class="p">)</span> x<span class="o">^</span><span class="m">2</span><span class="p">),</span> <span class="m">1</span><span class="p">,</span> <span class="kp">sum</span><span class="p">)</span></span>
<span class="code-line">psi <span class="o">&lt;-</span> <span class="kp">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">40</span><span class="p">)</span> <span class="o">-</span> hisq</span>
<span class="code-line"></span>
<span class="code-line">hisq</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##  [1] 0.6837702 0.6537022 0.6753417 0.7127732 0.5668960 0.5586903 0.6352115</span>
<span class="code-line">##  [8] 0.5321160 0.6095668 0.4845742 0.7066714 0.7357218 0.5392320 0.6971639</span>
<span class="code-line">## [15] 0.7446073 0.7127661 0.6342772 0.7105137 0.6846617 0.5063354 0.5280230</span>
<span class="code-line">## [22] 0.6017274 0.6250849 0.5901456 0.5629343 0.7013619 0.6606930 0.5730633</span>
<span class="code-line">## [29] 0.3615022 0.5113686 0.7736378 0.8056109 0.5005422 0.6206625 0.5937235</span>
<span class="code-line">## [36] 0.5294148 0.5592003 0.5560673 0.5733943 0.5742527</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>psi</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##  [1] 0.3162298 0.3462978 0.3246583 0.2872268 0.4331040 0.4413097 0.3647885</span>
<span class="code-line">##  [8] 0.4678840 0.3904332 0.5154258 0.2933286 0.2642782 0.4607680 0.3028361</span>
<span class="code-line">## [15] 0.2553927 0.2872339 0.3657228 0.2894863 0.3153383 0.4936646 0.4719770</span>
<span class="code-line">## [22] 0.3982726 0.3749151 0.4098544 0.4370657 0.2986381 0.3393070 0.4269367</span>
<span class="code-line">## [29] 0.6384978 0.4886314 0.2263622 0.1943891 0.4994578 0.3793375 0.4062765</span>
<span class="code-line">## [36] 0.4705852 0.4407997 0.4439327 0.4266057 0.4257473</span>
</pre></div>


<p>The above are the communalities and the specific variances of each of the variables.</p>
<p>To determine the amount of the total variance of which each loading contributes, we can divide the eigenvalues of <span class="math">\(R\)</span> by the number of variables, <span class="math">\(p = 40\)</span>. </p>
<p>Thus, all nine factors account for about 60% of the variance of the variables. This is not very good, especially considering there were supposed to be only four underlying factors! </p>
<h4>Rotating the Loadings</h4>
<p>Because we have <span class="math">\(m = 9\)</span>, I will use the varimax rotations from the psych package to rotate the loadings we have above. This will make it easier to see which variables correspond to the factors. </p>
<div class="highlight"><pre><span class="code-line"><span></span><span class="c1">## varimax includes a print method which makes the loading distributions easier to see.</span></span>
<span class="code-line">loadingsrot <span class="o">&lt;-</span> <span class="kp">print</span><span class="p">(</span>varimax<span class="p">(</span>loadings<span class="p">)</span><span class="o">$</span>loadings<span class="p">,</span>cutoff <span class="o">=</span> <span class="m">.3</span><span class="p">,</span>sort <span class="o">=</span> <span class="bp">T</span><span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## </span>
<span class="code-line">## Loadings:</span>
<span class="code-line">##       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  </span>
<span class="code-line">##  [1,] -0.681                                                        </span>
<span class="code-line">##  [2,] -0.713                                                        </span>
<span class="code-line">##  [3,] -0.681                                                        </span>
<span class="code-line">##  [4,] -0.655                                                        </span>
<span class="code-line">##  [5,]  0.506                                                   0.486</span>
<span class="code-line">##  [6,]        -0.657                                                 </span>
<span class="code-line">##  [7,]        -0.742                                                 </span>
<span class="code-line">##  [8,]        -0.765                                                 </span>
<span class="code-line">##  [9,]        -0.616                                                 </span>
<span class="code-line">## [10,]        -0.642                                                 </span>
<span class="code-line">## [11,]        -0.623                                                 </span>
<span class="code-line">## [12,]        -0.685                                                 </span>
<span class="code-line">## [13,]        -0.698                                                 </span>
<span class="code-line">## [14,]                0.716                                          </span>
<span class="code-line">## [15,]                0.784                                          </span>
<span class="code-line">## [16,]                0.769                                          </span>
<span class="code-line">## [17,]                0.731                                          </span>
<span class="code-line">## [18,]                0.643                                          </span>
<span class="code-line">## [19,]               -0.397 -0.534                                   </span>
<span class="code-line">## [20,]                      -0.718                                   </span>
<span class="code-line">## [21,]                      -0.747                                   </span>
<span class="code-line">## [22,]                      -0.688                                   </span>
<span class="code-line">## [23,]                      -0.313 -0.728                            </span>
<span class="code-line">## [24,]                             -0.753                            </span>
<span class="code-line">## [25,]                              0.759                            </span>
<span class="code-line">## [26,]                              0.727                0.301       </span>
<span class="code-line">## [27,]                              0.722                            </span>
<span class="code-line">## [28,]                                     0.794                     </span>
<span class="code-line">## [29,]        -0.349                       0.786                     </span>
<span class="code-line">## [30,]                                            0.744              </span>
<span class="code-line">## [31,]                                            0.745              </span>
<span class="code-line">## [32,]                              0.338        -0.618              </span>
<span class="code-line">## [33,]  0.302                                            0.681       </span>
<span class="code-line">## [34,]                             -0.408                      -0.522</span>
<span class="code-line">## [35,]                                                          0.578</span>
<span class="code-line">## [36,]                             -0.396         0.337        -0.501</span>
<span class="code-line">## [37,]                                           -0.407  0.481       </span>
<span class="code-line">## [38,]                             -0.478         0.355              </span>
<span class="code-line">## [39,]                              0.360                0.327  0.457</span>
<span class="code-line">## [40,]                0.391                              0.326       </span>
<span class="code-line">## </span>
<span class="code-line">##                 [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]</span>
<span class="code-line">## SS loadings    2.970 4.308 3.507 2.557 3.954 1.746 2.289 1.437 1.819</span>
<span class="code-line">## Proportion Var 0.074 0.108 0.088 0.064 0.099 0.044 0.057 0.036 0.045</span>
<span class="code-line">## Cumulative Var 0.074 0.182 0.270 0.334 0.432 0.476 0.533 0.569 0.615</span>
</pre></div>


<p>We can see from the above that the factors do not separate so easily. The values of the loadings below .3 have been omitted to make it clearer what the underling relationships are. Although they do not separate cleanly into the four theorized factors, we can see that the first factor, for instance, largely is between the first and tenth variables (which was assertiveness), the second factor between the 30th and 40th variables (which was dominance). Similarly, the fifth factor is between the 20th and 30th variables (social confidence) and the third and factor is largely between the 30th and 40th variables (adventurousness). However, the split is not so simple as we assumed before the analysis, as the other factors show relationships between variables which are not in the same groups.</p>
<p>The second function simply sorts the variables by factor, so we can get a better sense of how they separate. We can see that towards the top there are larger values for the loading matrix, which indicates a stronger association with the factor. We can also see that the 6th-9th factors also have some large values, which means that their correlations cannot be ignored. This suggests that the initial separation into only four factors may have been overly simplistic. </p>
<h3>Principle Factors Method</h3>
<p>In the previous method, we had ignored the structure of the specific variances. Now, using the principal factors method, we will take the <span class="math">\(\Phi\)</span> matrix into account. </p>
<p>We first make an initial estimate of the <span class="math">\(h_i\)</span>s, and use this to account for the specific variances. Below I create a diagonal matrix which has the specific variances in each of the diagonal elements. We will then subtract this matrix from the covariance matrix, and use the new matrix to compute our loadings. </p>
<div class="highlight"><pre><span class="code-line"><span></span>hinit <span class="o">&lt;-</span> <span class="m">1</span> <span class="o">-</span> <span class="m">1</span><span class="o">/</span><span class="kp">diag</span><span class="p">(</span><span class="kp">solve</span><span class="p">(</span>R<span class="p">))</span></span>
<span class="code-line">psiint <span class="o">&lt;-</span> <span class="m">1</span> <span class="o">-</span> hinit</span>
<span class="code-line">hinit</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##       AS1       AS2       AS3       AS4       AS5       AS6       AS7 </span>
<span class="code-line">## 0.7033517 0.5479249 0.5511059 0.5052776 0.3909682 0.4178874 0.4791205 </span>
<span class="code-line">##       AS8       AS9      AS10       SC1       SC2       SC3       SC4 </span>
<span class="code-line">## 0.3272596 0.2679338 0.2193710 0.5780393 0.6556874 0.4569506 0.6958877 </span>
<span class="code-line">##       SC5       SC6       SC7       SC8       SC9      SC10       AD1 </span>
<span class="code-line">## 0.5721770 0.6392857 0.4860941 0.5795566 0.5721815 0.3779786 0.3622515 </span>
<span class="code-line">##       AD2       AD3       AD4       AD5       AD6       AD7       AD8 </span>
<span class="code-line">## 0.3823573 0.4021933 0.4125813 0.4284814 0.6107542 0.5793594 0.3926540 </span>
<span class="code-line">##       AD9      AD10       DO1       DO2       DO3       DO4       DO5 </span>
<span class="code-line">## 0.2303057 0.3609034 0.6185178 0.6575069 0.4241176 0.5388412 0.4387844 </span>
<span class="code-line">##       DO6       DO7       DO8       DO9      DO10 </span>
<span class="code-line">## 0.4146146 0.4423540 0.4621925 0.4584707 0.4849043</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>psiint</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##       AS1       AS2       AS3       AS4       AS5       AS6       AS7 </span>
<span class="code-line">## 0.2966483 0.4520751 0.4488941 0.4947224 0.6090318 0.5821126 0.5208795 </span>
<span class="code-line">##       AS8       AS9      AS10       SC1       SC2       SC3       SC4 </span>
<span class="code-line">## 0.6727404 0.7320662 0.7806290 0.4219607 0.3443126 0.5430494 0.3041123 </span>
<span class="code-line">##       SC5       SC6       SC7       SC8       SC9      SC10       AD1 </span>
<span class="code-line">## 0.4278230 0.3607143 0.5139059 0.4204434 0.4278185 0.6220214 0.6377485 </span>
<span class="code-line">##       AD2       AD3       AD4       AD5       AD6       AD7       AD8 </span>
<span class="code-line">## 0.6176427 0.5978067 0.5874187 0.5715186 0.3892458 0.4206406 0.6073460 </span>
<span class="code-line">##       AD9      AD10       DO1       DO2       DO3       DO4       DO5 </span>
<span class="code-line">## 0.7696943 0.6390966 0.3814822 0.3424931 0.5758824 0.4611588 0.5612156 </span>
<span class="code-line">##       DO6       DO7       DO8       DO9      DO10 </span>
<span class="code-line">## 0.5853854 0.5576460 0.5378075 0.5415293 0.5150957</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span><span class="kp">head</span><span class="p">(</span><span class="kp">diag</span><span class="p">(</span>psiint<span class="p">,</span>nrow <span class="o">=</span> <span class="m">40</span><span class="p">))</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##           [,1]      [,2]      [,3]      [,4]      [,5]      [,6] [,7] [,8]</span>
<span class="code-line">## [1,] 0.2966483 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000    0    0</span>
<span class="code-line">## [2,] 0.0000000 0.4520751 0.0000000 0.0000000 0.0000000 0.0000000    0    0</span>
<span class="code-line">## [3,] 0.0000000 0.0000000 0.4488941 0.0000000 0.0000000 0.0000000    0    0</span>
<span class="code-line">## [4,] 0.0000000 0.0000000 0.0000000 0.4947224 0.0000000 0.0000000    0    0</span>
<span class="code-line">## [5,] 0.0000000 0.0000000 0.0000000 0.0000000 0.6090318 0.0000000    0    0</span>
<span class="code-line">## [6,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.5821126    0    0</span>
<span class="code-line">##      [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19]</span>
<span class="code-line">## [1,]    0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [2,]    0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [3,]    0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [4,]    0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [5,]    0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [6,]    0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">##      [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30]</span>
<span class="code-line">## [1,]     0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [2,]     0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [3,]     0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [4,]     0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [5,]     0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [6,]     0     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">##      [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40]</span>
<span class="code-line">## [1,]     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [2,]     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [3,]     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [4,]     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [5,]     0     0     0     0     0     0     0     0     0     0</span>
<span class="code-line">## [6,]     0     0     0     0     0     0     0     0     0     0</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>New <span class="o">&lt;-</span> R <span class="o">-</span> <span class="kp">diag</span><span class="p">(</span>psiint<span class="p">,</span>nrow <span class="o">=</span> <span class="m">40</span><span class="p">)</span></span>
<span class="code-line">eigs <span class="o">&lt;-</span> <span class="kp">eigen</span><span class="p">(</span>New<span class="p">)</span></span>
<span class="code-line"><span class="kp">lapply</span><span class="p">(</span>eigs<span class="p">,</span> <span class="kr">function</span><span class="p">(</span>x<span class="p">)</span> <span class="kp">head</span><span class="p">(</span>x<span class="p">))</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## $values</span>
<span class="code-line">## [1] 8.7248079 3.7312213 2.2221448 1.5595958 1.1319258 0.9492408</span>
<span class="code-line">## </span>
<span class="code-line">## $vectors</span>
<span class="code-line">##            [,1]          [,2]        [,3]        [,4]       [,5]</span>
<span class="code-line">## [1,] -0.2119143  0.0638645803  0.21682254 -0.02246826 -0.2561585</span>
<span class="code-line">## [2,] -0.2192735 -0.0651230428  0.06095857  0.17667274 -0.1331140</span>
<span class="code-line">## [3,] -0.2113429 -0.0975909567  0.02409237  0.18419419 -0.1497616</span>
<span class="code-line">## [4,] -0.1989699  0.0003466393  0.14650375  0.03612404 -0.1657413</span>
<span class="code-line">## [5,] -0.1825263 -0.0364514037 -0.03195393  0.06812156 -0.1884603</span>
<span class="code-line">## [6,] -0.1819015 -0.0973139299 -0.01977135  0.09858958 -0.1844743</span>
<span class="code-line">##             [,6]        [,7]        [,8]        [,9]        [,10]</span>
<span class="code-line">## [1,] -0.15827430 -0.02437054  0.42247811  0.28384644  0.103101134</span>
<span class="code-line">## [2,]  0.16948247  0.25660848 -0.08218936 -0.02585298  0.022204609</span>
<span class="code-line">## [3,]  0.15429878  0.31525832 -0.11681248  0.05386503 -0.098342734</span>
<span class="code-line">## [4,]  0.00831336 -0.26771149 -0.34418847  0.10641897  0.173190027</span>
<span class="code-line">## [5,]  0.13620105  0.29025531 -0.07182123  0.02172858  0.006960383</span>
<span class="code-line">## [6,]  0.11876169  0.26445132 -0.05503917 -0.11167753 -0.029465301</span>
<span class="code-line">##            [,11]        [,12]       [,13]       [,14]        [,15]</span>
<span class="code-line">## [1,] -0.09310605  0.023953605  0.11176428 -0.11366806  0.004013874</span>
<span class="code-line">## [2,] -0.09159496  0.116164513  0.12346706  0.12093219 -0.058282880</span>
<span class="code-line">## [3,] -0.09631138  0.023670802  0.03010137  0.17192468  0.174719738</span>
<span class="code-line">## [4,]  0.03116940 -0.041063817  0.12846342 -0.05639591  0.084647510</span>
<span class="code-line">## [5,]  0.08910892  0.056604682 -0.18983583 -0.14149013  0.187404140</span>
<span class="code-line">## [6,] -0.02110050  0.006001516  0.07260636  0.01404517  0.331118635</span>
<span class="code-line">##             [,16]       [,17]        [,18]       [,19]       [,20]</span>
<span class="code-line">## [1,]  0.051720282 -0.02023824 -0.058414767  0.05138678 -0.07469648</span>
<span class="code-line">## [2,]  0.007900105 -0.06065739 -0.204351746  0.35636341 -0.36586927</span>
<span class="code-line">## [3,] -0.059353877 -0.04104552 -0.100604716  0.11325441  0.04586721</span>
<span class="code-line">## [4,]  0.163214149  0.02202949 -0.115407241  0.16097110  0.26392717</span>
<span class="code-line">## [5,]  0.026535895 -0.03181385 -0.003240182 -0.48181263  0.13138548</span>
<span class="code-line">## [6,]  0.023463697 -0.17747720  0.323295238  0.01072855  0.29721500</span>
<span class="code-line">##             [,21]        [,22]       [,23]       [,24]       [,25]</span>
<span class="code-line">## [1,]  0.057959131 -0.039740203 -0.10091982  0.19428410  0.01796631</span>
<span class="code-line">## [2,] -0.063845223  0.070692539  0.09664590  0.02912342 -0.23794583</span>
<span class="code-line">## [3,]  0.152655994  0.235933268 -0.24627306  0.17021304  0.19246694</span>
<span class="code-line">## [4,] -0.064174449 -0.001977639 -0.14865577  0.22825409 -0.12945456</span>
<span class="code-line">## [5,]  0.012388216  0.045289069  0.12488489 -0.02175602  0.15939425</span>
<span class="code-line">## [6,]  0.008091656 -0.338532991  0.04980414 -0.17205428 -0.21068313</span>
<span class="code-line">##            [,26]      [,27]       [,28]      [,29]        [,30]</span>
<span class="code-line">## [1,]  0.03946758 -0.2840391 -0.20725439  0.3966971  0.153131769</span>
<span class="code-line">## [2,] -0.16426001 -0.1757583  0.01613049 -0.1790272 -0.144768073</span>
<span class="code-line">## [3,]  0.08815452  0.3573144 -0.14554754  0.1567410  0.034890131</span>
<span class="code-line">## [4,]  0.25713666 -0.2418887  0.16263086 -0.3007080 -0.003159806</span>
<span class="code-line">## [5,] -0.26803070 -0.3908587  0.06133227 -0.1097638 -0.017536034</span>
<span class="code-line">## [6,]  0.15421018  0.1218706  0.06392335  0.1732284 -0.069677270</span>
<span class="code-line">##            [,31]       [,32]       [,33]        [,34]        [,35]</span>
<span class="code-line">## [1,] -0.03929150  0.03903633  0.23440780 -0.195661904 -0.052521020</span>
<span class="code-line">## [2,] -0.11410580  0.26719581 -0.25721448  0.084579620  0.006368062</span>
<span class="code-line">## [3,]  0.30324362 -0.24999761 -0.01132970  0.048299141 -0.029114530</span>
<span class="code-line">## [4,] -0.02117228 -0.17866058  0.01595029 -0.006459983  0.166166465</span>
<span class="code-line">## [5,] -0.06221996 -0.04995202  0.12398561  0.033326042  0.296758825</span>
<span class="code-line">## [6,] -0.16322995  0.12937284  0.01295837 -0.090902394 -0.224304742</span>
<span class="code-line">##            [,36]         [,37]        [,38]       [,39]       [,40]</span>
<span class="code-line">## [1,]  0.07320291 -1.077204e-01  0.034580219  0.10461472 -0.07616725</span>
<span class="code-line">## [2,]  0.19823278 -1.040005e-01 -0.019282142  0.08930675 -0.16669195</span>
<span class="code-line">## [3,] -0.04175342  2.922844e-01 -0.039162734  0.01132162 -0.06103074</span>
<span class="code-line">## [4,] -0.23602211 -9.898293e-05 -0.024771785  0.17497598  0.17124571</span>
<span class="code-line">## [5,]  0.15422821  1.732424e-01  0.009510652 -0.10383857 -0.04741480</span>
<span class="code-line">## [6,] -0.03088877 -2.512679e-01 -0.022685293 -0.05952826  0.18244423</span>
</pre></div>


<p>We will then use this new matrix to compute our eigenvalues and vectors, and subsequently create our new loadings matrix. In a similar way, we will determine the specific variances and communalities, and then rotate the loadings matrix. </p>
<div class="highlight"><pre><span class="code-line"><span></span>eigenvectors2 <span class="o">&lt;-</span> <span class="kp">eigen</span><span class="p">(</span>New<span class="p">)</span><span class="o">$</span>vectors<span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">]</span></span>
<span class="code-line">loadings2 <span class="o">&lt;-</span> eigenvectors2 <span class="o">%*%</span> <span class="p">(</span><span class="kp">diag</span><span class="p">(</span><span class="m">1</span><span class="p">,</span>nrow <span class="o">=</span> <span class="m">9</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="kp">eigen</span><span class="p">(</span>New<span class="p">)</span><span class="o">$</span>values<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">])</span><span class="o">^</span><span class="m">.5</span><span class="p">)</span></span>
<span class="code-line">hisq2 <span class="o">&lt;-</span> <span class="kp">apply</span><span class="p">(</span><span class="kp">apply</span><span class="p">(</span>loadings2<span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="kr">function</span><span class="p">(</span>x<span class="p">)</span> x<span class="o">^</span><span class="m">2</span><span class="p">),</span> <span class="m">1</span><span class="p">,</span> <span class="kp">sum</span><span class="p">)</span></span>
<span class="code-line">psi <span class="o">&lt;-</span> <span class="kp">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">40</span><span class="p">)</span> <span class="o">-</span> hisq</span>
<span class="code-line">loadings2rot <span class="o">&lt;-</span> <span class="kp">print</span><span class="p">(</span>varimax<span class="p">(</span>loadings2<span class="p">)</span><span class="o">$</span>loadings<span class="p">,</span>cutoff <span class="o">=</span> <span class="m">.35</span><span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## </span>
<span class="code-line">## Loadings:</span>
<span class="code-line">##       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  </span>
<span class="code-line">##  [1,]                                                   0.713       </span>
<span class="code-line">##  [2,] -0.635                                                        </span>
<span class="code-line">##  [3,] -0.662                                                        </span>
<span class="code-line">##  [4,]                                           -0.574              </span>
<span class="code-line">##  [5,] -0.549                                                        </span>
<span class="code-line">##  [6,] -0.554                                                        </span>
<span class="code-line">##  [7,]  0.500                                                        </span>
<span class="code-line">##  [8,]                                                               </span>
<span class="code-line">##  [9,]                                                          0.368</span>
<span class="code-line">## [10,]                                                               </span>
<span class="code-line">## [11,]                              0.636                            </span>
<span class="code-line">## [12,]                              0.729                            </span>
<span class="code-line">## [13,]                              0.460                            </span>
<span class="code-line">## [14,]                                                   0.717       </span>
<span class="code-line">## [15,]                                           -0.620              </span>
<span class="code-line">## [16,]                             -0.739                            </span>
<span class="code-line">## [17,]                             -0.360         0.505              </span>
<span class="code-line">## [18,]                             -0.650                            </span>
<span class="code-line">## [19,]                             -0.688                            </span>
<span class="code-line">## [20,]                                                          0.371</span>
<span class="code-line">## [21,]                      -0.466                                   </span>
<span class="code-line">## [22,]                      -0.625                                   </span>
<span class="code-line">## [23,]                      -0.627                                   </span>
<span class="code-line">## [24,]                      -0.597                                   </span>
<span class="code-line">## [25,]                0.649                                          </span>
<span class="code-line">## [26,]                0.754                                          </span>
<span class="code-line">## [27,]                0.732                                          </span>
<span class="code-line">## [28,]                0.635                                          </span>
<span class="code-line">## [29,]                0.362                                          </span>
<span class="code-line">## [30,]                0.578                                          </span>
<span class="code-line">## [31,]                                     0.727                     </span>
<span class="code-line">## [32,]        -0.375                       0.730                     </span>
<span class="code-line">## [33,]        -0.609                                                 </span>
<span class="code-line">## [34,]        -0.711                                                 </span>
<span class="code-line">## [35,]        -0.686                                                 </span>
<span class="code-line">## [36,]        -0.588                                                 </span>
<span class="code-line">## [37,]        -0.582                                                 </span>
<span class="code-line">## [38,]        -0.581                                                 </span>
<span class="code-line">## [39,]        -0.631                                                 </span>
<span class="code-line">## [40,]        -0.651                                                 </span>
<span class="code-line">## </span>
<span class="code-line">##                 [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]</span>
<span class="code-line">## SS loadings    2.508 3.963 3.089 1.957 3.511 1.279 1.401 1.402 0.995</span>
<span class="code-line">## Proportion Var 0.063 0.099 0.077 0.049 0.088 0.032 0.035 0.035 0.025</span>
<span class="code-line">## Cumulative Var 0.063 0.162 0.239 0.288 0.376 0.408 0.443 0.478 0.503</span>
</pre></div>


<p>We can see a similar pattern to that of the principal component method above. The variance is not as well explained using this method, but when we perform the next step (using iterations of the above method), it will become a better representation of the data. Again, we can see similar relationships between the first five factors and the variables, but it is not all encompassing. </p>
<h3>Principal Factors Method</h3>
<p>We will now use a similar method to above, but iterate it each time and update it with the new initial squared loadings. That is, when we calculate the new <span class="math">\(h^2_i\)</span> values, we do the iterate until it converges. For completeness, I perform the process 100 times below. </p>
<div class="highlight"><pre><span class="code-line"><span></span>hinit2 <span class="o">&lt;-</span> <span class="m">1</span> <span class="o">-</span> <span class="m">1</span><span class="o">/</span><span class="kp">diag</span><span class="p">(</span><span class="kp">solve</span><span class="p">(</span>R<span class="p">))</span></span>
<span class="code-line"><span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="m">100</span><span class="p">)</span> <span class="p">{</span></span>
<span class="code-line">  New2 <span class="o">&lt;-</span> R <span class="o">-</span> <span class="kp">diag</span><span class="p">((</span><span class="m">1</span> <span class="o">-</span> hinit2<span class="p">),</span>nrow <span class="o">=</span> <span class="m">40</span><span class="p">)</span></span>
<span class="code-line">  eigenvectors3 <span class="o">&lt;-</span> <span class="kp">eigen</span><span class="p">(</span>New2<span class="p">)</span><span class="o">$</span>vectors<span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">]</span></span>
<span class="code-line">  loadings3 <span class="o">&lt;-</span> eigenvectors3 <span class="o">%*%</span> <span class="p">(</span><span class="kp">diag</span><span class="p">(</span><span class="m">1</span><span class="p">,</span>nrow <span class="o">=</span> <span class="m">9</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="kp">eigen</span><span class="p">(</span>New2<span class="p">)</span><span class="o">$</span>values<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">])</span><span class="o">^</span><span class="m">.5</span><span class="p">)</span></span>
<span class="code-line">  hinit2 <span class="o">&lt;-</span> <span class="kp">apply</span><span class="p">(</span><span class="kp">apply</span><span class="p">(</span>loadings3<span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="kr">function</span><span class="p">(</span>x<span class="p">)</span> x<span class="o">^</span><span class="m">2</span><span class="p">),</span> <span class="m">1</span><span class="p">,</span> <span class="kp">sum</span><span class="p">)</span></span>
<span class="code-line"><span class="p">}</span></span>
<span class="code-line">hisq3 <span class="o">=</span> hinit2 </span>
<span class="code-line">loadings3</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##             [,1]         [,2]         [,3]         [,4]         [,5]</span>
<span class="code-line">##  [1,] -0.6336865  0.129510159  0.342334002 -0.038023630 -0.298855098</span>
<span class="code-line">##  [2,] -0.6502007 -0.125780976  0.094612300  0.224797379 -0.119888358</span>
<span class="code-line">##  [3,] -0.6291168 -0.190720725  0.040105304  0.241398639 -0.146635370</span>
<span class="code-line">##  [4,] -0.5908644  0.002653042  0.226497992  0.040334761 -0.168819189</span>
<span class="code-line">##  [5,] -0.5403052 -0.069776558 -0.046541079  0.088730496 -0.184540364</span>
<span class="code-line">##  [6,] -0.5383186 -0.187930368 -0.027921243  0.127559024 -0.182887463</span>
<span class="code-line">##  [7,]  0.5427781 -0.094736535  0.006660377 -0.381431291  0.087614276</span>
<span class="code-line">##  [8,]  0.3964542 -0.078623909  0.051902429 -0.326084495  0.044529009</span>
<span class="code-line">##  [9,]  0.3450905 -0.102407731  0.114416779 -0.188480115  0.024731098</span>
<span class="code-line">## [10,]  0.2642319 -0.161843476  0.115746565 -0.166040194  0.068724964</span>
<span class="code-line">## [11,] -0.5066480  0.260520630  0.262478846 -0.290267019  0.080632270</span>
<span class="code-line">## [12,] -0.6545789  0.074217208  0.290576461 -0.232408027  0.333829685</span>
<span class="code-line">## [13,] -0.5774633  0.071893130  0.217354904 -0.150535446  0.064325771</span>
<span class="code-line">## [14,] -0.6108433  0.105405443  0.349790991 -0.163838651 -0.300910254</span>
<span class="code-line">## [15,] -0.6225742  0.015818600  0.276931601 -0.112348412 -0.156714309</span>
<span class="code-line">## [16,]  0.5917724 -0.235014489 -0.255368899  0.006650969 -0.424432473</span>
<span class="code-line">## [17,]  0.5279568 -0.274680621 -0.187219522 -0.101549741 -0.006358423</span>
<span class="code-line">## [18,]  0.4940006 -0.403112322 -0.229288093  0.053826480 -0.149052853</span>
<span class="code-line">## [19,]  0.5679135 -0.227968636 -0.220179480 -0.057163025 -0.401467891</span>
<span class="code-line">## [20,]  0.4988083 -0.198023532 -0.098685578 -0.087517556  0.037379190</span>
<span class="code-line">## [21,] -0.3811688  0.142742173 -0.307097139 -0.296217542 -0.089586852</span>
<span class="code-line">## [22,] -0.3269154  0.136263759 -0.233410980 -0.474756404 -0.138868985</span>
<span class="code-line">## [23,] -0.3203851 -0.030166568 -0.245768083 -0.487202590 -0.205275498</span>
<span class="code-line">## [24,] -0.3520775  0.095211884 -0.336299557 -0.428447845 -0.149642422</span>
<span class="code-line">## [25,]  0.3651857 -0.412331552  0.368944213 -0.117631028 -0.026511108</span>
<span class="code-line">## [26,]  0.3703239 -0.479742202  0.476104604 -0.096721625 -0.057825485</span>
<span class="code-line">## [27,]  0.3699674 -0.421161776  0.480916968 -0.124121065 -0.078094691</span>
<span class="code-line">## [28,]  0.2463836 -0.441672543  0.339399682 -0.114323666 -0.089602239</span>
<span class="code-line">## [29,]  0.1920995 -0.302887469  0.214310995  0.008630304 -0.010576560</span>
<span class="code-line">## [30,]  0.3177906 -0.361924210  0.349591276 -0.146596477 -0.020838225</span>
<span class="code-line">## [31,] -0.4021482 -0.351959582 -0.201011400 -0.176729613  0.263077182</span>
<span class="code-line">## [32,] -0.4265001 -0.447290807 -0.237762488 -0.201792383  0.345792026</span>
<span class="code-line">## [33,] -0.3041925 -0.513476732 -0.171039751 -0.023635033  0.034697829</span>
<span class="code-line">## [34,] -0.4423233 -0.542324765 -0.120056095  0.074356156  0.095296276</span>
<span class="code-line">## [35,] -0.3607007 -0.500592080 -0.174513283  0.046947376  0.037358826</span>
<span class="code-line">## [36,] -0.4350645 -0.446475795  0.030254396 -0.010627044  0.101759433</span>
<span class="code-line">## [37,] -0.4599254 -0.329350786 -0.137864380  0.028873337 -0.110769493</span>
<span class="code-line">## [38,] -0.4702438 -0.336331662 -0.199380424 -0.044648421 -0.119115633</span>
<span class="code-line">## [39,] -0.3655473 -0.514596691 -0.078419787  0.097432633  0.093421477</span>
<span class="code-line">## [40,] -0.3888139 -0.512946164 -0.095166329  0.169291414  0.033699196</span>
<span class="code-line">##               [,6]         [,7]          [,8]         [,9]</span>
<span class="code-line">##  [1,] -0.106461077  0.004012698  0.4158842813 -0.135351810</span>
<span class="code-line">##  [2,]  0.183656923 -0.219213531 -0.0853302346 -0.005595223</span>
<span class="code-line">##  [3,]  0.173629622 -0.280919773 -0.1084499357 -0.062148373</span>
<span class="code-line">##  [4,]  0.045883497  0.264423699 -0.2146298828 -0.139428187</span>
<span class="code-line">##  [5,]  0.153429789 -0.241690414 -0.0715201038 -0.043392862</span>
<span class="code-line">##  [6,]  0.135235784 -0.224915024 -0.0776985624  0.061374907</span>
<span class="code-line">##  [7,] -0.135960537  0.081417002 -0.0316562359 -0.128293688</span>
<span class="code-line">##  [8,] -0.049494223 -0.071142504 -0.0747379454 -0.122691640</span>
<span class="code-line">##  [9,] -0.224110839 -0.036705193 -0.0697731205 -0.189402920</span>
<span class="code-line">## [10,] -0.112025835 -0.220779261  0.0120029682 -0.083149450</span>
<span class="code-line">## [11,] -0.054378180 -0.154096849  0.0042190639  0.110051557</span>
<span class="code-line">## [12,] -0.097500210 -0.134497695 -0.0869242753 -0.052456320</span>
<span class="code-line">## [13,]  0.004985414  0.017801279 -0.0225716598 -0.066759174</span>
<span class="code-line">## [14,] -0.103460721  0.045917678  0.3512154313 -0.173798335</span>
<span class="code-line">## [15,]  0.086461623  0.283676355 -0.3076787991 -0.195371434</span>
<span class="code-line">## [16,]  0.116896158  0.026640961  0.0407768581 -0.024693231</span>
<span class="code-line">## [17,] -0.131489718 -0.307936400  0.2109326646 -0.053543527</span>
<span class="code-line">## [18,]  0.058937557  0.079736682 -0.0232532548 -0.217180572</span>
<span class="code-line">## [19,]  0.088122223  0.046636312  0.0008630064 -0.070659460</span>
<span class="code-line">## [20,]  0.007864417 -0.112906050 -0.1261029356 -0.214195713</span>
<span class="code-line">## [21,] -0.090118823 -0.097821370 -0.0685454038 -0.104261189</span>
<span class="code-line">## [22,]  0.016461123 -0.091602431 -0.0939518707  0.145870493</span>
<span class="code-line">## [23,]  0.037694710  0.008704829 -0.0416043160  0.183271179</span>
<span class="code-line">## [24,]  0.056262149 -0.029658115 -0.0706184986  0.004097048</span>
<span class="code-line">## [25,]  0.073337166 -0.028056229 -0.0530975791  0.108645037</span>
<span class="code-line">## [26,]  0.071261480  0.081462466  0.0360994696  0.185563020</span>
<span class="code-line">## [27,]  0.074598867  0.047942227  0.0369657600  0.117259474</span>
<span class="code-line">## [28,]  0.133700006  0.015520059 -0.0628408544  0.141265238</span>
<span class="code-line">## [29,]  0.051437400 -0.149282018 -0.0246684699 -0.103773907</span>
<span class="code-line">## [30,]  0.053217935 -0.144213470 -0.0810473995 -0.010744364</span>
<span class="code-line">## [31,]  0.444156811  0.088841988  0.1869857115 -0.057679182</span>
<span class="code-line">## [32,]  0.460313960  0.104878412  0.2129963667 -0.087767881</span>
<span class="code-line">## [33,] -0.114633165  0.097987560 -0.0090573562  0.030682748</span>
<span class="code-line">## [34,] -0.199403042  0.027929674 -0.0202432667 -0.069660173</span>
<span class="code-line">## [35,] -0.267136034  0.074407466 -0.0093759739  0.080036468</span>
<span class="code-line">## [36,] -0.174325196  0.029505768 -0.0120425589 -0.050011012</span>
<span class="code-line">## [37,] -0.226812362  0.044696510  0.0707773605  0.146141059</span>
<span class="code-line">## [38,] -0.177227803  0.122626669  0.0060156884  0.175156554</span>
<span class="code-line">## [39,] -0.160987378 -0.093535945 -0.0298388671 -0.005968257</span>
<span class="code-line">## [40,] -0.152326147  0.016936469 -0.0188479397 -0.086933077</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>hisq3</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##  [1] 0.8289141 0.6015374 0.6382330 0.5680873 0.4298459 0.4542829 0.4993689</span>
<span class="code-line">##  [8] 0.3025154 0.2711171 0.2100527 0.5230468 0.7217756 0.4179823 0.7903544</span>
<span class="code-line">## [15] 0.7225057 0.6674738 0.5590656 0.5417629 0.6023525 0.3814098 0.3890036</span>
<span class="code-line">## [22] 0.4633676 0.4802789 0.4611304 0.4748262 0.6541179 0.5900188 0.4340915</span>
<span class="code-line">## [29] 0.2110671 0.4064326 0.6699060 0.8747538 0.4109744 0.5645937 0.4981439</span>
<span class="code-line">## [36] 0.4339110 0.4319218 0.4673458 0.4583968 0.4845446</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>loadings</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##             [,1]         [,2]        [,3]          [,4]        [,5]</span>
<span class="code-line">##  [1,] -0.6277856  0.119554084  0.33171585 -0.0517100760  0.19589620</span>
<span class="code-line">##  [2,] -0.6628787 -0.132540591  0.11886326  0.2214725941  0.22140567</span>
<span class="code-line">##  [3,] -0.6390134 -0.197196788  0.05624741  0.2311725131  0.23664371</span>
<span class="code-line">##  [4,] -0.6038332 -0.001172604  0.25194869  0.0287228625  0.19716616</span>
<span class="code-line">##  [5,] -0.5623461 -0.075542614 -0.04215597  0.0889017298  0.31622038</span>
<span class="code-line">##  [6,] -0.5588305 -0.202629294 -0.02405988  0.1321338363  0.30155513</span>
<span class="code-line">##  [7,]  0.5610817 -0.101431288 -0.01542818 -0.4286785091 -0.17991988</span>
<span class="code-line">##  [8,]  0.4195786 -0.089834730  0.04744726 -0.4219788203 -0.09239017</span>
<span class="code-line">##  [9,]  0.3666707 -0.121246001  0.12235117 -0.2673284202 -0.19228688</span>
<span class="code-line">## [10,]  0.2834756 -0.191213944  0.13406289 -0.2440643282 -0.18539624</span>
<span class="code-line">## [11,] -0.5196860  0.270565545  0.30577781 -0.3423029175 -0.11245766</span>
<span class="code-line">## [12,] -0.6564641  0.068827634  0.31328652 -0.2478632919 -0.34403345</span>
<span class="code-line">## [13,] -0.5998907  0.074604175  0.26507843 -0.1892944458 -0.07212877</span>
<span class="code-line">## [14,] -0.6074783  0.096622639  0.34093184 -0.1742184243  0.20372042</span>
<span class="code-line">## [15,] -0.6248483  0.011604348  0.28844967 -0.1296150311  0.17592820</span>
<span class="code-line">## [16,]  0.5974964 -0.234896621 -0.29156288  0.0140733681  0.45380545</span>
<span class="code-line">## [17,]  0.5405337 -0.286677830 -0.22708170 -0.1085333297 -0.06070240</span>
<span class="code-line">## [18,]  0.5065189 -0.420628297 -0.27874397  0.0715082012  0.18189460</span>
<span class="code-line">## [19,]  0.5780675 -0.232627930 -0.26378683 -0.0556981294  0.44299196</span>
<span class="code-line">## [20,]  0.5219373 -0.216594655 -0.13173681 -0.1032620489 -0.04359939</span>
<span class="code-line">## [21,] -0.3992462  0.160965015 -0.36037555 -0.3690507373  0.03464572</span>
<span class="code-line">## [22,] -0.3394289  0.150689800 -0.26903653 -0.5548752336  0.16905090</span>
<span class="code-line">## [23,] -0.3320934 -0.027645815 -0.28907100 -0.5582492767  0.25327472</span>
<span class="code-line">## [24,] -0.3658667  0.108273914 -0.38501438 -0.4940891181  0.19559323</span>
<span class="code-line">## [25,]  0.3796437 -0.447822215  0.39727206 -0.1408538430  0.10110562</span>
<span class="code-line">## [26,]  0.3772945 -0.495954442  0.47234291 -0.1033727528  0.11469191</span>
<span class="code-line">## [27,]  0.3799486 -0.444134704  0.49194137 -0.1387764590  0.13915859</span>
<span class="code-line">## [28,]  0.2576489 -0.483342987  0.37297134 -0.1416818547  0.21231287</span>
<span class="code-line">## [29,]  0.2062744 -0.354617033  0.26543767 -0.0007295079  0.06470126</span>
<span class="code-line">## [30,]  0.3334748 -0.402402498  0.39061932 -0.1902953021  0.08669907</span>
<span class="code-line">## [31,] -0.4064146 -0.347591815 -0.19534506 -0.1439862302 -0.08445037</span>
<span class="code-line">## [32,] -0.4213233 -0.421047564 -0.21614195 -0.1475954934 -0.14140091</span>
<span class="code-line">## [33,] -0.3177238 -0.558528507 -0.21188225 -0.0260375231 -0.11058613</span>
<span class="code-line">## [34,] -0.4535206 -0.568930452 -0.13969631  0.0740933171 -0.20728453</span>
<span class="code-line">## [35,] -0.3733466 -0.534136456 -0.20889608  0.0462874732 -0.18328216</span>
<span class="code-line">## [36,] -0.4519620 -0.486894058  0.02868335 -0.0237170894 -0.22067245</span>
<span class="code-line">## [37,] -0.4792771 -0.359058583 -0.17026707  0.0243226733  0.01058587</span>
<span class="code-line">## [38,] -0.4884591 -0.361002718 -0.23670362 -0.0576248626  0.04542125</span>
<span class="code-line">## [39,] -0.3794872 -0.555721465 -0.09478251  0.1039076241 -0.19174868</span>
<span class="code-line">## [40,] -0.4024135 -0.549377337 -0.11356106  0.1869168187 -0.12464387</span>
<span class="code-line">##               [,6]          [,7]          [,8]         [,9]</span>
<span class="code-line">##  [1,] -0.256426344 -0.0051466920 -0.1050080325 -0.217875830</span>
<span class="code-line">##  [2,]  0.132387083 -0.2481776856  0.0048103856  0.073391368</span>
<span class="code-line">##  [3,]  0.106747616 -0.3142731034  0.0725529294 -0.009258277</span>
<span class="code-line">##  [4,] -0.096650456  0.2237402385  0.3933113732  0.175740568</span>
<span class="code-line">##  [5,]  0.101831072 -0.3414194020  0.0325078492  0.085362217</span>
<span class="code-line">##  [6,]  0.073081367 -0.2777839481 -0.0712005483  0.093765748</span>
<span class="code-line">##  [7,] -0.065822588  0.1121413950  0.1320328403  0.243711028</span>
<span class="code-line">##  [8,]  0.008179850 -0.1017128152  0.1404356750  0.359181871</span>
<span class="code-line">##  [9,] -0.331672078 -0.1723038527  0.3330872957 -0.293884580</span>
<span class="code-line">## [10,] -0.106304884 -0.4565341789 -0.0821946123 -0.171057932</span>
<span class="code-line">## [11,] -0.001271796 -0.1320537729 -0.2283180107  0.265527940</span>
<span class="code-line">## [12,]  0.087823904 -0.1132566054  0.0377935294 -0.011283238</span>
<span class="code-line">## [13,]  0.033343619  0.0308950899  0.1426224411 -0.200220801</span>
<span class="code-line">## [14,] -0.252897043  0.0281370136 -0.0346131237 -0.254485357</span>
<span class="code-line">## [15,] -0.039241251  0.1844820354  0.4216051360  0.098786819</span>
<span class="code-line">## [16,] -0.094810107  0.0093078526  0.0096644094  0.016502011</span>
<span class="code-line">## [17,] -0.083413069 -0.3147783298 -0.2285523728 -0.186028731</span>
<span class="code-line">## [18,]  0.002006571  0.0463524348  0.3018104199 -0.260546935</span>
<span class="code-line">## [19,] -0.109840640  0.0355312724  0.0666607568  0.098413082</span>
<span class="code-line">## [20,]  0.070382456 -0.2508050668  0.2867068313  0.083829363</span>
<span class="code-line">## [21,] -0.123678525 -0.1924745951  0.1507108412 -0.019742963</span>
<span class="code-line">## [22,]  0.011646505 -0.0474249609 -0.1572321905  0.166900898</span>
<span class="code-line">## [23,] -0.005346193  0.1102181121 -0.1334792270 -0.157127058</span>
<span class="code-line">## [24,]  0.064851965 -0.0003570599  0.0709592952 -0.068600025</span>
<span class="code-line">## [25,]  0.076120098  0.0523492570 -0.1131530027  0.095050608</span>
<span class="code-line">## [26,]  0.018459564  0.1824386999 -0.1389626180 -0.114702885</span>
<span class="code-line">## [27,]  0.013283974  0.1229109140 -0.0973772037 -0.116962488</span>
<span class="code-line">## [28,]  0.117125266  0.1369392140 -0.1222056233  0.146276756</span>
<span class="code-line">## [29,]  0.099806178 -0.2945216155  0.1256130100 -0.077929380</span>
<span class="code-line">## [30,]  0.083796843 -0.1520357393 -0.0181765447  0.107031691</span>
<span class="code-line">## [31,]  0.611418809  0.1300478000 -0.0035088423 -0.175680364</span>
<span class="code-line">## [32,]  0.569277998  0.1274642030  0.0120766707 -0.147817867</span>
<span class="code-line">## [33,] -0.064299580  0.1599389824  0.0008566237  0.011078551</span>
<span class="code-line">## [34,] -0.111993462  0.0128182266  0.0851071945  0.058119259</span>
<span class="code-line">## [35,] -0.242376556  0.0930813931 -0.0879622294  0.120472821</span>
<span class="code-line">## [36,] -0.121746325  0.0211133535  0.0949324784 -0.117122331</span>
<span class="code-line">## [37,] -0.329825553  0.0814961168 -0.2338333561  0.027777255</span>
<span class="code-line">## [38,] -0.266631231  0.1774163361 -0.1496133363 -0.028050715</span>
<span class="code-line">## [39,] -0.083409801 -0.1393220930 -0.0449142959  0.188743726</span>
<span class="code-line">## [40,] -0.136300169 -0.0389545949  0.0957233294  0.133687572</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>loadings3rot <span class="o">&lt;-</span> <span class="kp">print</span><span class="p">(</span>varimax<span class="p">(</span>loadings3<span class="p">)</span><span class="o">$</span>loadings<span class="p">,</span>cutoff <span class="o">=</span> <span class="m">.3</span><span class="p">)</span></span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>## </span>
<span class="code-line">## Loadings:</span>
<span class="code-line">##       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  </span>
<span class="code-line">##  [1,]                              0.328                0.771       </span>
<span class="code-line">##  [2,] -0.639                                                        </span>
<span class="code-line">##  [3,] -0.688 -0.300                                                 </span>
<span class="code-line">##  [4,]                                            0.593              </span>
<span class="code-line">##  [5,] -0.551                                                        </span>
<span class="code-line">##  [6,] -0.555                                                        </span>
<span class="code-line">##  [7,]  0.487                                                  -0.362</span>
<span class="code-line">##  [8,]                                                         -0.357</span>
<span class="code-line">##  [9,]                                                         -0.376</span>
<span class="code-line">## [10,]                                                         -0.326</span>
<span class="code-line">## [11,]                              0.605                            </span>
<span class="code-line">## [12,]                              0.755                            </span>
<span class="code-line">## [13,]                              0.463                            </span>
<span class="code-line">## [14,]                              0.324                0.749       </span>
<span class="code-line">## [15,]                              0.300         0.703              </span>
<span class="code-line">## [16,]                             -0.757                            </span>
<span class="code-line">## [17,]                             -0.361        -0.509        -0.340</span>
<span class="code-line">## [18,]                             -0.624                            </span>
<span class="code-line">## [19,]                             -0.706                            </span>
<span class="code-line">## [20,]                             -0.327                      -0.398</span>
<span class="code-line">## [21,]               -0.350 -0.455                                   </span>
<span class="code-line">## [22,]                      -0.647                                   </span>
<span class="code-line">## [23,]                      -0.662                                   </span>
<span class="code-line">## [24,]                      -0.606                                   </span>
<span class="code-line">## [25,]                0.653                                          </span>
<span class="code-line">## [26,]                0.771                                          </span>
<span class="code-line">## [27,]                0.734                                          </span>
<span class="code-line">## [28,]                0.641                                          </span>
<span class="code-line">## [29,]                0.347                                          </span>
<span class="code-line">## [30,]                0.573                                          </span>
<span class="code-line">## [31,]                                     0.730                     </span>
<span class="code-line">## [32,]        -0.367                       0.834                     </span>
<span class="code-line">## [33,]        -0.606                                                 </span>
<span class="code-line">## [34,]        -0.717                                                 </span>
<span class="code-line">## [35,]        -0.698                                                 </span>
<span class="code-line">## [36,]        -0.592                                                 </span>
<span class="code-line">## [37,]        -0.575                                                 </span>
<span class="code-line">## [38,]        -0.578                                                 </span>
<span class="code-line">## [39,]        -0.628                                                 </span>
<span class="code-line">## [40,]        -0.649                                                 </span>
<span class="code-line">## </span>
<span class="code-line">##                 [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]</span>
<span class="code-line">## SS loadings    2.456 3.967 3.049 1.971 3.529 1.417 1.485 1.511 1.206</span>
<span class="code-line">## Proportion Var 0.061 0.099 0.076 0.049 0.088 0.035 0.037 0.038 0.030</span>
<span class="code-line">## Cumulative Var 0.061 0.161 0.237 0.286 0.374 0.410 0.447 0.485 0.515</span>
</pre></div>


<p>Again, we can see a similar pattern to the two above methods. The iterated method also created loadings which are closer to the principal component method. There are a few differences; for instance, in the iterated method we see that the third variable is part of both the 1st and 2nd factor, which wasn’t present in the principal component method nor the principal factor method. Still, the analysis from before holds: much of the expected separation is contained in the factors (or some combination of them), but there are other correlations which those four factors cannot account for.</p>
<p>I will use the rotated matrix above to make some considerations about the level of effectiveness of the analysis. We know that the main goal of factor analysis is to acquire factors for which each variable can be loaded into only one factor. If we can do this, we have essentially reached our goal – we have separated the variables completely into a smaller number of factors which accounts for the covariates between them. </p>
<p>However, in practice, this is very difficult to achieve. In the loading matrix above, there are many instance where the variables correlate strongly with more than one factor at once -- that is there is no clear distinction between what these questions relate to in terms of our factors. This indicates that factor analysis is not doing a very good job at separating the factors with the number of factors we have used.  </p>
<h1>Some Considerations</h1>
<p>In an ideal situation, we would use a very small value of <span class="math">\(m\)</span> relative to the amount of variables <span class="math">\(p\)</span>. Although <span class="math">\(m = 9\)</span> performed decently well, it is quite a large number of factors. Even with nine factors, we see that the factor analysis was only able to account for around 60% of the covariation of the original variables. A fundamental issue with factor analysis is that the correlation matrix <span class="math">\(R\)</span> contains both structure and error, and factor analysis is not able to separate the two. Thus, the original assumptions of no relationships between the errors and the factors are too optimistic, as this rarely happens in practice. </p>
<p>As a result, the loadings above are quite difficult to interpret. It is difficult to say what the exact factors are in plain English. Here, we can see some of the difficulty in working with factor analysis in practice – it is often questioned if these factors truly exist. </p>
<h1>Conclusions and Relation to Psychological Tests</h1>
<div class="highlight"><pre><span class="code-line"><span></span>loadings</span>
</pre></div>


<div class="highlight"><pre><span class="code-line"><span></span>##             [,1]         [,2]        [,3]          [,4]        [,5]</span>
<span class="code-line">##  [1,] -0.6277856  0.119554084  0.33171585 -0.0517100760  0.19589620</span>
<span class="code-line">##  [2,] -0.6628787 -0.132540591  0.11886326  0.2214725941  0.22140567</span>
<span class="code-line">##  [3,] -0.6390134 -0.197196788  0.05624741  0.2311725131  0.23664371</span>
<span class="code-line">##  [4,] -0.6038332 -0.001172604  0.25194869  0.0287228625  0.19716616</span>
<span class="code-line">##  [5,] -0.5623461 -0.075542614 -0.04215597  0.0889017298  0.31622038</span>
<span class="code-line">##  [6,] -0.5588305 -0.202629294 -0.02405988  0.1321338363  0.30155513</span>
<span class="code-line">##  [7,]  0.5610817 -0.101431288 -0.01542818 -0.4286785091 -0.17991988</span>
<span class="code-line">##  [8,]  0.4195786 -0.089834730  0.04744726 -0.4219788203 -0.09239017</span>
<span class="code-line">##  [9,]  0.3666707 -0.121246001  0.12235117 -0.2673284202 -0.19228688</span>
<span class="code-line">## [10,]  0.2834756 -0.191213944  0.13406289 -0.2440643282 -0.18539624</span>
<span class="code-line">## [11,] -0.5196860  0.270565545  0.30577781 -0.3423029175 -0.11245766</span>
<span class="code-line">## [12,] -0.6564641  0.068827634  0.31328652 -0.2478632919 -0.34403345</span>
<span class="code-line">## [13,] -0.5998907  0.074604175  0.26507843 -0.1892944458 -0.07212877</span>
<span class="code-line">## [14,] -0.6074783  0.096622639  0.34093184 -0.1742184243  0.20372042</span>
<span class="code-line">## [15,] -0.6248483  0.011604348  0.28844967 -0.1296150311  0.17592820</span>
<span class="code-line">## [16,]  0.5974964 -0.234896621 -0.29156288  0.0140733681  0.45380545</span>
<span class="code-line">## [17,]  0.5405337 -0.286677830 -0.22708170 -0.1085333297 -0.06070240</span>
<span class="code-line">## [18,]  0.5065189 -0.420628297 -0.27874397  0.0715082012  0.18189460</span>
<span class="code-line">## [19,]  0.5780675 -0.232627930 -0.26378683 -0.0556981294  0.44299196</span>
<span class="code-line">## [20,]  0.5219373 -0.216594655 -0.13173681 -0.1032620489 -0.04359939</span>
<span class="code-line">## [21,] -0.3992462  0.160965015 -0.36037555 -0.3690507373  0.03464572</span>
<span class="code-line">## [22,] -0.3394289  0.150689800 -0.26903653 -0.5548752336  0.16905090</span>
<span class="code-line">## [23,] -0.3320934 -0.027645815 -0.28907100 -0.5582492767  0.25327472</span>
<span class="code-line">## [24,] -0.3658667  0.108273914 -0.38501438 -0.4940891181  0.19559323</span>
<span class="code-line">## [25,]  0.3796437 -0.447822215  0.39727206 -0.1408538430  0.10110562</span>
<span class="code-line">## [26,]  0.3772945 -0.495954442  0.47234291 -0.1033727528  0.11469191</span>
<span class="code-line">## [27,]  0.3799486 -0.444134704  0.49194137 -0.1387764590  0.13915859</span>
<span class="code-line">## [28,]  0.2576489 -0.483342987  0.37297134 -0.1416818547  0.21231287</span>
<span class="code-line">## [29,]  0.2062744 -0.354617033  0.26543767 -0.0007295079  0.06470126</span>
<span class="code-line">## [30,]  0.3334748 -0.402402498  0.39061932 -0.1902953021  0.08669907</span>
<span class="code-line">## [31,] -0.4064146 -0.347591815 -0.19534506 -0.1439862302 -0.08445037</span>
<span class="code-line">## [32,] -0.4213233 -0.421047564 -0.21614195 -0.1475954934 -0.14140091</span>
<span class="code-line">## [33,] -0.3177238 -0.558528507 -0.21188225 -0.0260375231 -0.11058613</span>
<span class="code-line">## [34,] -0.4535206 -0.568930452 -0.13969631  0.0740933171 -0.20728453</span>
<span class="code-line">## [35,] -0.3733466 -0.534136456 -0.20889608  0.0462874732 -0.18328216</span>
<span class="code-line">## [36,] -0.4519620 -0.486894058  0.02868335 -0.0237170894 -0.22067245</span>
<span class="code-line">## [37,] -0.4792771 -0.359058583 -0.17026707  0.0243226733  0.01058587</span>
<span class="code-line">## [38,] -0.4884591 -0.361002718 -0.23670362 -0.0576248626  0.04542125</span>
<span class="code-line">## [39,] -0.3794872 -0.555721465 -0.09478251  0.1039076241 -0.19174868</span>
<span class="code-line">## [40,] -0.4024135 -0.549377337 -0.11356106  0.1869168187 -0.12464387</span>
<span class="code-line">##               [,6]          [,7]          [,8]         [,9]</span>
<span class="code-line">##  [1,] -0.256426344 -0.0051466920 -0.1050080325 -0.217875830</span>
<span class="code-line">##  [2,]  0.132387083 -0.2481776856  0.0048103856  0.073391368</span>
<span class="code-line">##  [3,]  0.106747616 -0.3142731034  0.0725529294 -0.009258277</span>
<span class="code-line">##  [4,] -0.096650456  0.2237402385  0.3933113732  0.175740568</span>
<span class="code-line">##  [5,]  0.101831072 -0.3414194020  0.0325078492  0.085362217</span>
<span class="code-line">##  [6,]  0.073081367 -0.2777839481 -0.0712005483  0.093765748</span>
<span class="code-line">##  [7,] -0.065822588  0.1121413950  0.1320328403  0.243711028</span>
<span class="code-line">##  [8,]  0.008179850 -0.1017128152  0.1404356750  0.359181871</span>
<span class="code-line">##  [9,] -0.331672078 -0.1723038527  0.3330872957 -0.293884580</span>
<span class="code-line">## [10,] -0.106304884 -0.4565341789 -0.0821946123 -0.171057932</span>
<span class="code-line">## [11,] -0.001271796 -0.1320537729 -0.2283180107  0.265527940</span>
<span class="code-line">## [12,]  0.087823904 -0.1132566054  0.0377935294 -0.011283238</span>
<span class="code-line">## [13,]  0.033343619  0.0308950899  0.1426224411 -0.200220801</span>
<span class="code-line">## [14,] -0.252897043  0.0281370136 -0.0346131237 -0.254485357</span>
<span class="code-line">## [15,] -0.039241251  0.1844820354  0.4216051360  0.098786819</span>
<span class="code-line">## [16,] -0.094810107  0.0093078526  0.0096644094  0.016502011</span>
<span class="code-line">## [17,] -0.083413069 -0.3147783298 -0.2285523728 -0.186028731</span>
<span class="code-line">## [18,]  0.002006571  0.0463524348  0.3018104199 -0.260546935</span>
<span class="code-line">## [19,] -0.109840640  0.0355312724  0.0666607568  0.098413082</span>
<span class="code-line">## [20,]  0.070382456 -0.2508050668  0.2867068313  0.083829363</span>
<span class="code-line">## [21,] -0.123678525 -0.1924745951  0.1507108412 -0.019742963</span>
<span class="code-line">## [22,]  0.011646505 -0.0474249609 -0.1572321905  0.166900898</span>
<span class="code-line">## [23,] -0.005346193  0.1102181121 -0.1334792270 -0.157127058</span>
<span class="code-line">## [24,]  0.064851965 -0.0003570599  0.0709592952 -0.068600025</span>
<span class="code-line">## [25,]  0.076120098  0.0523492570 -0.1131530027  0.095050608</span>
<span class="code-line">## [26,]  0.018459564  0.1824386999 -0.1389626180 -0.114702885</span>
<span class="code-line">## [27,]  0.013283974  0.1229109140 -0.0973772037 -0.116962488</span>
<span class="code-line">## [28,]  0.117125266  0.1369392140 -0.1222056233  0.146276756</span>
<span class="code-line">## [29,]  0.099806178 -0.2945216155  0.1256130100 -0.077929380</span>
<span class="code-line">## [30,]  0.083796843 -0.1520357393 -0.0181765447  0.107031691</span>
<span class="code-line">## [31,]  0.611418809  0.1300478000 -0.0035088423 -0.175680364</span>
<span class="code-line">## [32,]  0.569277998  0.1274642030  0.0120766707 -0.147817867</span>
<span class="code-line">## [33,] -0.064299580  0.1599389824  0.0008566237  0.011078551</span>
<span class="code-line">## [34,] -0.111993462  0.0128182266  0.0851071945  0.058119259</span>
<span class="code-line">## [35,] -0.242376556  0.0930813931 -0.0879622294  0.120472821</span>
<span class="code-line">## [36,] -0.121746325  0.0211133535  0.0949324784 -0.117122331</span>
<span class="code-line">## [37,] -0.329825553  0.0814961168 -0.2338333561  0.027777255</span>
<span class="code-line">## [38,] -0.266631231  0.1774163361 -0.1496133363 -0.028050715</span>
<span class="code-line">## [39,] -0.083409801 -0.1393220930 -0.0449142959  0.188743726</span>
<span class="code-line">## [40,] -0.136300169 -0.0389545949  0.0957233294  0.133687572</span>
</pre></div>


<p>We know that the original variables were constructed considering four groups (assertiveness, social confidence, adventurousness, and dominance). These were the intended characteristics that the statements were testing for. Above, we can see how factors 1-5 capture a lot of the variables in each set. So, we could say that factor 1 represents assertiveness, factor 2 represents dominance, factor 3 and 4 represent adventurousness, and factor 5 represents social confidence. </p>
<p>However, this would not be so accurate, as there are other factors to consider as well. We can see that factors 6-9 have members from all the different groups. This suggests that the relationship between the variables was not so simple as we once thought. Additionally, variable 10 failed to have a loading greater than .3 into any of the factors, which suggests that even 9 factors are inadequate to capture the variation in the data.  </p>
<p>In this example, which seemed relatively straightforward, we see that problems emerged quite quickly. What, for instance, is factor six? And why are factors 3 and 4 separated? It is not so clear that our prior ideas about the factors are accurate. </p>
<p>One thing is clear, though. The four factors used to create the questionnaire are insufficient to truly describe the structure of the data. To say that these statements measure these factors would be jumping to conclusions too quickly. Doing so is, in a way, oversimplifying the data. </p>
<p>In conclusion, we have learned that this dataset cannot be so simply separated into the four purported factors. In fact, even separating the variables into 9 factors can only account for 60% of the variation of the variables. We can see that while factor analysis is a powerful technique, it is very dependent on the dataset which it is performed on. The self-checking property of the assumptions of factor analysis ensures that only models which fit the assumptions will produce results which separate the variables adequately to the different factors.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
								</article>
						</div>
					</div>
				</div>
			</section>
	</div>
</div>

				</div>
			</div>

		<!-- Footer Wrapper -->
			<div id="footer-wrapper">
				<!-- Footer -->
					<section id="footer" class="container">
						<div class="row">
							<div class="8u">
								<section>
									<header>
										<h2>Latest articles</h2>
									</header>
									<ul class="dates">
										<li>
											<span class="date">Sep <strong>09</strong></span>
											<h3><a href="sumstatsmeasuresofspread.html">Summary Statistics Part 2: Measures of Spread</a></h3>
											<p><p>An overview of statistics and central tendency.</p></p>
										</li>
										<li>
											<span class="date">Sep <strong>02</strong></span>
											<h3><a href="sumstatscentraltendency.html">Summary Statistics Part 1: Central Tendency</a></h3>
											<p><p>An overview of statistics and central tendency.</p></p>
										</li>
										<li>
											<span class="date">Mar <strong>09</strong></span>
											<h3><a href="approaches-to-contingency-tables.html">Approaches To Contingency Tables</a></h3>
											<p><p>Some approaches to contingency tables using R and Bayesian Statistics</p></p>
										</li>
									</ul>
								</section>
							</div>
						</div>
						<div class="row">
							<div class="4u">
								<section>
									<header>
										<h2>Blogroll</h2>
									</header>
									<ul class="divided">
											<li><a href="http://getpelican.com/">Pelican</a></li>
											<li><a href="http://python.org/">Python.org</a></li>
											<li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
											<li><a href="#">You can modify those links in your config file</a></li>
									</ul>
								</section>
							</div>
							<div class="4u">
								<section>
									<header>
										<h2>Categories</h2>
									</header>
									<ul class="divided">
											<li><a href="https://seanammirati.github.io/category/r_markdown">r_markdown</a></li>
											<li><a href="https://seanammirati.github.io/category/statistics-beginner">Statistics, Beginner</a></li>
									</ul>
								</section>
							</div>
							<div class="4u">
							
								<section>
									<header>
										<h2>Contact</h2>
									</header>
									<ul class="social">
									</ul>
								</section>
							</div>
						</div>
					</section>
			</div>
		<script src="/theme/js/jquery.min.js"></script>
		<script src="/theme/js/jquery.dropotron.js"></script>
		<script src="/theme/js/config.js"></script>
		<script src="/theme/js/skel.min.js"></script>
		<script src="/theme/js/skel-panels.min.js"></script>
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><link rel="stylesheet" href="/theme/css/ie8.css" /><![endif]-->
	</body>
</html>